# DAG Documentation

**Source Repository:** Tezz1999/Covid-19-Realtime-Stream  
**File Path:** hive_connection.py  
**Stars:** 1  
**License:** MIT  
**Detected Version:** 2.x  
**Topology Pattern:** linear  
**Complexity Score:** 2/10  

---

[Pipeline Name] - Comprehensive Pipeline Description

Opening Summary:
This is a simple linear data pipeline that executes Hive database operations for COVID-19 realtime streaming data. The pipeline follows a sequential topology pattern with two tasks executing in strict order. Key infrastructure features include Hive database connectivity and scheduled daily execution at 1:00 AM.

Pipeline Steps:

1. run_after_loop
  • Objective: Execute a system command to identify the executing user context before Hive operations
  • Technical Details:
    - Input: No explicit dependencies (first task in sequence)
    - Output: System command output; triggers downstream hive_task
    - Integrations: Local system shell execution
    - Key Parameters: bash_command='echo `whoami`'
  • Operator or Mechanism: BashOperator
  • Notes: Serves as a preliminary system check before database operations

2. hive_script_task
  • Objective: Execute HiveQL script to create database and table, then insert test data
  • Technical Details:
    - Input: Depends on successful completion of run_after_loop task
    - Output: Creates database 'mydb', table 'mydb.test_af', and inserts test value (2)
    - Integrations: Hive database via hive_cli_conn_id="hive_local"
    - Key Parameters: hql (multi-statement HiveQL script), hive_cli_conn_id="hive_local"
  • Operator or Mechanism: HiveOperator
  • Notes: Executes three Hive operations in sequence: database creation, table creation, and data insertion

Orchestration & Scheduling:
- Schedule: Daily at 1:00 AM ('00 1 * * *')
- Start Date: 1 day prior to current date (days_ago(1))
- Catchup: Not explicitly set (defaults to True)
- Max Active Runs: Not specified
- Default Args: No custom default_args provided

Infrastructure & Dependencies:
- Connections: hive_cli_conn_id="hive_local" (Hive database connection)
- Database Operations: 
  - Creates database 'mydb' if not exists
  - Creates table 'mydb.test_af' with integer column 'test'
  - Inserts test value 2 into the table
- Task Dependencies: Strict linear dependency: run_after_loop → hive_script_task

Failure Handling & Alerts:
- No explicit failure handling mechanisms configured
- No email operators or failure triggers specified
- Retry policies not explicitly defined in default_args

Pattern-Specific Notes:
- Linear/Sequential Pattern: Two tasks execute in strict sequential order
- Simple two-step workflow: system check → Hive database operations
- No parallel execution, branching, or sensor-based gating present
