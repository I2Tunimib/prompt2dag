# DAG Documentation

**Source Repository:** synthetic-generator-v2  
**File Path:** synthetic/synthetic_fan_out_fan_in_06_financial_portfolio_rebalancing.py  
**Stars:** 0  
**License:** MIT  
**Detected Version:** 2.x  
**Topology Pattern:** fan_out_fan_in  
**Complexity Score:** 6/10  

---

[Portfolio Rebalancing DAG] - Comprehensive Pipeline Description

Opening Summary:
This DAG implements a financial portfolio rebalancing pipeline using a fan-out fan-in pattern to process holdings from 5 brokerage accounts in parallel, analyze each portfolio independently, aggregate results to calculate rebalancing trades, and generate final trade orders. The main data flow involves parallel CSV data fetching from multiple brokerages, individual portfolio analysis, aggregation of results, and trade order generation. Key infrastructure features include daily scheduling, PythonOperator-based task execution, and explicit fan-out fan-in orchestration with 5 parallel branches.

Pipeline Steps:

Pre-Processing Stage (before parallel):
*No pre-processing tasks - DAG starts directly with parallel brokerage data fetching*

Parallel Segment (5 parallel tasks):
1. fetch_brokerage_holdings_BROKERAGE_001
  • Objective: Fetch holdings CSV data from brokerage account BROKERAGE_001
  • Technical Details:
    - Input: brokerage_id parameter "BROKERAGE_001"
    - Output: Holdings data dictionary with brokerage ID and mock holdings list
    - Integrations: Simulated brokerage API calls (mock implementation)
    - Key Parameters: brokerage_id="BROKERAGE_001"
  • Operator or Mechanism: PythonOperator
  • Notes: First of 5 parallel brokerage data fetchers

2. fetch_brokerage_holdings_BROKERAGE_002
  • Objective: Fetch holdings CSV data from brokerage account BROKERAGE_002
  • Technical Details:
    - Input: brokerage_id parameter "BROKERAGE_002"
    - Output: Holdings data dictionary with brokerage ID and mock holdings list
    - Integrations: Simulated brokerage API calls (mock implementation)
    - Key Parameters: brokerage_id="BROKERAGE_002"
  • Operator or Mechanism: PythonOperator

3. fetch_brokerage_holdings_BROKERAGE_003
  • Objective: Fetch holdings CSV data from brokerage account BROKERAGE_003
  • Technical Details:
    - Input: brokerage_id parameter "BROKERAGE_003"
    - Output: Holdings data dictionary with brokerage ID and mock holdings list
    - Integrations: Simulated brokerage API calls (mock implementation)
    - Key Parameters: brokerage_id="BROKERAGE_003"
  • Operator or Mechanism: PythonOperator

4. fetch_brokerage_holdings_BROKERAGE_004
  • Objective: Fetch holdings CSV data from brokerage account BROKERAGE_004
  • Technical Details:
    - Input: brokerage_id parameter "BROKERAGE_004"
    - Output: Holdings data dictionary with brokerage ID and mock holdings list
    - Integrations: Simulated brokerage API calls (mock implementation)
    - Key Parameters: brokerage_id="BROKERAGE_004"
  • Operator or Mechanism: PythonOperator

5. fetch_brokerage_holdings_BROKERAGE_005
  • Objective: Fetch holdings CSV data from brokerage account BROKERAGE_005
  • Technical Details:
    - Input: brokerage_id parameter "BROKERAGE_005"
    - Output: Holdings data dictionary with brokerage ID and mock holdings list
    - Integrations: Simulated brokerage API calls (mock implementation)
    - Key Parameters: brokerage_id="BROKERAGE_005"
  • Operator or Mechanism: PythonOperator

6. analyze_portfolio (5 parallel instances)
  • Objective: Calculate portfolio metrics (total value, allocation percentages, risk score) for each brokerage account
  • Technical Details:
    - Input: Holdings data from corresponding fetch_brokerage_holdings task
    - Output: Analysis results dictionary with portfolio metrics
    - Integrations: None (pure calculation)
    - Key Parameters: holdings_data from upstream fetch tasks
  • Operator or Mechanism: PythonOperator
  • Notes: Runs in parallel for each brokerage account (5 instances)

Synchronization/Join Stage (after parallel):
7. aggregate_and_rebalance
  • Objective: Aggregate all portfolio analysis results and calculate rebalancing trades based on target allocations
  • Technical Details:
    - Input: Analysis results from all 5 analyze_portfolio tasks
    - Output: List of rebalancing trades with symbol, action, amount, and allocation data
    - Integrations: None (aggregation and calculation logic)
    - Key Parameters: analysis_results list from all parallel branches
  • Operator or Mechanism: PythonOperator
  • Notes: Implicit fan-in point where all 5 parallel branches converge

8. generate_trade_orders
  • Objective: Generate final trade orders CSV file with rebalancing instructions
  • Technical Details:
    - Input: Rebalancing trades list from aggregate_and_rebalance task
    - Output: Trade orders CSV file with timestamped filename
    - Integrations: File system output (CSV generation)
    - Key Parameters: rebalancing_trades from upstream aggregation
  • Operator or Mechanism: PythonOperator

Orchestration & Scheduling:
- Schedule: @daily
- Start_date: days_ago(1)
- Catchup: Not specified (defaults to DAG default)
- Max_active_runs: Not specified
- Default_args: retries=2, retry_delay=timedelta(minutes=5), email_on_failure=False, email_on_retry=False, depends_on_past=False

Infrastructure & Dependencies:
- Sensors: None
- External triggers: None
- Task grouping: None
- Connections/IDs: None specified (mock API implementations)
- Data I/O hints: Outputs trade_orders_YYYYMMDD.csv with timestamp

Failure Handling & Alerts:
- Retry policy: 2 retries with 5-minute delay
- Email alerts disabled (email_on_failure=False, email_on_retry=False)
- No explicit failure handling operators

Pattern-Specific Notes:
- Fan-out fan-in pattern with explicit 5-way parallel width
- Parallel segment: 5 brokerage data fetchers → 5 portfolio analyzers
- Join achieved through aggregate_and_rebalance task collecting all analysis results
- No explicit trigger rules needed as default all_success suffices for fan-in
