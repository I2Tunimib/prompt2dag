{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ec9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8,742 rows, 94 cols\n",
      "Rows after keeping only declared LLMs: 8,742\n",
      "\n",
      "========================================================================================================================\n",
      "TABLE L1: LLM_for_Workflow × Method (All runs)  [appendix-ready]\n",
      "========================================================================================================================\n",
      "                       LLM_for_Workflow                 Method   N  N_Passed  Pass%         SAT         PCT    Combined  ORT_scaled   Issues     Crit    Major    Minor\n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507     Direct (Reasoning) 342       243   71.1 5.85 ± 1.54 5.90 ± 2.34 5.94 ± 1.82 7.10 ± 1.76 6.061404 0.415205 1.649123 3.997076\n",
      "              deepinfra-claude-4-sonnet Direct (Non-Reasoning) 342       168   49.1 4.97 ± 1.67 5.19 ± 1.98 5.13 ± 1.77 6.11 ± 1.94 7.263158 0.368421 1.976608 4.918129\n",
      "              deepinfra-claude-4-sonnet  Prompt2DAG (Template) 249       138   55.4 4.25 ± 3.66 4.25 ± 3.85 4.29 ± 3.76 6.39 ± 1.52 5.176707 0.702811 2.216867 2.257028\n",
      "              deepinfra-claude-4-sonnet       Prompt2DAG (LLM) 333       222   66.7 6.99 ± 0.41 4.97 ± 3.56 6.03 ± 1.92 6.89 ± 1.69 7.120120 0.414414 1.750751 4.954955\n",
      "              deepinfra-claude-4-sonnet    Prompt2DAG (Hybrid) 333       315   94.6 6.21 ± 0.56 6.61 ± 1.63 6.47 ± 0.94 8.00 ± 1.09 5.630631 0.354354 1.114114 4.162162\n",
      "                  deepinfra-deepseek_ai Direct (Non-Reasoning) 342       167   48.8 4.61 ± 1.60 4.94 ± 1.77 4.80 ± 1.66 5.79 ± 1.84 7.400585 0.418129 2.391813 4.590643\n",
      "                  deepinfra-deepseek_ai  Prompt2DAG (Template) 186        87   46.8 3.63 ± 3.77 3.61 ± 3.89 3.64 ± 3.83 6.16 ± 1.56 4.731183 0.784946 1.967742 1.978495\n",
      "                  deepinfra-deepseek_ai       Prompt2DAG (LLM) 261       201   77.0 6.65 ± 0.36 5.59 ± 3.10 6.15 ± 1.64 7.40 ± 1.70 5.605364 0.409962 1.482759 3.712644\n",
      "                  deepinfra-deepseek_ai    Prompt2DAG (Hybrid) 261       258   98.9 6.05 ± 0.40 6.60 ± 0.79 6.38 ± 0.53 7.73 ± 0.89 6.011494 0.363985 1.766284 3.881226\n",
      "               deepinfra-gemini-2.5-pro     Direct (Reasoning) 342       261   76.3 6.14 ± 1.56 6.65 ± 1.77 6.47 ± 1.63 6.99 ± 1.95 6.538012 0.432749 2.546784 3.558480\n",
      "                   deepinfra-meta_llama Direct (Non-Reasoning) 342       177   51.8 4.78 ± 1.59 5.18 ± 1.79 5.00 ± 1.67 5.80 ± 2.01 7.362573 0.514620 2.476608 4.371345\n",
      "                   deepinfra-meta_llama  Prompt2DAG (Template) 204       126   61.8 4.59 ± 3.64 4.76 ± 3.79 4.69 ± 3.73 6.44 ± 1.53 5.583333 0.774510 2.387255 2.421569\n",
      "                   deepinfra-meta_llama       Prompt2DAG (LLM) 279       276   98.9 6.71 ± 0.42 7.45 ± 0.94 7.09 ± 0.53 8.00 ± 1.01 6.232975 0.412186 1.756272 4.064516\n",
      "                   deepinfra-meta_llama    Prompt2DAG (Hybrid) 279       276   98.9 6.10 ± 0.72 7.01 ± 0.90 6.59 ± 0.75 7.87 ± 0.90 5.505376 0.376344 1.827957 3.301075\n",
      "                deepinfra-microsoft_phi Direct (Non-Reasoning) 342       160   46.8 4.56 ± 1.62 5.07 ± 1.89 4.83 ± 1.73 5.88 ± 1.94 7.228070 0.350877 2.304094 4.573099\n",
      "                deepinfra-microsoft_phi  Prompt2DAG (Template) 147        66   44.9 3.44 ± 3.68 3.45 ± 3.86 3.48 ± 3.78 6.08 ± 1.51 4.721088 0.789116 1.945578 1.986395\n",
      "                deepinfra-microsoft_phi       Prompt2DAG (LLM) 225       171   76.0 5.31 ± 2.73 5.76 ± 3.29 5.56 ± 2.97 7.43 ± 1.75 5.026667 0.582222 1.280000 3.164444\n",
      "                deepinfra-microsoft_phi    Prompt2DAG (Hybrid) 225       213   94.7 5.89 ± 1.28 6.48 ± 1.59 6.23 ± 1.38 7.64 ± 1.03 5.688889 0.417778 1.800000 3.471111\n",
      "               deepinfra-mistralaiSmall Direct (Non-Reasoning) 342       160   46.8 4.46 ± 1.90 4.85 ± 2.17 4.68 ± 2.01 5.72 ± 1.97 7.014620 0.529240 2.418129 4.067251\n",
      "               deepinfra-mistralaiSmall  Prompt2DAG (Template) 240       138   57.5 4.38 ± 3.61 4.41 ± 3.83 4.42 ± 3.71 6.38 ± 1.50 5.416667 0.729167 2.245833 2.441667\n",
      "               deepinfra-mistralaiSmall       Prompt2DAG (LLM) 315       300   95.2 6.94 ± 0.40 7.09 ± 1.73 7.04 ± 0.93 7.86 ± 1.23 6.114286 0.352381 2.120635 3.641270\n",
      "               deepinfra-mistralaiSmall    Prompt2DAG (Hybrid) 315       273   86.7 6.08 ± 0.45 6.01 ± 2.40 6.07 ± 1.29 7.65 ± 1.27 5.723810 0.365079 1.212698 4.146032\n",
      "                         deepinfra-qwen Direct (Non-Reasoning) 342       171   50.0 4.87 ± 1.66 5.21 ± 1.90 5.07 ± 1.76 6.04 ± 1.96 7.134503 0.415205 2.125731 4.593567\n",
      "                         deepinfra-qwen  Prompt2DAG (Template) 210       126   60.0 4.53 ± 3.63 4.63 ± 3.82 4.61 ± 3.73 6.48 ± 1.50 5.390476 0.704762 2.352381 2.333333\n",
      "                         deepinfra-qwen       Prompt2DAG (LLM) 288       267   92.7 6.25 ± 1.80 7.02 ± 2.06 6.69 ± 1.93 8.03 ± 1.31 5.736111 0.406250 1.381944 3.947917\n",
      "                         deepinfra-qwen    Prompt2DAG (Hybrid) 288       279   96.9 5.93 ± 1.13 6.74 ± 1.27 6.37 ± 1.18 7.69 ± 0.99 5.906250 0.420139 1.829861 3.656250\n",
      "                        deepinfra-qwen3 Direct (Non-Reasoning) 342         0    0.0 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 5.12 ± 0.89 1.874269 1.081871 0.397661 0.394737\n",
      "                        deepinfra-qwen3  Prompt2DAG (Template) 342       114   33.3 4.17 ± 2.96 2.59 ± 3.67 3.41 ± 2.92 5.63 ± 1.87 5.002924 0.590643 2.216374 2.195906\n",
      "                        deepinfra-qwen3       Prompt2DAG (LLM) 342         0    0.0 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 5.03 ± 0.90 1.944444 1.178363 0.385965 0.380117\n",
      "                        deepinfra-qwen3    Prompt2DAG (Hybrid) 342         0    0.0 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 5.10 ± 0.87 1.871345 1.114035 0.368421 0.388889\n",
      "\n",
      "========================================================================================================================\n",
      "TABLE L2: Pass rate (%) pivot  [LLM rows × Method cols]\n",
      "========================================================================================================================\n",
      "Method                                  Direct (Non-Reasoning) Prompt2DAG (Template) Prompt2DAG (LLM) Prompt2DAG (Hybrid) Direct (Reasoning)\n",
      "LLM_for_Workflow                                                                                                                            \n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507                                                                                                 71.1\n",
      "deepinfra-claude-4-sonnet                                 49.1                  55.4             66.7                94.6                   \n",
      "deepinfra-deepseek_ai                                     48.8                  46.8             77.0                98.9                   \n",
      "deepinfra-gemini-2.5-pro                                                                                                                76.3\n",
      "deepinfra-meta_llama                                      51.8                  61.8             98.9                98.9                   \n",
      "deepinfra-microsoft_phi                                   46.8                  44.9             76.0                94.7                   \n",
      "deepinfra-mistralaiSmall                                  46.8                  57.5             95.2                86.7                   \n",
      "deepinfra-qwen                                            50.0                  60.0             92.7                96.9                   \n",
      "deepinfra-qwen3                                            0.0                  33.3              0.0                 0.0                   \n",
      "\n",
      "========================================================================================================================\n",
      "TABLE L3: ORT_scaled (mean) pivot  [LLM rows × Method cols]\n",
      "========================================================================================================================\n",
      "Method                                  Direct (Non-Reasoning) Prompt2DAG (Template) Prompt2DAG (LLM) Prompt2DAG (Hybrid) Direct (Reasoning)\n",
      "LLM_for_Workflow                                                                                                                            \n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507                                                                                                  7.1\n",
      "deepinfra-claude-4-sonnet                                 6.11                  6.39             6.89                 8.0                   \n",
      "deepinfra-deepseek_ai                                     5.79                  6.16              7.4                7.73                   \n",
      "deepinfra-gemini-2.5-pro                                                                                                                6.99\n",
      "deepinfra-meta_llama                                       5.8                  6.44              8.0                7.87                   \n",
      "deepinfra-microsoft_phi                                   5.88                  6.08             7.43                7.64                   \n",
      "deepinfra-mistralaiSmall                                  5.72                  6.38             7.86                7.65                   \n",
      "deepinfra-qwen                                            6.04                  6.48             8.03                7.69                   \n",
      "deepinfra-qwen3                                           5.12                  5.63             5.03                 5.1                   \n",
      "\n",
      "========================================================================================================================\n",
      "TABLE L4: LLM_for_Workflow × Orchestrator (aggregated over methods)  [optional appendix]\n",
      "========================================================================================================================\n",
      "                       LLM_for_Workflow Orchestrator   N  Pass%  ORT  Combined\n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507      airflow 114   73.7 7.23      6.11\n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507      dagster 114   71.1 7.25      5.84\n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507      prefect 114   68.4 6.82      5.86\n",
      "              deepinfra-claude-4-sonnet      airflow 447   38.5 5.96      3.90\n",
      "              deepinfra-claude-4-sonnet      dagster 402   81.3 7.54      6.46\n",
      "              deepinfra-claude-4-sonnet      prefect 408   84.3 7.21      6.48\n",
      "                  deepinfra-deepseek_ai      airflow 375   45.1 5.98      3.99\n",
      "                  deepinfra-deepseek_ai      dagster 336   79.5 7.27      5.97\n",
      "                  deepinfra-deepseek_ai      prefect 339   81.7 7.07      6.17\n",
      "               deepinfra-gemini-2.5-pro      airflow 114   76.3 6.95      6.52\n",
      "               deepinfra-gemini-2.5-pro      dagster 114   76.3 7.18      6.50\n",
      "               deepinfra-gemini-2.5-pro      prefect 114   76.3 6.84      6.38\n",
      "                   deepinfra-meta_llama      airflow 393   62.6 6.55      4.95\n",
      "                   deepinfra-meta_llama      dagster 354   87.0 7.43      6.43\n",
      "                   deepinfra-meta_llama      prefect 357   84.3 7.07      6.35\n",
      "                deepinfra-microsoft_phi      airflow 339   59.6 6.48      4.63\n",
      "                deepinfra-microsoft_phi      dagster 297   65.7 6.77      5.19\n",
      "                deepinfra-microsoft_phi      prefect 303   70.3 6.89      5.63\n",
      "               deepinfra-mistralaiSmall      airflow 429   50.8 6.22      4.43\n",
      "               deepinfra-mistralaiSmall      dagster 387   81.4 7.42      6.07\n",
      "               deepinfra-mistralaiSmall      prefect 396   85.4 7.15      6.42\n",
      "                         deepinfra-qwen      airflow 402   62.4 6.58      4.76\n",
      "                         deepinfra-qwen      dagster 363   81.8 7.53      6.45\n",
      "                         deepinfra-qwen      prefect 363   81.3 7.08      6.08\n",
      "                        deepinfra-qwen3      airflow 456    0.0 5.12      0.00\n",
      "                        deepinfra-qwen3      dagster 456    0.0 4.76      0.78\n",
      "                        deepinfra-qwen3      prefect 456   25.0 5.78      1.78\n",
      "\n",
      "========================================================================================================================\n",
      "TABLE L5: LLM_for_Workflow × Orchestrator × Method (compact metrics)  [big appendix table]\n",
      "========================================================================================================================\n",
      "                       LLM_for_Workflow Orchestrator                 Method   N  Pass%  ORT  Combined\n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507      airflow     Direct (Reasoning) 114   73.7 7.23      6.11\n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507      dagster     Direct (Reasoning) 114   71.1 7.25      5.84\n",
      "deepinfra-Qwen3-235B-A22B-Thinking-2507      prefect     Direct (Reasoning) 114   68.4 6.82      5.86\n",
      "              deepinfra-claude-4-sonnet      airflow Direct (Non-Reasoning) 114   50.9 5.90      5.14\n",
      "              deepinfra-claude-4-sonnet      airflow  Prompt2DAG (Template) 111   13.5 5.45      0.95\n",
      "              deepinfra-claude-4-sonnet      airflow       Prompt2DAG (LLM) 111    0.0 5.04      3.35\n",
      "              deepinfra-claude-4-sonnet      airflow    Prompt2DAG (Hybrid) 111   89.2 7.44      6.13\n",
      "              deepinfra-claude-4-sonnet      dagster Direct (Non-Reasoning) 114   47.4 6.20      5.00\n",
      "              deepinfra-claude-4-sonnet      dagster  Prompt2DAG (Template)  66   86.4 7.62      7.40\n",
      "              deepinfra-claude-4-sonnet      dagster       Prompt2DAG (LLM) 111  100.0 8.25      7.58\n",
      "              deepinfra-claude-4-sonnet      dagster    Prompt2DAG (Hybrid) 111   94.6 8.16      6.26\n",
      "              deepinfra-claude-4-sonnet      prefect Direct (Non-Reasoning) 114   49.1 6.22      5.24\n",
      "              deepinfra-claude-4-sonnet      prefect  Prompt2DAG (Template)  72   91.7 6.69      6.59\n",
      "              deepinfra-claude-4-sonnet      prefect       Prompt2DAG (LLM) 111  100.0 7.37      7.14\n",
      "              deepinfra-claude-4-sonnet      prefect    Prompt2DAG (Hybrid) 111  100.0 8.40      7.01\n",
      "                  deepinfra-deepseek_ai      airflow Direct (Non-Reasoning) 114   48.2 5.80      5.05\n",
      "                  deepinfra-deepseek_ai      airflow  Prompt2DAG (Template)  87    0.0 5.05      0.00\n",
      "                  deepinfra-deepseek_ai      airflow       Prompt2DAG (LLM)  87   31.0 5.70      4.30\n",
      "                  deepinfra-deepseek_ai      airflow    Prompt2DAG (Hybrid)  87  100.0 7.41      6.28\n",
      "                  deepinfra-deepseek_ai      dagster Direct (Non-Reasoning) 114   47.4 5.76      4.44\n",
      "                  deepinfra-deepseek_ai      dagster  Prompt2DAG (Template)  48   87.5 7.53      7.34\n",
      "                  deepinfra-deepseek_ai      dagster       Prompt2DAG (LLM)  87  100.0 8.61      7.15\n",
      "                  deepinfra-deepseek_ai      dagster    Prompt2DAG (Hybrid)  87   96.6 7.76      6.06\n",
      "                  deepinfra-deepseek_ai      prefect Direct (Non-Reasoning) 114   50.9 5.82      4.92\n",
      "                  deepinfra-deepseek_ai      prefect  Prompt2DAG (Template)  51   88.2 6.78      6.38\n",
      "                  deepinfra-deepseek_ai      prefect       Prompt2DAG (LLM)  87  100.0 7.90      7.02\n",
      "                  deepinfra-deepseek_ai      prefect    Prompt2DAG (Hybrid)  87  100.0 8.03      6.82\n",
      "               deepinfra-gemini-2.5-pro      airflow     Direct (Reasoning) 114   76.3 6.95      6.52\n",
      "               deepinfra-gemini-2.5-pro      dagster     Direct (Reasoning) 114   76.3 7.18      6.50\n",
      "               deepinfra-gemini-2.5-pro      prefect     Direct (Reasoning) 114   76.3 6.84      6.38\n",
      "                   deepinfra-meta_llama      airflow Direct (Non-Reasoning) 114   42.1 5.76      5.04\n",
      "                   deepinfra-meta_llama      airflow  Prompt2DAG (Template)  93   16.1 5.23      1.13\n",
      "                   deepinfra-meta_llama      airflow       Prompt2DAG (LLM)  93  100.0 7.77      7.07\n",
      "                   deepinfra-meta_llama      airflow    Prompt2DAG (Hybrid)  93   96.8 7.63      6.52\n",
      "                   deepinfra-meta_llama      dagster Direct (Non-Reasoning) 114   62.3 6.10      5.13\n",
      "                   deepinfra-meta_llama      dagster  Prompt2DAG (Template)  54  100.0 7.94      8.18\n",
      "                   deepinfra-meta_llama      dagster       Prompt2DAG (LLM)  93   96.8 8.41      7.07\n",
      "                   deepinfra-meta_llama      dagster    Prompt2DAG (Hybrid)  93  100.0 7.78      6.36\n",
      "                   deepinfra-meta_llama      prefect Direct (Non-Reasoning) 114   50.9 5.54      4.83\n",
      "                   deepinfra-meta_llama      prefect  Prompt2DAG (Template)  57  100.0 7.00      7.20\n",
      "                   deepinfra-meta_llama      prefect       Prompt2DAG (LLM)  93  100.0 7.84      7.14\n",
      "                   deepinfra-meta_llama      prefect    Prompt2DAG (Hybrid)  93  100.0 8.21      6.89\n",
      "                deepinfra-microsoft_phi      airflow Direct (Non-Reasoning) 114   48.2 5.99      5.08\n",
      "                deepinfra-microsoft_phi      airflow  Prompt2DAG (Template)  75    0.0 5.00      0.00\n",
      "                deepinfra-microsoft_phi      airflow       Prompt2DAG (LLM)  75   96.0 7.72      6.75\n",
      "                deepinfra-microsoft_phi      airflow    Prompt2DAG (Hybrid)  75  100.0 7.45      6.45\n",
      "                deepinfra-microsoft_phi      dagster Direct (Non-Reasoning) 114   47.4 5.70      4.64\n",
      "                deepinfra-microsoft_phi      dagster  Prompt2DAG (Template)  33   90.9 7.63      7.64\n",
      "                deepinfra-microsoft_phi      dagster       Prompt2DAG (LLM)  75   56.0 7.17      4.34\n",
      "                deepinfra-microsoft_phi      dagster    Prompt2DAG (Hybrid)  75   92.0 7.62      5.80\n",
      "                deepinfra-microsoft_phi      prefect Direct (Non-Reasoning) 114   44.7 5.93      4.77\n",
      "                deepinfra-microsoft_phi      prefect  Prompt2DAG (Template)  39   92.3 6.86      6.64\n",
      "                deepinfra-microsoft_phi      prefect       Prompt2DAG (LLM)  75   76.0 7.40      5.60\n",
      "                deepinfra-microsoft_phi      prefect    Prompt2DAG (Hybrid)  75   92.0 7.84      6.44\n",
      "               deepinfra-mistralaiSmall      airflow Direct (Non-Reasoning) 114   43.9 5.54      4.98\n",
      "               deepinfra-mistralaiSmall      airflow  Prompt2DAG (Template) 105   14.3 5.35      0.99\n",
      "               deepinfra-mistralaiSmall      airflow       Prompt2DAG (LLM) 105   85.7 7.24      6.60\n",
      "               deepinfra-mistralaiSmall      airflow    Prompt2DAG (Hybrid) 105   60.0 6.79      5.09\n",
      "               deepinfra-mistralaiSmall      dagster Direct (Non-Reasoning) 114   44.7 5.79      4.00\n",
      "               deepinfra-mistralaiSmall      dagster  Prompt2DAG (Template)  63   85.7 7.52      7.31\n",
      "               deepinfra-mistralaiSmall      dagster       Prompt2DAG (LLM) 105  100.0 8.50      7.44\n",
      "               deepinfra-mistralaiSmall      dagster    Prompt2DAG (Hybrid) 105  100.0 8.06      6.22\n",
      "               deepinfra-mistralaiSmall      prefect Direct (Non-Reasoning) 114   51.8 5.82      5.07\n",
      "               deepinfra-mistralaiSmall      prefect  Prompt2DAG (Template)  72   95.8 6.90      6.88\n",
      "               deepinfra-mistralaiSmall      prefect       Prompt2DAG (LLM) 105  100.0 7.82      7.08\n",
      "               deepinfra-mistralaiSmall      prefect    Prompt2DAG (Hybrid) 105  100.0 8.09      6.90\n",
      "                         deepinfra-qwen      airflow Direct (Non-Reasoning) 114   49.1 6.09      5.18\n",
      "                         deepinfra-qwen      airflow  Prompt2DAG (Template)  96   15.6 5.40      1.10\n",
      "                         deepinfra-qwen      airflow       Prompt2DAG (LLM)  96   90.6 7.53      6.40\n",
      "                         deepinfra-qwen      airflow    Prompt2DAG (Hybrid)  96   96.9 7.40      6.30\n",
      "                         deepinfra-qwen      dagster Direct (Non-Reasoning) 114   47.4 6.02      4.92\n",
      "                         deepinfra-qwen      dagster  Prompt2DAG (Template)  57   94.7 7.68      7.95\n",
      "                         deepinfra-qwen      dagster       Prompt2DAG (LLM)  96  100.0 9.01      7.68\n",
      "                         deepinfra-qwen      dagster    Prompt2DAG (Hybrid)  96   96.9 7.76      6.13\n",
      "                         deepinfra-qwen      prefect Direct (Non-Reasoning) 114   53.5 6.00      5.11\n",
      "                         deepinfra-qwen      prefect  Prompt2DAG (Template)  57  100.0 7.08      7.19\n",
      "                         deepinfra-qwen      prefect       Prompt2DAG (LLM)  96   87.5 7.54      5.98\n",
      "                         deepinfra-qwen      prefect    Prompt2DAG (Hybrid)  96   96.9 7.90      6.69\n",
      "                        deepinfra-qwen3      airflow Direct (Non-Reasoning) 114    0.0 5.14      0.00\n",
      "                        deepinfra-qwen3      airflow  Prompt2DAG (Template) 114    0.0 5.15      0.00\n",
      "                        deepinfra-qwen3      airflow       Prompt2DAG (LLM) 114    0.0 5.00      0.00\n",
      "                        deepinfra-qwen3      airflow    Prompt2DAG (Hybrid) 114    0.0 5.17      0.00\n",
      "                        deepinfra-qwen3      dagster Direct (Non-Reasoning) 114    0.0 5.02      0.00\n",
      "                        deepinfra-qwen3      dagster  Prompt2DAG (Template) 114    0.0 3.85      3.10\n",
      "                        deepinfra-qwen3      dagster       Prompt2DAG (LLM) 114    0.0 5.02      0.00\n",
      "                        deepinfra-qwen3      dagster    Prompt2DAG (Hybrid) 114    0.0 5.13      0.00\n",
      "                        deepinfra-qwen3      prefect Direct (Non-Reasoning) 114    0.0 5.19      0.00\n",
      "                        deepinfra-qwen3      prefect  Prompt2DAG (Template) 114  100.0 7.88      7.12\n",
      "                        deepinfra-qwen3      prefect       Prompt2DAG (LLM) 114    0.0 5.07      0.00\n",
      "                        deepinfra-qwen3      prefect    Prompt2DAG (Hybrid) 114    0.0 5.00      0.00\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "llm_performance_analysis.py\n",
    "\n",
    "Analyzes performance across LLMs while preserving your 5-method methodology.\n",
    "\n",
    "Outputs:\n",
    "1) TABLE L1: LLM_for_Workflow × Method (All runs)\n",
    "2) TABLE L2: Pass-rate pivot (LLM rows × Method columns)\n",
    "3) TABLE L3: ORT pivot (LLM rows × Method columns)\n",
    "4) TABLE L4 (optional): LLM_for_Workflow × Orchestrator (aggregated over methods)\n",
    "5) TABLE L5 (optional): LLM_for_Workflow × Orchestrator × Method (big; appendix only)\n",
    "\n",
    "Notes:\n",
    "- Uses Std_LLM for Direct (Non-Reasoning) + Prompt2DAG strategies\n",
    "- Uses Reasoning_LLM for Direct (Reasoning)\n",
    "- Computes ORT_scaled using the same approach as your main analysis (global min-max scaling)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "CSV_PATH = \"/Users/abubakarialidu/Desktop/Data Result/all_sessions_cleaned.csv\"\n",
    "\n",
    "STANDARD_LLMS = (\n",
    "  \"deepinfra:deepseek_ai\",\n",
    "  \"deepinfra:meta_llama\",\n",
    "  \"deepinfra:qwen\",\n",
    "  \"deepinfra:qwen3\",\n",
    "  \"deepinfra:microsoft_phi\",\n",
    "  \"deepinfra:claude-4-sonnet\",\n",
    "  \"deepinfra:mistralaiSmall\",\n",
    ")\n",
    "\n",
    "REASONING_LLMS = (\n",
    "  \"deepinfra:Qwen3-235B-A22B-Thinking-2507\",\n",
    "  \"deepinfra:gemini-2.5-pro\",\n",
    ")\n",
    "\n",
    "ORCH_ORDER = [\"airflow\", \"dagster\", \"prefect\"]\n",
    "METHOD_ORDER = [\n",
    "    \"Direct (Non-Reasoning)\",\n",
    "    \"Prompt2DAG (Template)\",\n",
    "    \"Prompt2DAG (LLM)\",\n",
    "    \"Prompt2DAG (Hybrid)\",\n",
    "    \"Direct (Reasoning)\",\n",
    "]\n",
    "\n",
    "# ORT penalty weights (match your main analysis)\n",
    "ALPHA_CRIT = 2.0\n",
    "BETA_MAJOR = 1.0\n",
    "GAMMA_MINOR = 0.25\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 240)\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def normalize_llm_name(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Make LLM identifiers comparable across formats:\n",
    "    - dataset often uses deepinfra-deepseek_ai, while your lists use deepinfra:deepseek_ai\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    x = str(x).strip()\n",
    "    x = x.replace(\"deepinfra:\", \"deepinfra-\")\n",
    "    x = x.replace(\":\", \"-\")\n",
    "    x = x.replace(\"/\", \"_\")\n",
    "    x = x.replace(\" \", \"\")\n",
    "    return x\n",
    "\n",
    "STD_SET = set(normalize_llm_name(x) for x in STANDARD_LLMS)\n",
    "RSN_SET = set(normalize_llm_name(x) for x in REASONING_LLMS)\n",
    "ALL_LLM_SET = STD_SET.union(RSN_SET)\n",
    "\n",
    "def classify_method(row):\n",
    "    workflow = row.get(\"Workflow\", \"\")\n",
    "    strategy = str(row.get(\"Strategy\") or \"\").lower()\n",
    "    if workflow == \"Direct\":\n",
    "        return \"Direct (Non-Reasoning)\"\n",
    "    elif workflow == \"Reasoning\":\n",
    "        return \"Direct (Reasoning)\"\n",
    "    elif workflow == \"Prompt2DAG\":\n",
    "        if \"template\" in strategy:\n",
    "            return \"Prompt2DAG (Template)\"\n",
    "        elif \"llm\" in strategy:\n",
    "            return \"Prompt2DAG (LLM)\"\n",
    "        elif \"hybrid\" in strategy:\n",
    "            return \"Prompt2DAG (Hybrid)\"\n",
    "        else:\n",
    "            return f\"Prompt2DAG ({row.get('Strategy','Unknown')})\"\n",
    "    else:\n",
    "        return workflow\n",
    "\n",
    "def mean_sd(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    if len(x) == 0:\n",
    "        return \"NA\"\n",
    "    return f\"{x.mean():.2f} ± {x.std(ddof=1):.2f}\"\n",
    "\n",
    "# -----------------------\n",
    "# Load\n",
    "# -----------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Loaded {len(df):,} rows, {len(df.columns)} cols\")\n",
    "\n",
    "# Normalize orchestrator\n",
    "df[\"Orchestrator\"] = df[\"Orchestrator\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Passed → bool\n",
    "if df[\"Passed\"].dtype != bool:\n",
    "    df[\"Passed\"] = df[\"Passed\"].astype(str).str.lower().map({\"true\": True, \"false\": False, \"1\": True, \"0\": False})\n",
    "\n",
    "# Method\n",
    "df[\"Method\"] = df.apply(classify_method, axis=1)\n",
    "df = df[df[\"Method\"].isin(METHOD_ORDER)].copy()\n",
    "\n",
    "# Ensure columns\n",
    "for c in [\"Std_LLM\", \"Reasoning_LLM\"]:\n",
    "    if c not in df.columns:\n",
    "        df[c] = \"unknown\"\n",
    "\n",
    "for c in [\"Static_Score\", \"Compliance_Score\", \"Combined_Score\"]:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing required score column: {c}\")\n",
    "\n",
    "for c in [\"Critical_Issues\", \"Major_Issues\", \"Minor_Issues\"]:\n",
    "    if c not in df.columns:\n",
    "        df[c] = 0\n",
    "    df[c] = df[c].fillna(0)\n",
    "\n",
    "df[\"Total_Issues\"] = df[\"Critical_Issues\"] + df[\"Major_Issues\"] + df[\"Minor_Issues\"]\n",
    "\n",
    "# LLM_for_Workflow (Std for Direct/P2D; Reasoning for Reasoning)\n",
    "def get_llm_for_workflow(row):\n",
    "    if row[\"Method\"] == \"Direct (Reasoning)\":\n",
    "        return normalize_llm_name(row.get(\"Reasoning_LLM\", \"\"))\n",
    "    else:\n",
    "        return normalize_llm_name(row.get(\"Std_LLM\", \"\"))\n",
    "\n",
    "df[\"LLM_for_Workflow\"] = df.apply(get_llm_for_workflow, axis=1)\n",
    "\n",
    "# Filter to declared LLMs only (recommended for clean appendix tables)\n",
    "df = df[df[\"LLM_for_Workflow\"].isin(ALL_LLM_SET)].copy()\n",
    "print(f\"Rows after keeping only declared LLMs: {len(df):,}\")\n",
    "\n",
    "# -----------------------\n",
    "# ORT_scaled (global min-max scaling like your main analysis)\n",
    "# -----------------------\n",
    "df[\"Base_Score\"] = np.where(df[\"Passed\"] == True, df[\"Combined_Score\"], 0.0)\n",
    "df[\"Penalty\"] = (\n",
    "    ALPHA_CRIT * df[\"Critical_Issues\"] +\n",
    "    BETA_MAJOR * df[\"Major_Issues\"] +\n",
    "    GAMMA_MINOR * df[\"Minor_Issues\"]\n",
    ")\n",
    "df[\"ORT_raw\"] = df[\"Base_Score\"] - df[\"Penalty\"]\n",
    "\n",
    "ort_min = df[\"ORT_raw\"].min()\n",
    "ort_max = df[\"ORT_raw\"].max()\n",
    "df[\"ORT_scaled\"] = 0.0\n",
    "if ort_max > ort_min:\n",
    "    df[\"ORT_scaled\"] = 10.0 * (df[\"ORT_raw\"] - ort_min) / (ort_max - ort_min)\n",
    "\n",
    "# -----------------------\n",
    "# TABLE L1: LLM × Method (All runs)\n",
    "# -----------------------\n",
    "grp = df.groupby([\"LLM_for_Workflow\", \"Method\"], observed=True)\n",
    "\n",
    "t1 = grp.agg(\n",
    "    N=(\"Passed\", \"size\"),\n",
    "    N_Passed=(\"Passed\", \"sum\"),\n",
    "    Pass_Rate=(\"Passed\", \"mean\"),\n",
    "    SAT_mean=(\"Static_Score\", \"mean\"),\n",
    "    SAT_sd=(\"Static_Score\", \"std\"),\n",
    "    PCT_mean=(\"Compliance_Score\", \"mean\"),\n",
    "    PCT_sd=(\"Compliance_Score\", \"std\"),\n",
    "    Combined_mean=(\"Combined_Score\", \"mean\"),\n",
    "    Combined_sd=(\"Combined_Score\", \"std\"),\n",
    "    ORT_mean=(\"ORT_scaled\", \"mean\"),\n",
    "    ORT_sd=(\"ORT_scaled\", \"std\"),\n",
    "    Crit=(\"Critical_Issues\", \"mean\"),\n",
    "    Major=(\"Major_Issues\", \"mean\"),\n",
    "    Minor=(\"Minor_Issues\", \"mean\"),\n",
    "    Issues=(\"Total_Issues\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "t1[\"Pass%\"] = (100 * t1[\"Pass_Rate\"]).round(1)\n",
    "t1[\"SAT\"] = t1.apply(lambda r: f\"{r['SAT_mean']:.2f} ± {r['SAT_sd']:.2f}\", axis=1)\n",
    "t1[\"PCT\"] = t1.apply(lambda r: f\"{r['PCT_mean']:.2f} ± {r['PCT_sd']:.2f}\", axis=1)\n",
    "t1[\"Combined\"] = t1.apply(lambda r: f\"{r['Combined_mean']:.2f} ± {r['Combined_sd']:.2f}\", axis=1)\n",
    "t1[\"ORT_scaled\"] = t1.apply(lambda r: f\"{r['ORT_mean']:.2f} ± {r['ORT_sd']:.2f}\", axis=1)\n",
    "\n",
    "t1_out = t1[[\n",
    "    \"LLM_for_Workflow\", \"Method\", \"N\", \"N_Passed\", \"Pass%\", \"SAT\", \"PCT\", \"Combined\", \"ORT_scaled\",\n",
    "    \"Issues\", \"Crit\", \"Major\", \"Minor\"\n",
    "]].copy()\n",
    "\n",
    "t1_out[\"Method\"] = pd.Categorical(t1_out[\"Method\"], METHOD_ORDER, ordered=True)\n",
    "t1_out = t1_out.sort_values([\"LLM_for_Workflow\", \"Method\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TABLE L1: LLM_for_Workflow × Method (All runs)  [appendix-ready]\")\n",
    "print(\"=\"*120)\n",
    "print(t1_out.to_string(index=False))\n",
    "\n",
    "# -----------------------\n",
    "# TABLE L2: Pass rate pivot (LLM rows × Method cols)\n",
    "# -----------------------\n",
    "pass_pivot = (\n",
    "    grp[\"Passed\"].mean().reset_index()\n",
    "    .assign(PassPct=lambda d: (100*d[\"Passed\"]).round(1))\n",
    "    .pivot(index=\"LLM_for_Workflow\", columns=\"Method\", values=\"PassPct\")\n",
    ")\n",
    "pass_pivot = pass_pivot.reindex(columns=METHOD_ORDER)\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TABLE L2: Pass rate (%) pivot  [LLM rows × Method cols]\")\n",
    "print(\"=\"*120)\n",
    "print(pass_pivot.fillna(\"\").to_string())\n",
    "\n",
    "# -----------------------\n",
    "# TABLE L3: ORT pivot (LLM rows × Method cols)\n",
    "# -----------------------\n",
    "ort_pivot = (\n",
    "    grp[\"ORT_scaled\"].mean().reset_index()\n",
    "    .assign(ORT=lambda d: d[\"ORT_scaled\"].round(2))\n",
    "    .pivot(index=\"LLM_for_Workflow\", columns=\"Method\", values=\"ORT\")\n",
    ")\n",
    "ort_pivot = ort_pivot.reindex(columns=METHOD_ORDER)\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TABLE L3: ORT_scaled (mean) pivot  [LLM rows × Method cols]\")\n",
    "print(\"=\"*120)\n",
    "print(ort_pivot.fillna(\"\").to_string())\n",
    "\n",
    "# -----------------------\n",
    "# TABLE L4: LLM × Orchestrator (aggregated over methods)\n",
    "# -----------------------\n",
    "grp2 = df.groupby([\"LLM_for_Workflow\", \"Orchestrator\"], observed=True)\n",
    "\n",
    "t4 = grp2.agg(\n",
    "    N=(\"Passed\", \"size\"),\n",
    "    Pass_Rate=(\"Passed\", \"mean\"),\n",
    "    ORT=(\"ORT_scaled\", \"mean\"),\n",
    "    Combined=(\"Combined_Score\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "t4[\"Pass%\"] = (100*t4[\"Pass_Rate\"]).round(1)\n",
    "t4[\"ORT\"] = t4[\"ORT\"].round(2)\n",
    "t4[\"Combined\"] = t4[\"Combined\"].round(2)\n",
    "\n",
    "t4[\"Orchestrator\"] = pd.Categorical(t4[\"Orchestrator\"], ORCH_ORDER, ordered=True)\n",
    "t4 = t4.sort_values([\"LLM_for_Workflow\", \"Orchestrator\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TABLE L4: LLM_for_Workflow × Orchestrator (aggregated over methods)  [optional appendix]\")\n",
    "print(\"=\"*120)\n",
    "print(t4[[\"LLM_for_Workflow\",\"Orchestrator\",\"N\",\"Pass%\",\"ORT\",\"Combined\"]].to_string(index=False))\n",
    "\n",
    "# -----------------------\n",
    "# TABLE L5: LLM × Orchestrator × Method (BIG, but useful for appendix/diagnostics)\n",
    "# -----------------------\n",
    "grp3 = df.groupby([\"LLM_for_Workflow\", \"Orchestrator\", \"Method\"], observed=True)\n",
    "\n",
    "t5 = grp3.agg(\n",
    "    N=(\"Passed\", \"size\"),\n",
    "    Pass_Rate=(\"Passed\", \"mean\"),\n",
    "    ORT=(\"ORT_scaled\", \"mean\"),\n",
    "    Combined=(\"Combined_Score\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "t5[\"Pass%\"] = (100*t5[\"Pass_Rate\"]).round(1)\n",
    "t5[\"ORT\"] = t5[\"ORT\"].round(2)\n",
    "t5[\"Combined\"] = t5[\"Combined\"].round(2)\n",
    "\n",
    "t5[\"Orchestrator\"] = pd.Categorical(t5[\"Orchestrator\"], ORCH_ORDER, ordered=True)\n",
    "t5[\"Method\"] = pd.Categorical(t5[\"Method\"], METHOD_ORDER, ordered=True)\n",
    "t5 = t5.sort_values([\"LLM_for_Workflow\",\"Orchestrator\",\"Method\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TABLE L5: LLM_for_Workflow × Orchestrator × Method (compact metrics)  [big appendix table]\")\n",
    "print(\"=\"*120)\n",
    "print(t5[[\"LLM_for_Workflow\",\"Orchestrator\",\"Method\",\"N\",\"Pass%\",\"ORT\",\"Combined\"]].to_string(index=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
