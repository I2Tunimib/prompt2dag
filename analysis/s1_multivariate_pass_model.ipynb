{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ebe0a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8,742 rows, 94 cols\n",
      "Filtered to Prompt2DAG: 5,664 rows\n",
      "Using base LLM column: Std_LLM\n",
      "Modeling rows after dropna: 5,664\n",
      "\n",
      "Baseline numeric: ['S1_Graph_total_nodes_in_flow', 'S1_Graph_total_edges', 'S1_Graph_total_components', 'S1_Graph_max_pipeline_depth']\n",
      "Full numeric: ['S1_Graph_total_nodes_in_flow', 'S1_Graph_total_edges', 'S1_Graph_total_components', 'S1_Graph_max_pipeline_depth', 'S1_Graph_overall_score', 'S1_Graph_Node_Connectivity_score', 'S1_Sem_ROUGE1_norm', 'S1_Sem_KeyTerm_rate']\n",
      "Categorical: ['Orchestrator', 'Method', 'Std_LLM']\n",
      "\n",
      "==============================================================================================================\n",
      "STATSMODELS LOGISTIC REGRESSION (FULL MODEL): Odds Ratios + 95% CI\n",
      "==============================================================================================================\n",
      "\n",
      "Formula:\n",
      " Passed_num ~ S1_Graph_total_nodes_in_flow + S1_Graph_total_edges + S1_Graph_total_components + S1_Graph_max_pipeline_depth + S1_Graph_overall_score + S1_Graph_Node_Connectivity_score + S1_Sem_ROUGE1_norm + S1_Sem_KeyTerm_rate + C(Orchestrator) + C(Method) + C(Std_LLM)\n",
      "\n",
      "Top predictors (sorted by p-value):\n",
      "                                          coef      OR  CI_low  CI_high      p\n",
      "C(Orchestrator)[T.prefect]              4.1417 62.9085 44.9961  87.9516 0.0000\n",
      "C(Orchestrator)[T.dagster]              2.5897 13.3261 10.5336  16.8588 0.0000\n",
      "C(Method)[T.Prompt2DAG (Template)]     -2.0931  0.1233  0.0982   0.1548 0.0000\n",
      "C(Std_LLM)[T.deepinfra-qwen3]          -2.6263  0.0723  0.0427   0.1227 0.0000\n",
      "C(Std_LLM)[T.deepinfra-meta_llama]      1.8362  6.2726  4.2839   9.1844 0.0000\n",
      "C(Method)[T.Prompt2DAG (LLM)]          -1.0038  0.3665  0.2956   0.4544 0.0000\n",
      "Intercept                              -5.0993  0.0061  0.0019   0.0201 0.0000\n",
      "C(Std_LLM)[T.deepinfra-qwen]            1.1144  3.0477  2.2021   4.2182 0.0000\n",
      "S1_Graph_overall_score                  0.4101  1.5070  1.3337   1.7029 0.0000\n",
      "C(Std_LLM)[T.deepinfra-mistralaiSmall]  0.8090  2.2456  1.6725   3.0150 0.0000\n",
      "C(Std_LLM)[T.deepinfra-deepseek_ai]     0.4998  1.6484  1.1988   2.2668 0.0021\n",
      "S1_Graph_max_pipeline_depth             0.1011  1.1064  1.0178   1.2026 0.0176\n",
      "C(Std_LLM)[T.deepinfra-microsoft_phi]   0.3923  1.4804  1.0602   2.0672 0.0213\n",
      "S1_Graph_total_edges                   -0.0636  0.9384  0.8702   1.0120 0.0987\n",
      "S1_Sem_KeyTerm_rate                     1.2519  3.4970  0.6763  18.0833 0.1353\n",
      "S1_Sem_ROUGE1_norm                      0.0929  1.0973  0.9493   1.2684 0.2089\n",
      "S1_Graph_total_nodes_in_flow            0.0501  1.0513  0.9488   1.1650 0.3391\n",
      "S1_Graph_total_components              -0.0248  0.9755  0.9005   1.0567 0.5429\n",
      "S1_Graph_Node_Connectivity_score       -0.0002  0.9998  0.9976   1.0021 0.8876\n",
      "\n",
      "KEY EFFECT: S1_Graph_overall_score\n",
      "  OR = 1.507  (95% CI 1.334–1.703), p=4.74e-11\n",
      "\n",
      "KEY EFFECT: S1_Graph_Node_Connectivity_score\n",
      "  OR = 1.000  (95% CI 0.998–1.002), p=0.888\n",
      "\n",
      "==============================================================================================================\n",
      "SKLEARN AUC (Hold-out): Baseline vs Full\n",
      "==============================================================================================================\n",
      "Baseline AUC (complexity + controls): 0.9222\n",
      "Full AUC (+ S1 metrics):             0.9265\n",
      "Δ AUC:                               +0.0043\n",
      "\n",
      "==============================================================================================================\n",
      "GROUPED CV (GroupKFold by Pipeline_ID): AUC Baseline vs Full\n",
      "==============================================================================================================\n",
      "Baseline AUC (GroupKFold) mean±sd: 0.9296 ± 0.0226\n",
      "Full AUC (GroupKFold) mean±sd:     0.9334 ± 0.0192\n",
      "Δ AUC (mean):                      +0.0038\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "s1_multivariate_pass_model.py\n",
    "\n",
    "Goal:\n",
    "- Demonstrate that S1 metrics (especially S1_Graph_overall_score / connectivity)\n",
    "  remain predictive of pass/fail AFTER controlling for:\n",
    "    - pipeline complexity (nodes, edges, depth, components)\n",
    "    - orchestrator\n",
    "    - Prompt2DAG strategy (Template/LLM/Hybrid) [Method column]\n",
    "    - base LLM (Std_LLM)\n",
    "\n",
    "Outputs:\n",
    "- Logistic regression odds ratios + 95% CI (statsmodels)\n",
    "- AUC (sklearn) for baseline vs full model\n",
    "- Optional GroupKFold AUC by Pipeline_ID (recommended)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "CSV_PATH = \"/Users/abubakarialidu/Desktop/Data Result/all_sessions_cleaned.csv\"\n",
    "\n",
    "FILTER_PROMPT2DAG_ONLY = True  # S1 metrics exist there\n",
    "TEST_SIZE = 0.25\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Candidate column names for the \"base model\" dimension\n",
    "STD_LLM_CANDIDATES = [\"Std_LLM\", \"STD_LLM\", \"Base_LLM\", \"Model\", \"LLM\"]\n",
    "\n",
    "# Complexity features\n",
    "COMPLEXITY_COLS = [\n",
    "    \"S1_Graph_total_nodes_in_flow\",\n",
    "    \"S1_Graph_total_edges\",\n",
    "    \"S1_Graph_total_components\",\n",
    "    \"S1_Graph_max_pipeline_depth\",\n",
    "]\n",
    "\n",
    "# S1 features (keep modest to reduce multicollinearity)\n",
    "S1_FEATURES = [\n",
    "    \"S1_Graph_overall_score\",\n",
    "    \"S1_Graph_Node_Connectivity_score\",\n",
    "    \"S1_Sem_ROUGE1_norm\",\n",
    "    \"S1_Sem_KeyTerm_rate\",\n",
    "]\n",
    "\n",
    "# Categorical controls\n",
    "CATEGORICAL_COLS = [\"Orchestrator\", \"Method\"]  # Method = Template/LLM/Hybrid for Prompt2DAG\n",
    "\n",
    "# Group leakage control\n",
    "GROUP_COL = \"Pipeline_ID\"  # use GroupKFold if available\n",
    "\n",
    "# -----------------------\n",
    "# Load\n",
    "# -----------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Loaded {len(df):,} rows, {len(df.columns)} cols\")\n",
    "\n",
    "# Method classification (if you haven't already stored Method in the CSV)\n",
    "def classify_method(row):\n",
    "    workflow = row.get(\"Workflow\", \"\")\n",
    "    strategy = str(row.get(\"Strategy\") or \"\").lower()\n",
    "    if workflow == \"Prompt2DAG\":\n",
    "        if \"template\" in strategy:\n",
    "            return \"Prompt2DAG (Template)\"\n",
    "        elif \"llm\" in strategy:\n",
    "            return \"Prompt2DAG (LLM)\"\n",
    "        elif \"hybrid\" in strategy:\n",
    "            return \"Prompt2DAG (Hybrid)\"\n",
    "        else:\n",
    "            return f\"Prompt2DAG ({row.get('Strategy', 'Unknown')})\"\n",
    "    return workflow\n",
    "\n",
    "if \"Method\" not in df.columns:\n",
    "    df[\"Method\"] = df.apply(classify_method, axis=1)\n",
    "\n",
    "if FILTER_PROMPT2DAG_ONLY:\n",
    "    df = df[df[\"Workflow\"] == \"Prompt2DAG\"].copy()\n",
    "    print(f\"Filtered to Prompt2DAG: {len(df):,} rows\")\n",
    "\n",
    "# Passed numeric\n",
    "df[\"Passed_num\"] = df[\"Passed\"].astype(int)\n",
    "\n",
    "# Find Std_LLM column if present\n",
    "std_llm_col = None\n",
    "for c in STD_LLM_CANDIDATES:\n",
    "    if c in df.columns:\n",
    "        std_llm_col = c\n",
    "        break\n",
    "\n",
    "if std_llm_col is not None:\n",
    "    print(f\"Using base LLM column: {std_llm_col}\")\n",
    "    if std_llm_col not in CATEGORICAL_COLS:\n",
    "        CATEGORICAL_COLS = CATEGORICAL_COLS + [std_llm_col]\n",
    "else:\n",
    "    print(\"WARNING: No Std_LLM column found. Model will not control for base LLM.\")\n",
    "\n",
    "# Ensure required columns exist\n",
    "needed_numeric = [c for c in (COMPLEXITY_COLS + S1_FEATURES) if c in df.columns]\n",
    "missing_numeric = [c for c in (COMPLEXITY_COLS + S1_FEATURES) if c not in df.columns]\n",
    "if missing_numeric:\n",
    "    print(\"WARNING: Missing some numeric predictors:\", missing_numeric)\n",
    "\n",
    "needed_cats = [c for c in CATEGORICAL_COLS if c in df.columns]\n",
    "missing_cats = [c for c in CATEGORICAL_COLS if c not in df.columns]\n",
    "if missing_cats:\n",
    "    print(\"WARNING: Missing some categorical predictors:\", missing_cats)\n",
    "\n",
    "# Drop rows with missing predictors (simple approach)\n",
    "model_cols = [\"Passed_num\"] + needed_numeric + needed_cats\n",
    "if GROUP_COL in df.columns:\n",
    "    model_cols += [GROUP_COL]\n",
    "\n",
    "df_m = df[model_cols].dropna().copy()\n",
    "print(f\"Modeling rows after dropna: {len(df_m):,}\")\n",
    "\n",
    "# -----------------------\n",
    "# Build Baseline vs Full features\n",
    "# -----------------------\n",
    "baseline_numeric = [c for c in COMPLEXITY_COLS if c in df_m.columns]\n",
    "full_numeric = baseline_numeric + [c for c in S1_FEATURES if c in df_m.columns]\n",
    "\n",
    "categorical = needed_cats\n",
    "\n",
    "print(\"\\nBaseline numeric:\", baseline_numeric)\n",
    "print(\"Full numeric:\", full_numeric)\n",
    "print(\"Categorical:\", categorical)\n",
    "\n",
    "# -----------------------\n",
    "# (1) Statsmodels: Odds ratios + CI (Full model)\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\" * 110)\n",
    "print(\"STATSMODELS LOGISTIC REGRESSION (FULL MODEL): Odds Ratios + 95% CI\")\n",
    "print(\"=\" * 110)\n",
    "\n",
    "# Build formula: Passed_num ~ num + C(cat) ...\n",
    "formula_terms = []\n",
    "formula_terms += full_numeric\n",
    "formula_terms += [f\"C({c})\" for c in categorical]\n",
    "\n",
    "formula = \"Passed_num ~ \" + \" + \".join(formula_terms)\n",
    "print(\"\\nFormula:\\n\", formula)\n",
    "\n",
    "# Fit model\n",
    "logit = smf.logit(formula=formula, data=df_m).fit(disp=False)\n",
    "\n",
    "# OR table\n",
    "params = logit.params\n",
    "conf = logit.conf_int()\n",
    "or_table = pd.DataFrame({\n",
    "    \"coef\": params,\n",
    "    \"OR\": np.exp(params),\n",
    "    \"CI_low\": np.exp(conf[0]),\n",
    "    \"CI_high\": np.exp(conf[1]),\n",
    "    \"p\": logit.pvalues\n",
    "}).sort_values(\"p\")\n",
    "\n",
    "print(\"\\nTop predictors (sorted by p-value):\")\n",
    "print(or_table.head(25).to_string(float_format=lambda x: f\"{x:0.4f}\"))\n",
    "\n",
    "# Highlight key S1 effects if present\n",
    "for key in [\"S1_Graph_overall_score\", \"S1_Graph_Node_Connectivity_score\"]:\n",
    "    if key in or_table.index:\n",
    "        r = or_table.loc[key]\n",
    "        print(f\"\\nKEY EFFECT: {key}\")\n",
    "        print(f\"  OR = {r['OR']:.3f}  (95% CI {r['CI_low']:.3f}–{r['CI_high']:.3f}), p={r['p']:.3g}\")\n",
    "\n",
    "# -----------------------\n",
    "# (2) Sklearn: AUC baseline vs full (hold-out split)\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\" * 110)\n",
    "print(\"SKLEARN AUC (Hold-out): Baseline vs Full\")\n",
    "print(\"=\" * 110)\n",
    "\n",
    "X = df_m[baseline_numeric + full_numeric].copy()  # will be overwritten below\n",
    "y = df_m[\"Passed_num\"].values\n",
    "\n",
    "# ColumnTransformer: scale numeric, one-hot categorical\n",
    "def make_pipeline(numeric_cols, categorical_cols):\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numeric_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    clf = LogisticRegression(max_iter=500, solver=\"liblinear\")\n",
    "    return Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_m, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Baseline model\n",
    "pipe_base = make_pipeline(baseline_numeric, categorical)\n",
    "pipe_base.fit(X_train[baseline_numeric + categorical], y_train)\n",
    "p_base = pipe_base.predict_proba(X_test[baseline_numeric + categorical])[:, 1]\n",
    "auc_base = roc_auc_score(y_test, p_base)\n",
    "\n",
    "# Full model\n",
    "pipe_full = make_pipeline(full_numeric, categorical)\n",
    "pipe_full.fit(X_train[full_numeric + categorical], y_train)\n",
    "p_full = pipe_full.predict_proba(X_test[full_numeric + categorical])[:, 1]\n",
    "auc_full = roc_auc_score(y_test, p_full)\n",
    "\n",
    "print(f\"Baseline AUC (complexity + controls): {auc_base:.4f}\")\n",
    "print(f\"Full AUC (+ S1 metrics):             {auc_full:.4f}\")\n",
    "print(f\"Δ AUC:                               {auc_full - auc_base:+.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "# (3) Optional: GroupKFold AUC by Pipeline_ID (stronger evidence)\n",
    "# -----------------------\n",
    "if GROUP_COL in df_m.columns:\n",
    "    print(\"\\n\" + \"=\" * 110)\n",
    "    print(\"GROUPED CV (GroupKFold by Pipeline_ID): AUC Baseline vs Full\")\n",
    "    print(\"=\" * 110)\n",
    "\n",
    "    groups = df_m[GROUP_COL].values\n",
    "    gkf = GroupKFold(n_splits=min(5, df_m[GROUP_COL].nunique()))\n",
    "\n",
    "    # Need X and y in same df order\n",
    "    X_base = df_m[baseline_numeric + categorical]\n",
    "    X_full = df_m[full_numeric + categorical]\n",
    "    y = df_m[\"Passed_num\"].values\n",
    "\n",
    "    # Cross-val scores\n",
    "    aucs_base = cross_val_score(pipe_base, X_base, y, cv=gkf, groups=groups, scoring=\"roc_auc\")\n",
    "    aucs_full = cross_val_score(pipe_full, X_full, y, cv=gkf, groups=groups, scoring=\"roc_auc\")\n",
    "\n",
    "    print(f\"Baseline AUC (GroupKFold) mean±sd: {aucs_base.mean():.4f} ± {aucs_base.std():.4f}\")\n",
    "    print(f\"Full AUC (GroupKFold) mean±sd:     {aucs_full.mean():.4f} ± {aucs_full.std():.4f}\")\n",
    "    print(f\"Δ AUC (mean):                      {aucs_full.mean() - aucs_base.mean():+.4f}\")\n",
    "else:\n",
    "    print(\"\\nNOTE: Pipeline_ID not available; skipping GroupKFold. (Recommended if you have it.)\")\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
