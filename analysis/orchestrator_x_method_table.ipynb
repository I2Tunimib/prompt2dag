{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3421b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8,742 rows, 94 cols\n",
      "\n",
      "==============================================================================================================\n",
      "TABLE O1: Orchestrator × Method (5-method classification; aggregated over LLMs)\n",
      "==============================================================================================================\n",
      "Orchestrator                 Method   N  N_Passed  Pass%         SAT         PCT    Combined  ORT_scaled  TotalIssues_mean  Crit_mean  Major_mean  Minor_mean\n",
      "     airflow Direct (Non-Reasoning) 798       322   40.4 4.02 ± 2.22 4.62 ± 2.67 4.35 ± 2.43 5.75 ± 1.84          7.338346   0.497494    1.897243    4.943609\n",
      "     airflow  Prompt2DAG (Template) 681        60    8.8 0.55 ± 1.78 0.68 ± 2.18 0.62 ± 1.99 5.25 ± 1.09          2.334802   1.116006    0.615272    0.603524\n",
      "     airflow       Prompt2DAG (LLM) 681       369   54.2 5.30 ± 2.55 4.10 ± 3.78 4.72 ± 2.77 6.48 ± 1.64          6.183554   0.547724    1.461087    4.174743\n",
      "     airflow    Prompt2DAG (Hybrid) 681       507   74.4 4.78 ± 2.22 5.30 ± 3.13 5.08 ± 2.55 6.98 ± 1.34          6.640235   0.503671    1.356828    4.779736\n",
      "     airflow     Direct (Reasoning) 228       171   75.0 5.77 ± 1.46 6.68 ± 2.03 6.31 ± 1.72 7.09 ± 1.82          6.956140   0.346491    2.122807    4.486842\n",
      "     dagster Direct (Non-Reasoning) 798       338   42.4 3.84 ± 2.23 4.15 ± 2.48 4.02 ± 2.35 5.80 ± 1.87          6.006266   0.572682    1.892231    3.541353\n",
      "     dagster  Prompt2DAG (Template) 435       291   66.9 7.17 ± 1.31 5.62 ± 3.96 6.44 ± 2.53 6.66 ± 2.05          6.652874   0.390805    3.370115    2.891954\n",
      "     dagster       Prompt2DAG (LLM) 681       531   78.0 5.42 ± 2.83 6.17 ± 3.32 5.82 ± 3.07 7.80 ± 1.76          4.262849   0.552129    0.975037    2.735683\n",
      "     dagster    Prompt2DAG (Hybrid) 681       549   80.6 4.85 ± 2.29 5.33 ± 2.64 5.13 ± 2.45 7.42 ± 1.40          4.214391   0.472834    1.318649    2.422907\n",
      "     dagster     Direct (Reasoning) 228       168   73.7 5.95 ± 1.54 6.29 ± 2.16 6.17 ± 1.77 7.22 ± 1.90          5.653509   0.434211    1.776316    3.442982\n",
      "     prefect Direct (Non-Reasoning) 798       343   43.0 4.25 ± 2.34 4.27 ± 2.37 4.28 ± 2.35 5.79 ± 1.85          6.060150   0.506266    2.249373    3.304511\n",
      "     prefect  Prompt2DAG (Template) 462       444   96.1 6.73 ± 1.43 6.96 ± 1.45 6.90 ± 1.40 7.13 ± 0.97          7.924242   0.411255    3.456710    4.056277\n",
      "     prefect       Prompt2DAG (LLM) 681       537   78.9 5.60 ± 2.86 5.51 ± 2.88 5.59 ± 2.87 7.21 ± 1.51          5.628488   0.547724    1.889868    3.190896\n",
      "     prefect    Prompt2DAG (Hybrid) 681       558   81.9 5.49 ± 2.55 5.78 ± 2.73 5.67 ± 2.64 7.58 ± 1.48          4.422907   0.534508    1.409692    2.478708\n",
      "     prefect     Direct (Reasoning) 228       165   72.4 6.26 ± 1.61 5.85 ± 2.05 6.12 ± 1.76 6.83 ± 1.82          6.289474   0.491228    2.394737    3.403509\n",
      "\n",
      "==============================================================================================================\n",
      "OPTIONAL WIDE TABLES (Orchestrator rows × Method cols)\n",
      "==============================================================================================================\n",
      "\n",
      "Pass rate (%):\n",
      "Method       Direct (Non-Reasoning) Prompt2DAG (Template) Prompt2DAG (LLM) Prompt2DAG (Hybrid) Direct (Reasoning)\n",
      "Orchestrator                                                                                                     \n",
      "airflow                       40.4%                  8.8%            54.2%               74.4%              75.0%\n",
      "dagster                       42.4%                 66.9%            78.0%               80.6%              73.7%\n",
      "prefect                       43.0%                 96.1%            78.9%               81.9%              72.4%\n",
      "\n",
      "ORT_scaled (mean ± sd):\n",
      "Method       Direct (Non-Reasoning) Prompt2DAG (Template) Prompt2DAG (LLM) Prompt2DAG (Hybrid) Direct (Reasoning)\n",
      "Orchestrator                                                                                                     \n",
      "airflow                 5.75 ± 1.84           5.25 ± 1.09      6.48 ± 1.64         6.98 ± 1.34        7.09 ± 1.82\n",
      "dagster                 5.80 ± 1.87           6.66 ± 2.05      7.80 ± 1.76         7.42 ± 1.40        7.22 ± 1.90\n",
      "prefect                 5.79 ± 1.85           7.13 ± 0.97      7.21 ± 1.51         7.58 ± 1.48        6.83 ± 1.82\n",
      "\n",
      "Combined_Score (mean ± sd):\n",
      "Method       Direct (Non-Reasoning) Prompt2DAG (Template) Prompt2DAG (LLM) Prompt2DAG (Hybrid) Direct (Reasoning)\n",
      "Orchestrator                                                                                                     \n",
      "airflow                 4.35 ± 2.43           0.62 ± 1.99      4.72 ± 2.77         5.08 ± 2.55        6.31 ± 1.72\n",
      "dagster                 4.02 ± 2.35           6.44 ± 2.53      5.82 ± 3.07         5.13 ± 2.45        6.17 ± 1.77\n",
      "prefect                 4.28 ± 2.35           6.90 ± 1.40      5.59 ± 2.87         5.67 ± 2.64        6.12 ± 1.76\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "orchestrator_x_method_table.py\n",
    "\n",
    "Creates ONE paper-ready table showing how the 5 methods perform across the 3 orchestrators\n",
    "using all_sessions_cleaned.csv.\n",
    "\n",
    "Output (default): 15-row table (Orchestrator × Method) with:\n",
    "N, Pass%, SAT, PCT, Combined, ORT_scaled, Issues (Total/Crit/Major/Minor)\n",
    "\n",
    "Also prints an optional wide pivot (Orchestrator rows, Method columns) for Pass% / ORT / Combined.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "CSV_PATH = \"/Users/abubakarialidu/Desktop/Data Result/all_sessions_cleaned.csv\"\n",
    "\n",
    "METHOD_ORDER = [\n",
    "    \"Direct (Non-Reasoning)\",\n",
    "    \"Prompt2DAG (Template)\",\n",
    "    \"Prompt2DAG (LLM)\",\n",
    "    \"Prompt2DAG (Hybrid)\",\n",
    "    \"Direct (Reasoning)\",\n",
    "]\n",
    "\n",
    "ORCH_ORDER = [\"airflow\", \"dagster\", \"prefect\"]\n",
    "\n",
    "# ORT penalty weights (match your main analysis)\n",
    "ALPHA_CRIT = 2.0\n",
    "BETA_MAJOR = 1.0\n",
    "GAMMA_MINOR = 0.25\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 220)\n",
    "\n",
    "# -----------------------------\n",
    "# Load\n",
    "# -----------------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Loaded {len(df):,} rows, {len(df.columns)} cols\")\n",
    "\n",
    "# Normalize orchestrator labels\n",
    "if \"Orchestrator\" not in df.columns:\n",
    "    raise ValueError(\"Missing column: Orchestrator\")\n",
    "df[\"Orchestrator\"] = df[\"Orchestrator\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Ensure Passed is boolean-ish\n",
    "if \"Passed\" not in df.columns:\n",
    "    raise ValueError(\"Missing column: Passed\")\n",
    "if df[\"Passed\"].dtype != bool:\n",
    "    # handles 0/1, \"True\"/\"False\", etc.\n",
    "    df[\"Passed\"] = df[\"Passed\"].astype(str).str.lower().map({\"true\": True, \"false\": False, \"1\": True, \"0\": False})\n",
    "\n",
    "# -----------------------------\n",
    "# 5-method classification\n",
    "# -----------------------------\n",
    "def classify_method(row):\n",
    "    workflow = row.get(\"Workflow\", \"\")\n",
    "    strategy = str(row.get(\"Strategy\") or \"\").lower()\n",
    "    if workflow == \"Direct\":\n",
    "        return \"Direct (Non-Reasoning)\"\n",
    "    elif workflow == \"Reasoning\":\n",
    "        return \"Direct (Reasoning)\"\n",
    "    elif workflow == \"Prompt2DAG\":\n",
    "        if \"template\" in strategy:\n",
    "            return \"Prompt2DAG (Template)\"\n",
    "        elif \"llm\" in strategy:\n",
    "            return \"Prompt2DAG (LLM)\"\n",
    "        elif \"hybrid\" in strategy:\n",
    "            return \"Prompt2DAG (Hybrid)\"\n",
    "        else:\n",
    "            return f\"Prompt2DAG ({row.get('Strategy','Unknown')})\"\n",
    "    else:\n",
    "        return workflow\n",
    "\n",
    "df[\"Method\"] = df.apply(classify_method, axis=1)\n",
    "df = df[df[\"Method\"].isin(METHOD_ORDER)].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Ensure issues + scores exist\n",
    "# -----------------------------\n",
    "for c in [\"Static_Score\", \"Compliance_Score\", \"Combined_Score\"]:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing column: {c}\")\n",
    "\n",
    "for c in [\"Critical_Issues\", \"Major_Issues\", \"Minor_Issues\"]:\n",
    "    if c not in df.columns:\n",
    "        df[c] = 0\n",
    "    df[c] = df[c].fillna(0)\n",
    "\n",
    "df[\"Total_Issues\"] = df[\"Critical_Issues\"] + df[\"Major_Issues\"] + df[\"Minor_Issues\"]\n",
    "\n",
    "# -----------------------------\n",
    "# ORT (match your earlier approach: raw then min-max scaled to [0,10])\n",
    "# -----------------------------\n",
    "df[\"Base_Score\"] = np.where(df[\"Passed\"] == True, df[\"Combined_Score\"], 0.0)\n",
    "df[\"Penalty\"] = (\n",
    "    ALPHA_CRIT * df[\"Critical_Issues\"]\n",
    "    + BETA_MAJOR * df[\"Major_Issues\"]\n",
    "    + GAMMA_MINOR * df[\"Minor_Issues\"]\n",
    ")\n",
    "df[\"ORT_raw\"] = df[\"Base_Score\"] - df[\"Penalty\"]\n",
    "\n",
    "ort_min = df[\"ORT_raw\"].min()\n",
    "ort_max = df[\"ORT_raw\"].max()\n",
    "df[\"ORT_scaled\"] = 0.0\n",
    "if ort_max > ort_min:\n",
    "    df[\"ORT_scaled\"] = 10.0 * (df[\"ORT_raw\"] - ort_min) / (ort_max - ort_min)\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def mean_sd_str(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    if len(x) == 0:\n",
    "        return \"NA\"\n",
    "    return f\"{x.mean():.2f} ± {x.std(ddof=1):.2f}\"\n",
    "\n",
    "def pct_str(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").dropna()\n",
    "    if len(x) == 0:\n",
    "        return \"NA\"\n",
    "    return f\"{100*x.mean():.1f}%\"\n",
    "\n",
    "# -----------------------------\n",
    "# SINGLE TABLE (15 rows): Orchestrator × Method\n",
    "# -----------------------------\n",
    "grp = df.groupby([\"Orchestrator\", \"Method\"], observed=True)\n",
    "\n",
    "table = grp.agg(\n",
    "    N=(\"Passed\", \"size\"),\n",
    "    N_Passed=(\"Passed\", \"sum\"),\n",
    "    Pass_Rate=(\"Passed\", \"mean\"),\n",
    "    SAT_mean=(\"Static_Score\", \"mean\"),\n",
    "    SAT_sd=(\"Static_Score\", \"std\"),\n",
    "    PCT_mean=(\"Compliance_Score\", \"mean\"),\n",
    "    PCT_sd=(\"Compliance_Score\", \"std\"),\n",
    "    Combined_mean=(\"Combined_Score\", \"mean\"),\n",
    "    Combined_sd=(\"Combined_Score\", \"std\"),\n",
    "    ORT_mean=(\"ORT_scaled\", \"mean\"),\n",
    "    ORT_sd=(\"ORT_scaled\", \"std\"),\n",
    "    TotalIssues_mean=(\"Total_Issues\", \"mean\"),\n",
    "    Crit_mean=(\"Critical_Issues\", \"mean\"),\n",
    "    Major_mean=(\"Major_Issues\", \"mean\"),\n",
    "    Minor_mean=(\"Minor_Issues\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "# format\n",
    "table[\"Pass%\"] = (100 * table[\"Pass_Rate\"]).round(1)\n",
    "table[\"SAT\"] = table.apply(lambda r: f\"{r['SAT_mean']:.2f} ± {r['SAT_sd']:.2f}\", axis=1)\n",
    "table[\"PCT\"] = table.apply(lambda r: f\"{r['PCT_mean']:.2f} ± {r['PCT_sd']:.2f}\", axis=1)\n",
    "table[\"Combined\"] = table.apply(lambda r: f\"{r['Combined_mean']:.2f} ± {r['Combined_sd']:.2f}\", axis=1)\n",
    "table[\"ORT_scaled\"] = table.apply(lambda r: f\"{r['ORT_mean']:.2f} ± {r['ORT_sd']:.2f}\", axis=1)\n",
    "\n",
    "# Keep paper columns\n",
    "table_out = table[[\n",
    "    \"Orchestrator\", \"Method\", \"N\", \"N_Passed\", \"Pass%\", \"SAT\", \"PCT\", \"Combined\", \"ORT_scaled\",\n",
    "    \"TotalIssues_mean\", \"Crit_mean\", \"Major_mean\", \"Minor_mean\"\n",
    "]].copy()\n",
    "\n",
    "# ordering\n",
    "table_out[\"Orchestrator\"] = pd.Categorical(table_out[\"Orchestrator\"], ORCH_ORDER, ordered=True)\n",
    "table_out[\"Method\"] = pd.Categorical(table_out[\"Method\"], METHOD_ORDER, ordered=True)\n",
    "table_out = table_out.sort_values([\"Orchestrator\", \"Method\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"TABLE O1: Orchestrator × Method (5-method classification; aggregated over LLMs)\")\n",
    "print(\"=\"*110)\n",
    "print(table_out.to_string(index=False))\n",
    "\n",
    "# -----------------------------\n",
    "# OPTIONAL: wide pivot versions (nice for a compact paper table)\n",
    "# -----------------------------\n",
    "def make_wide(metric_col, fmt=None):\n",
    "    t = grp[metric_col].agg([\"mean\", \"std\", \"size\"]).reset_index()\n",
    "    if fmt is None:\n",
    "        t[\"val\"] = t.apply(lambda r: f\"{r['mean']:.2f} ± {r['std']:.2f}\", axis=1)\n",
    "    else:\n",
    "        t[\"val\"] = t[\"mean\"].map(fmt)\n",
    "    wide = t.pivot(index=\"Orchestrator\", columns=\"Method\", values=\"val\")\n",
    "    wide = wide.reindex(index=ORCH_ORDER, columns=METHOD_ORDER)\n",
    "    return wide\n",
    "\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"OPTIONAL WIDE TABLES (Orchestrator rows × Method cols)\")\n",
    "print(\"=\"*110)\n",
    "\n",
    "pass_wide = grp[\"Passed\"].mean().reset_index()\n",
    "pass_wide[\"val\"] = (100 * pass_wide[\"Passed\"]).map(lambda v: f\"{v:.1f}%\")\n",
    "pass_wide = pass_wide.pivot(index=\"Orchestrator\", columns=\"Method\", values=\"val\").reindex(index=ORCH_ORDER, columns=METHOD_ORDER)\n",
    "\n",
    "print(\"\\nPass rate (%):\")\n",
    "print(pass_wide.to_string())\n",
    "\n",
    "print(\"\\nORT_scaled (mean ± sd):\")\n",
    "print(make_wide(\"ORT_scaled\").to_string())\n",
    "\n",
    "print(\"\\nCombined_Score (mean ± sd):\")\n",
    "print(make_wide(\"Combined_Score\").to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
