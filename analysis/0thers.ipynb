{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ead9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "RUN COUNT RECONCILIATION\n",
      "========================================================================================================================\n",
      "\n",
      "[1] Total rows: 8742\n",
      "Pipelines: 38\n",
      "Orchestrators: 3 ['airflow', 'dagster', 'prefect']\n",
      "Methods: 5 ['Direct (Non-Reasoning)', 'Prompt2DAG (Template)', 'Prompt2DAG (LLM)', 'Prompt2DAG (Hybrid)', 'Direct (Reasoning)']\n",
      "\n",
      "[2] Rows per Method\n",
      "Method\n",
      "Direct (Non-Reasoning)    2394\n",
      "Prompt2DAG (Template)     1578\n",
      "Prompt2DAG (LLM)          2043\n",
      "Prompt2DAG (Hybrid)       2043\n",
      "Direct (Reasoning)         684\n",
      "\n",
      "[3] Factorial grid (under stated assumptions)\n",
      "Standard LLMs observed: 7\n",
      "Reasoning LLMs observed: 2\n",
      "Ideal total runs if fully populated = 10,260\n",
      "Observed total runs                 = 8,742\n",
      "Missing vs ideal                    = 1,518\n",
      "\n",
      "[4] Coverage by Method × LLM (expected rows per LLM if complete = 114 pipe×orch × 3 reps = 342)\n",
      "                Method                        LLM_for_Workflow   N  Expected_N  Missing_rows\n",
      "Direct (Non-Reasoning)               deepinfra-claude-4-sonnet 342         342             0\n",
      "Direct (Non-Reasoning)                   deepinfra-deepseek_ai 342         342             0\n",
      "Direct (Non-Reasoning)                    deepinfra-meta_llama 342         342             0\n",
      "Direct (Non-Reasoning)                 deepinfra-microsoft_phi 342         342             0\n",
      "Direct (Non-Reasoning)                deepinfra-mistralaiSmall 342         342             0\n",
      "Direct (Non-Reasoning)                          deepinfra-qwen 342         342             0\n",
      "Direct (Non-Reasoning)                         deepinfra-qwen3 342         342             0\n",
      "    Direct (Reasoning) deepinfra-Qwen3-235B-A22B-Thinking-2507 342         342             0\n",
      "    Direct (Reasoning)                deepinfra-gemini-2.5-pro 342         342             0\n",
      "   Prompt2DAG (Hybrid)                 deepinfra-microsoft_phi 225         342           117\n",
      "   Prompt2DAG (Hybrid)                   deepinfra-deepseek_ai 261         342            81\n",
      "   Prompt2DAG (Hybrid)                    deepinfra-meta_llama 279         342            63\n",
      "   Prompt2DAG (Hybrid)                          deepinfra-qwen 288         342            54\n",
      "   Prompt2DAG (Hybrid)                deepinfra-mistralaiSmall 315         342            27\n",
      "   Prompt2DAG (Hybrid)               deepinfra-claude-4-sonnet 333         342             9\n",
      "   Prompt2DAG (Hybrid)                         deepinfra-qwen3 342         342             0\n",
      "      Prompt2DAG (LLM)                 deepinfra-microsoft_phi 225         342           117\n",
      "      Prompt2DAG (LLM)                   deepinfra-deepseek_ai 261         342            81\n",
      "      Prompt2DAG (LLM)                    deepinfra-meta_llama 279         342            63\n",
      "      Prompt2DAG (LLM)                          deepinfra-qwen 288         342            54\n",
      "      Prompt2DAG (LLM)                deepinfra-mistralaiSmall 315         342            27\n",
      "      Prompt2DAG (LLM)               deepinfra-claude-4-sonnet 333         342             9\n",
      "      Prompt2DAG (LLM)                         deepinfra-qwen3 342         342             0\n",
      " Prompt2DAG (Template)                 deepinfra-microsoft_phi 147         342           195\n",
      " Prompt2DAG (Template)                   deepinfra-deepseek_ai 186         342           156\n",
      " Prompt2DAG (Template)                    deepinfra-meta_llama 204         342           138\n",
      " Prompt2DAG (Template)                          deepinfra-qwen 210         342           132\n",
      " Prompt2DAG (Template)                deepinfra-mistralaiSmall 240         342           102\n",
      " Prompt2DAG (Template)               deepinfra-claude-4-sonnet 249         342            93\n",
      " Prompt2DAG (Template)                         deepinfra-qwen3 342         342             0\n",
      "\n",
      "[5] Coverage by Method × Orchestrator\n",
      "                Method Orchestrator   N\n",
      "Direct (Non-Reasoning)      airflow 798\n",
      "Direct (Non-Reasoning)      dagster 798\n",
      "Direct (Non-Reasoning)      prefect 798\n",
      "    Direct (Reasoning)      airflow 228\n",
      "    Direct (Reasoning)      dagster 228\n",
      "    Direct (Reasoning)      prefect 228\n",
      "   Prompt2DAG (Hybrid)      airflow 681\n",
      "   Prompt2DAG (Hybrid)      dagster 681\n",
      "   Prompt2DAG (Hybrid)      prefect 681\n",
      "      Prompt2DAG (LLM)      airflow 681\n",
      "      Prompt2DAG (LLM)      dagster 681\n",
      "      Prompt2DAG (LLM)      prefect 681\n",
      " Prompt2DAG (Template)      airflow 681\n",
      " Prompt2DAG (Template)      dagster 435\n",
      " Prompt2DAG (Template)      prefect 462\n",
      "\n",
      "[6] Repeat count distribution per (pipeline, orch, method, llm) cell\n",
      "n_repeats_observed\n",
      "3    2914\n",
      "\n",
      "[7] Incomplete cells (<3 repeats): 0\n",
      "\n",
      "[8] Missing pipeline×orchestrator pairs per Method×LLM (cells with 0 runs)\n",
      "               Method          LLM_for_Workflow  Missing_pipe_orch_pairs\n",
      "Prompt2DAG (Template)   deepinfra-microsoft_phi                       65\n",
      "Prompt2DAG (Template)     deepinfra-deepseek_ai                       52\n",
      "Prompt2DAG (Template)      deepinfra-meta_llama                       46\n",
      "Prompt2DAG (Template)            deepinfra-qwen                       44\n",
      "  Prompt2DAG (Hybrid)   deepinfra-microsoft_phi                       39\n",
      "     Prompt2DAG (LLM)   deepinfra-microsoft_phi                       39\n",
      "Prompt2DAG (Template)  deepinfra-mistralaiSmall                       34\n",
      "Prompt2DAG (Template) deepinfra-claude-4-sonnet                       31\n",
      "  Prompt2DAG (Hybrid)     deepinfra-deepseek_ai                       27\n",
      "     Prompt2DAG (LLM)     deepinfra-deepseek_ai                       27\n",
      "  Prompt2DAG (Hybrid)      deepinfra-meta_llama                       21\n",
      "     Prompt2DAG (LLM)      deepinfra-meta_llama                       21\n",
      "  Prompt2DAG (Hybrid)            deepinfra-qwen                       18\n",
      "     Prompt2DAG (LLM)            deepinfra-qwen                       18\n",
      "  Prompt2DAG (Hybrid)  deepinfra-mistralaiSmall                        9\n",
      "     Prompt2DAG (LLM)  deepinfra-mistralaiSmall                        9\n",
      "  Prompt2DAG (Hybrid) deepinfra-claude-4-sonnet                        3\n",
      "     Prompt2DAG (LLM) deepinfra-claude-4-sonnet                        3\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 250)\n",
    "pd.set_option(\"display.width\", 220)\n",
    "\n",
    "CSV = \"/Users/abubakarialidu/Desktop/Data Result/all_sessions_cleaned.csv\"\n",
    "\n",
    "METHOD_ORDER = [\n",
    "    \"Direct (Non-Reasoning)\",\n",
    "    \"Prompt2DAG (Template)\",\n",
    "    \"Prompt2DAG (LLM)\",\n",
    "    \"Prompt2DAG (Hybrid)\",\n",
    "    \"Direct (Reasoning)\",\n",
    "]\n",
    "\n",
    "ORCH_ORDER = [\"airflow\", \"dagster\", \"prefect\"]\n",
    "\n",
    "def classify_method(row):\n",
    "    workflow = row.get(\"Workflow\", \"\")\n",
    "    strategy = str(row.get(\"Strategy\") or \"\").lower()\n",
    "    if workflow == \"Direct\":\n",
    "        return \"Direct (Non-Reasoning)\"\n",
    "    if workflow == \"Reasoning\":\n",
    "        return \"Direct (Reasoning)\"\n",
    "    if workflow == \"Prompt2DAG\":\n",
    "        if \"template\" in strategy:\n",
    "            return \"Prompt2DAG (Template)\"\n",
    "        if \"llm\" in strategy:\n",
    "            return \"Prompt2DAG (LLM)\"\n",
    "        if \"hybrid\" in strategy:\n",
    "            return \"Prompt2DAG (Hybrid)\"\n",
    "        return f\"Prompt2DAG ({row.get('Strategy','Unknown')})\"\n",
    "    return workflow\n",
    "\n",
    "def normalize_llm_name(x):\n",
    "    if pd.isna(x):\n",
    "        return \"unknown\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"deepinfra:\", \"deepinfra-\")\n",
    "    s = s.replace(\":\", \"-\")\n",
    "    return s\n",
    "\n",
    "def infer_repeat_id(row):\n",
    "    \"\"\"\n",
    "    Best-effort extraction of a repetition index from Run_Name (or similar).\n",
    "    If you have an explicit repeat/seed column, replace this with it.\n",
    "    \"\"\"\n",
    "    rn = str(row.get(\"Run_Name\", \"\") or \"\")\n",
    "    m = re.search(r\"(?:rep|repeat|run|trial)[\\-_ ]?(\\d+)\\b\", rn.lower())\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    # fallback: use Session+Run_Name uniqueness (still allows counting repeats via group sizes)\n",
    "    return np.nan\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "\n",
    "# Basic normalization\n",
    "df[\"Method\"] = df.apply(classify_method, axis=1)\n",
    "df = df[df[\"Method\"].isin(METHOD_ORDER)].copy()\n",
    "\n",
    "df[\"Orchestrator\"] = df[\"Orchestrator\"].astype(str).str.lower().str.strip()\n",
    "df[\"Pipeline_ID\"] = df[\"Pipeline_ID\"].astype(str)\n",
    "\n",
    "# LLM used in the workflow (Std for non-reasoning and Prompt2DAG; Reasoning_LLM for Direct Reasoning)\n",
    "df[\"Std_LLM\"] = df.get(\"Std_LLM\", \"unknown\")\n",
    "df[\"Reasoning_LLM\"] = df.get(\"Reasoning_LLM\", \"unknown\")\n",
    "\n",
    "df[\"LLM_for_Workflow\"] = np.where(\n",
    "    df[\"Method\"] == \"Direct (Reasoning)\",\n",
    "    df[\"Reasoning_LLM\"].map(normalize_llm_name),\n",
    "    df[\"Std_LLM\"].map(normalize_llm_name),\n",
    ")\n",
    "\n",
    "# Optional: infer repeat IDs from names if present\n",
    "df[\"Repeat_ID_guess\"] = df.apply(infer_repeat_id, axis=1)\n",
    "\n",
    "print(\"=\" * 120)\n",
    "print(\"RUN COUNT RECONCILIATION\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# 1) Basic totals\n",
    "print(\"\\n[1] Total rows:\", len(df))\n",
    "print(\"Pipelines:\", df[\"Pipeline_ID\"].nunique())\n",
    "print(\"Orchestrators:\", df[\"Orchestrator\"].nunique(), sorted(df[\"Orchestrator\"].unique()))\n",
    "print(\"Methods:\", df[\"Method\"].nunique(), METHOD_ORDER)\n",
    "\n",
    "# 2) Counts by method (should match your paper tables)\n",
    "method_counts = df[\"Method\"].value_counts().reindex(METHOD_ORDER)\n",
    "print(\"\\n[2] Rows per Method\")\n",
    "print(method_counts.to_string())\n",
    "\n",
    "# 3) Show the “ideal” factorial size under your stated design assumptions\n",
    "#    - standard LLMs apply to Direct (Non-Reasoning) + Prompt2DAG methods\n",
    "#    - reasoning LLMs apply only to Direct (Reasoning)\n",
    "std_llms = sorted(df[df[\"Method\"] != \"Direct (Reasoning)\"][\"LLM_for_Workflow\"].unique())\n",
    "rsn_llms = sorted(df[df[\"Method\"] == \"Direct (Reasoning)\"][\"LLM_for_Workflow\"].unique())\n",
    "\n",
    "n_pipes = df[\"Pipeline_ID\"].nunique()\n",
    "n_orch = df[\"Orchestrator\"].nunique()\n",
    "n_reps_assumed = 3  # your stated repetition count\n",
    "\n",
    "n_methods_std = 4  # Direct(NR) + 3 Prompt2DAG variants\n",
    "n_methods_rsn = 1  # Direct(Reasoning)\n",
    "\n",
    "ideal_total = (len(std_llms) * n_methods_std * n_orch * n_pipes * n_reps_assumed) + \\\n",
    "              (len(rsn_llms) * n_methods_rsn * n_orch * n_pipes * n_reps_assumed)\n",
    "\n",
    "print(\"\\n[3] Factorial grid (under stated assumptions)\")\n",
    "print(f\"Standard LLMs observed: {len(std_llms)}\")\n",
    "print(f\"Reasoning LLMs observed: {len(rsn_llms)}\")\n",
    "print(f\"Ideal total runs if fully populated = {ideal_total:,}\")\n",
    "print(f\"Observed total runs                 = {len(df):,}\")\n",
    "print(f\"Missing vs ideal                    = {ideal_total - len(df):,}\")\n",
    "\n",
    "# 4) Coverage completeness by (Method × LLM): expected = 3 orch × 38 pipes × 3 reps = 342 per LLM if complete\n",
    "#    We compute expected from the global pipeline×orchestrator set to avoid assuming 38/3 if filters exist.\n",
    "pipe_orch = df[[\"Pipeline_ID\", \"Orchestrator\"]].drop_duplicates()\n",
    "expected_pipe_orch = len(pipe_orch)  # typically 38*3 = 114\n",
    "expected_per_llm = expected_pipe_orch * n_reps_assumed\n",
    "\n",
    "print(\"\\n[4] Coverage by Method × LLM (expected rows per LLM if complete = \"\n",
    "      f\"{expected_pipe_orch} pipe×orch × {n_reps_assumed} reps = {expected_per_llm})\")\n",
    "\n",
    "mx = (\n",
    "    df.groupby([\"Method\", \"LLM_for_Workflow\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"N\")\n",
    ")\n",
    "mx[\"Expected_N\"] = np.where(\n",
    "    mx[\"Method\"] == \"Direct (Reasoning)\",\n",
    "    expected_per_llm,   # applies to reasoning llms only; still same expected per LLM\n",
    "    expected_per_llm\n",
    ")\n",
    "mx[\"Missing_rows\"] = mx[\"Expected_N\"] - mx[\"N\"]\n",
    "\n",
    "# show largest deficits first\n",
    "mx_sorted = mx.sort_values([\"Method\", \"Missing_rows\"], ascending=[True, False])\n",
    "print(mx_sorted.to_string(index=False))\n",
    "\n",
    "# 5) Coverage by Method × Orchestrator (to see if missingness is orchestrator-skewed)\n",
    "print(\"\\n[5] Coverage by Method × Orchestrator\")\n",
    "mo = (\n",
    "    df.groupby([\"Method\", \"Orchestrator\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"N\")\n",
    "      .sort_values([\"Method\", \"Orchestrator\"])\n",
    ")\n",
    "print(mo.to_string(index=False))\n",
    "\n",
    "# 6) Repeat count distribution per configuration cell (Pipeline × Orchestrator × Method × LLM)\n",
    "cell = [\"Pipeline_ID\", \"Orchestrator\", \"Method\", \"LLM_for_Workflow\"]\n",
    "cell_counts = df.groupby(cell).size().reset_index(name=\"n_repeats_observed\")\n",
    "\n",
    "print(\"\\n[6] Repeat count distribution per (pipeline, orch, method, llm) cell\")\n",
    "rep_dist = cell_counts[\"n_repeats_observed\"].value_counts().sort_index()\n",
    "print(rep_dist.to_string())\n",
    "\n",
    "# 7) Identify incomplete cells (less than 3 repeats)\n",
    "incomplete = cell_counts[cell_counts[\"n_repeats_observed\"] < n_reps_assumed].copy()\n",
    "print(\"\\n[7] Incomplete cells (<3 repeats):\", len(incomplete))\n",
    "if len(incomplete) > 0:\n",
    "    # show a small sample and aggregate counts by method/LLM to diagnose\n",
    "    print(\"\\nSample incomplete cells:\")\n",
    "    print(incomplete.head(20).to_string(index=False))\n",
    "\n",
    "    print(\"\\nIncomplete-cell counts by Method:\")\n",
    "    print(incomplete[\"Method\"].value_counts().reindex(METHOD_ORDER).fillna(0).astype(int).to_string())\n",
    "\n",
    "    print(\"\\nIncomplete-cell counts by Method × LLM (top 20):\")\n",
    "    top_incomp = (\n",
    "        incomplete.groupby([\"Method\", \"LLM_for_Workflow\"]).size().reset_index(name=\"n_cells\")\n",
    "        .sort_values(\"n_cells\", ascending=False)\n",
    "        .head(20)\n",
    "    )\n",
    "    print(top_incomp.to_string(index=False))\n",
    "\n",
    "# 8) Identify missing pipe×orch pairs per (Method×LLM): i.e., cells with 0 runs (not present at all)\n",
    "print(\"\\n[8] Missing pipeline×orchestrator pairs per Method×LLM (cells with 0 runs)\")\n",
    "full_pairs = set(map(tuple, pipe_orch.values.tolist()))\n",
    "\n",
    "missing_rows = []\n",
    "for (m, llm), sub in df.groupby([\"Method\", \"LLM_for_Workflow\"]):\n",
    "    present_pairs = set(map(tuple, sub[[\"Pipeline_ID\", \"Orchestrator\"]].drop_duplicates().values.tolist()))\n",
    "    missing_pairs = full_pairs - present_pairs\n",
    "    if missing_pairs:\n",
    "        missing_rows.append({\n",
    "            \"Method\": m,\n",
    "            \"LLM_for_Workflow\": llm,\n",
    "            \"Missing_pipe_orch_pairs\": len(missing_pairs),\n",
    "        })\n",
    "\n",
    "missing_pairs_df = pd.DataFrame(missing_rows).sort_values(\n",
    "    [\"Missing_pipe_orch_pairs\", \"Method\"], ascending=[False, True]\n",
    ")\n",
    "print(missing_pairs_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
