metadata:
  target_orchestrator: airflow
  generated_at: 2025-11-28 15:51:04.413764
  source_analysis_file: 
    Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_sensor_gated_02_database_partition_check.py_description.txt
  pipeline_name: database_partition_check_etl
  pipeline_description: A sensor-gated daily ETL pipeline that waits for database partition availability before 
    extracting, transforming, and loading incremental orders data.
  orchestrator_specific: {}
schedule:
  enabled: true
  schedule_expression: '@daily'
  start_date: '2024-01-01T00:00:00Z'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: database_conn
    conn_type: generic
    description: Database Connection
    config:
      host: db-host.example.com
      port: 5432
      database: orders_db
      schema: public
      base_path:
      base_url:
      protocol: jdbc
      bucket:
      queue_name:
      login: DB_USER
      password: DB_PASSWORD
tasks:
  - task_id: wait_for_partition
    task_name: Wait for Database Partition
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: wait_for_partition
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids: []
    trigger_rule: all_success
    retries: 3
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: extract_incremental_orders
    task_name: Extract Incremental Orders
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: extract_incremental_orders
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - wait_for_partition
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: transform_orders_data
    task_name: Transform Orders Data
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: transform_orders_data
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - extract_incremental_orders
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: load_orders_to_warehouse
    task_name: Load Orders to Warehouse
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: load_orders_to_warehouse
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - transform_orders_data
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
