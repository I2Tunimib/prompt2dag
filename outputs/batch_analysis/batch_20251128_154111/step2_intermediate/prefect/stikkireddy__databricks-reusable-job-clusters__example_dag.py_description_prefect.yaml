metadata:
  target_orchestrator: prefect
  generated_at: 2025-11-28 15:45:44.941196
  source_analysis_file: 
    Pipeline_Description_Dataset/stikkireddy__databricks-reusable-job-clusters__example_dag.py_description.txt
  pipeline_name: test_dbx_aws_dag_reuse
  pipeline_description: This pipeline orchestrates Databricks notebook executions with conditional branching logic and 
    cluster reuse capabilities
  orchestrator_specific:
    flow_name: test_dbx_aws_dag_reuse
    deployment_name: test_dbx_aws_dag_reuse_deployment
    work_pool: default-agent-pool
    task_runner: SequentialTaskRunner
    prefect_version: 2.14.0
schedule:
  enabled: false
  schedule_expression:
  start_date: '2023-06-06T00:00:00'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: databricks_api_connection
    conn_type: Secret
    description: Databricks API Connection
    config:
      block_type: Secret
      block_module: prefect.blocks.system
      block_name: databricks_api_connection
      config:
        base_url: https://dbc-xxxxxxxx-xxxx.cloud.databricks.com
        host: dbc-xxxxxxxx-xxxx.cloud.databricks.com
        port:
        protocol: https
        database:
        schema:
        bucket:
        queue_name:
        token_secret_name: DATABRICKS_TOKEN
  - conn_id: databricks_secrets_store
    conn_type: Secret
    description: Databricks Secrets Store
    config:
      block_type: Secret
      block_module: prefect.blocks.system
      block_name: databricks_secrets_store
      config:
        base_path:
        base_url:
        host:
        port:
        protocol:
        database:
        schema:
        bucket:
        queue_name:
        token_secret_name: DATABRICKS_TOKEN
tasks:
  - task_id: initialize_pipeline
    task_name: Initialize Pipeline
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: initialize_pipeline
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config: {}
      retries: 1
      retry_delay_seconds: 300
    upstream_task_ids: []
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: execute_databricks_notebook
    task_name: Execute Databricks Notebook
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: execute_databricks_notebook
    config:
      task_decorator: '@task'
      infrastructure:
        config: {}
      retries: 1
      retry_delay_seconds: 300
    upstream_task_ids:
      - initialize_pipeline
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: intermediate_step
    task_name: Intermediate Step
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: intermediate_step
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config: {}
      retries: 1
      retry_delay_seconds: 300
    upstream_task_ids:
      - execute_databricks_notebook
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: branch_decision
    task_name: Branch Decision
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: branch_decision
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: branch_func
      retries: 1
      retry_delay_seconds: 300
    upstream_task_ids:
      - intermediate_step
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: terminal_branch
    task_name: Terminal Branch
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: terminal_branch
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config: {}
      retries: 1
      retry_delay_seconds: 300
    upstream_task_ids:
      - branch_decision
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: execute_secondary_notebook
    task_name: Execute Secondary Databricks Notebook
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: execute_secondary_notebook
    config:
      task_decorator: '@task'
      infrastructure:
        config: {}
      retries: 1
      retry_delay_seconds: 300
    upstream_task_ids:
      - branch_decision
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: pre_completion_step
    task_name: Pre-Completion Step
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: pre_completion_step
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config: {}
      retries: 1
      retry_delay_seconds: 300
    upstream_task_ids:
      - execute_secondary_notebook
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: complete_pipeline
    task_name: Complete Pipeline
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: complete_pipeline
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config: {}
      retries: 1
      retry_delay_seconds: 300
    upstream_task_ids:
      - pre_completion_step
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
