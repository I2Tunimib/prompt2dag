{
  "metadata": {
    "schema_version": "1.0",
    "analysis_timestamp": "2025-11-28T15:46:02.328289",
    "source_file": "Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_branch_merge_02_backup_strategy_selector.py_description.txt",
    "llm_provider": "deepinfra",
    "llm_model": "Qwen3-Coder",
    "analysis_results": {
      "detected_patterns": [
        "sequential",
        "branching"
      ],
      "task_executors_used": [
        "python",
        "bash"
      ],
      "has_branching": true,
      "has_parallelism": false,
      "has_sensors": false,
      "total_components": 6,
      "complexity_score": "medium"
    },
    "orchestrator_compatibility": {
      "airflow": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential pattern fully supported",
          "Branching via BranchPythonOperator"
        ]
      },
      "prefect": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential flow with task dependencies",
          "Conditional logic via Python control flow"
        ]
      },
      "dagster": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Op graph with dependencies",
          "Dynamic graphs or branching ops"
        ]
      }
    },
    "validation_warnings": []
  },
  "pipeline_summary": {
    "name": "Backup Strategy Selector",
    "description": "[Backup Strategy Selector] - Comprehensive Pipeline Description. This DAG implements a branch-merge pattern for automated database backup strategy selection based on day of week.",
    "flow_patterns": [
      "sequential",
      "branching"
    ],
    "task_executors": [
      "python",
      "bash"
    ],
    "complexity": "medium"
  },
  "components": [
    {
      "id": "start_backup_process",
      "name": "Start Backup Process",
      "category": "Orchestrator",
      "description": "Initialize the backup workflow as a starting point. Simple workflow starter task with no inputs or outputs.",
      "inputs": [],
      "outputs": [],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": "0.1",
          "memory": "64Mi",
          "gpu": null
        },
        "network": null
      },
      "io_spec": [],
      "upstream_policy": {
        "type": "all_success",
        "description": "No upstream dependencies as this is the initial task",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "system_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "date_check_task",
      "name": "Date Check Task",
      "category": "Splitter",
      "description": "Determine backup strategy by checking day of week (Saturday vs weekdays). Routes execution to either full or incremental backup path.",
      "inputs": [],
      "outputs": [],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": "check_day_of_week",
        "environment": {},
        "resources": {
          "cpu": "0.2",
          "memory": "128Mi",
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "execution_date",
          "direction": "input",
          "kind": "object",
          "format": "other",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Requires successful completion of start_backup_process",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "system_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "full_backup_task",
      "name": "Full Backup Task",
      "category": "Transformer",
      "description": "Perform complete database backup (executed only on Saturdays). Simulates backup with 5-second bash command.",
      "inputs": [],
      "outputs": [],
      "executor_type": "bash",
      "executor_config": {
        "image": null,
        "command": [
          "sleep",
          "5"
        ],
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": "0.5",
          "memory": "256Mi",
          "gpu": null
        },
        "network": null
      },
      "io_spec": [],
      "upstream_policy": {
        "type": "all_success",
        "description": "Requires successful completion of date_check_task",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "system_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "incremental_backup_task",
      "name": "Incremental Backup Task",
      "category": "Transformer",
      "description": "Perform partial backup of changed data only (executed on weekdays). Simulates backup with 3-second bash command.",
      "inputs": [],
      "outputs": [],
      "executor_type": "bash",
      "executor_config": {
        "image": null,
        "command": [
          "sleep",
          "3"
        ],
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": "0.3",
          "memory": "128Mi",
          "gpu": null
        },
        "network": null
      },
      "io_spec": [],
      "upstream_policy": {
        "type": "all_success",
        "description": "Requires successful completion of date_check_task",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "system_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "verify_backup_task",
      "name": "Verify Backup Task",
      "category": "QualityCheck",
      "description": "Validate backup integrity and completeness after either backup type. Merge point for both branches with special trigger rule.",
      "inputs": [],
      "outputs": [],
      "executor_type": "bash",
      "executor_config": {
        "image": null,
        "command": [
          "echo",
          "Backup verification complete"
        ],
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": "0.2",
          "memory": "128Mi",
          "gpu": null
        },
        "network": null
      },
      "io_spec": [],
      "upstream_policy": {
        "type": "none_failed",
        "description": "Runs when either full_backup_task or incremental_backup_task completes (at least one succeeds)",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "system_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "backup_complete",
      "name": "Backup Complete",
      "category": "Orchestrator",
      "description": "Mark backup workflow completion. Final workflow marker with no additional processing.",
      "inputs": [],
      "outputs": [],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": "0.1",
          "memory": "64Mi",
          "gpu": null
        },
        "network": null
      },
      "io_spec": [],
      "upstream_policy": {
        "type": "all_success",
        "description": "Requires successful completion of verify_backup_task",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "system_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    }
  ],
  "flow_structure": {
    "pattern": "branching",
    "entry_points": [
      "start_backup_process"
    ],
    "nodes": {
      "start_backup_process": {
        "kind": "Task",
        "component_type_id": "start_backup_process",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "date_check_task"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "date_check_task": {
        "kind": "Branch",
        "component_type_id": "date_check_task",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "full_backup_task",
          "incremental_backup_task"
        ],
        "branch_config": {
          "type": "conditional",
          "branches": [
            {
              "label": "Saturday - Full Backup",
              "condition": "execution_date.weekday() == 5",
              "next_node": "full_backup_task"
            },
            {
              "label": "Weekday - Incremental Backup",
              "condition": "else",
              "next_node": "incremental_backup_task"
            }
          ]
        },
        "sensor_config": null,
        "parallel_config": null
      },
      "full_backup_task": {
        "kind": "Task",
        "component_type_id": "full_backup_task",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "verify_backup_task"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "incremental_backup_task": {
        "kind": "Task",
        "component_type_id": "incremental_backup_task",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "verify_backup_task"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "verify_backup_task": {
        "kind": "Task",
        "component_type_id": "verify_backup_task",
        "upstream_policy": {
          "type": "none_failed",
          "timeout_seconds": null
        },
        "next_nodes": [
          "backup_complete"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "backup_complete": {
        "kind": "Task",
        "component_type_id": "backup_complete",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      }
    },
    "edges": [
      {
        "from": "start_backup_process",
        "to": "date_check_task",
        "edge_type": "success"
      },
      {
        "from": "date_check_task",
        "to": "full_backup_task",
        "edge_type": "conditional",
        "condition": "Saturday - Full Backup"
      },
      {
        "from": "date_check_task",
        "to": "incremental_backup_task",
        "edge_type": "conditional",
        "condition": "Weekday - Incremental Backup"
      },
      {
        "from": "full_backup_task",
        "to": "verify_backup_task",
        "edge_type": "success"
      },
      {
        "from": "incremental_backup_task",
        "to": "verify_backup_task",
        "edge_type": "success"
      },
      {
        "from": "verify_backup_task",
        "to": "backup_complete",
        "edge_type": "success"
      }
    ]
  },
  "parameters": {
    "pipeline": {
      "name": {
        "description": "Pipeline identifier",
        "type": "string",
        "default": "Backup Strategy Selector",
        "required": false,
        "constraints": null
      },
      "description": {
        "description": "Human-readable pipeline description",
        "type": "string",
        "default": "[Backup Strategy Selector] - Comprehensive Pipeline Description. This DAG implements a branch-merge pattern for automated database backup strategy selection based on day of week.",
        "required": false,
        "constraints": null
      },
      "tags": {
        "description": "Classification tags",
        "type": "array",
        "default": [
          "branch_merge",
          "backup",
          "database"
        ],
        "required": false
      }
    },
    "schedule": {
      "enabled": {
        "description": "Whether pipeline runs on schedule",
        "type": "boolean",
        "default": true,
        "required": false
      },
      "cron_expression": {
        "description": "Cron or preset (e.g., @daily, 0 0 * * *)",
        "type": "string",
        "default": "@daily",
        "required": false
      },
      "start_date": {
        "description": "When to start scheduling",
        "type": "datetime",
        "default": "2024-01-01T00:00:00Z",
        "required": false,
        "format": "ISO8601"
      },
      "end_date": {
        "description": "When to stop scheduling",
        "type": "datetime",
        "default": null,
        "required": false
      },
      "timezone": {
        "description": "Schedule timezone",
        "type": "string",
        "default": null,
        "required": false
      },
      "catchup": {
        "description": "Run missed intervals",
        "type": "boolean",
        "default": false,
        "required": false
      },
      "batch_window": {
        "description": "Batch window parameter name (e.g., ds, execution_date)",
        "type": "string",
        "default": "execution_date",
        "required": false
      },
      "partitioning": {
        "description": "Data partitioning strategy (e.g., daily, hourly, monthly)",
        "type": "string",
        "default": "daily",
        "required": false
      }
    },
    "execution": {
      "max_active_runs": {
        "description": "Max concurrent pipeline runs",
        "type": "integer",
        "default": 1,
        "required": false
      },
      "timeout_seconds": {
        "description": "Pipeline execution timeout",
        "type": "integer",
        "default": null,
        "required": false
      },
      "retry_policy": {
        "description": "Pipeline-level retry behavior",
        "type": "object",
        "default": {
          "retries": 2,
          "retry_delay_minutes": 5
        },
        "required": false
      },
      "depends_on_past": {
        "description": "Whether execution depends on previous run success",
        "type": "boolean",
        "default": false,
        "required": false
      }
    },
    "components": {
      "start_backup_process": {
        "task_type": {
          "description": "Type of operator used for this task",
          "type": "string",
          "default": "EmptyOperator",
          "required": false
        }
      },
      "date_check_task": {
        "task_type": {
          "description": "Type of operator used for this task",
          "type": "string",
          "default": "BranchPythonOperator",
          "required": false
        },
        "provide_context": {
          "description": "Whether to provide execution context to the task",
          "type": "boolean",
          "default": true,
          "required": false
        }
      },
      "full_backup_task": {
        "task_type": {
          "description": "Type of operator used for this task",
          "type": "string",
          "default": "BashOperator",
          "required": false
        },
        "execution_time_seconds": {
          "description": "Simulated execution time for the backup",
          "type": "integer",
          "default": 5,
          "required": false
        }
      },
      "incremental_backup_task": {
        "task_type": {
          "description": "Type of operator used for this task",
          "type": "string",
          "default": "BashOperator",
          "required": false
        },
        "execution_time_seconds": {
          "description": "Simulated execution time for the backup",
          "type": "integer",
          "default": 3,
          "required": false
        }
      },
      "verify_backup_task": {
        "task_type": {
          "description": "Type of operator used for this task",
          "type": "string",
          "default": "BashOperator",
          "required": false
        },
        "trigger_rule": {
          "description": "Rule for triggering task execution",
          "type": "string",
          "default": "none_failed_min_one_success",
          "required": false
        }
      },
      "backup_complete": {
        "task_type": {
          "description": "Type of operator used for this task",
          "type": "string",
          "default": "EmptyOperator",
          "required": false
        }
      }
    },
    "environment": {
      "EMAIL_ON_FAILURE": {
        "description": "Enable/disable email notifications on task failure",
        "type": "boolean",
        "default": false,
        "required": false,
        "associated_component_id": null
      },
      "EMAIL_ON_RETRY": {
        "description": "Enable/disable email notifications on task retry",
        "type": "boolean",
        "default": false,
        "required": false,
        "associated_component_id": null
      }
    }
  },
  "integrations": {
    "connections": [],
    "data_lineage": {
      "sources": [
        "DAG trigger event initiating backup process"
      ],
      "sinks": [
        "Backup workflow completion marker"
      ],
      "intermediate_datasets": [
        "Execution date context for day-of-week determination",
        "Branch routing decision (full vs incremental backup)",
        "Backup simulation results from bash commands"
      ]
    }
  }
}