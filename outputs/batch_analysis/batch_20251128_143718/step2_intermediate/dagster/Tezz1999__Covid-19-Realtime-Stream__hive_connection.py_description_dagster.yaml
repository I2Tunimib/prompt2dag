metadata:
  target_orchestrator: dagster
  generated_at: 2025-11-28 14:40:11.550327
  source_analysis_file: 
    Pipeline_Description_Dataset/Tezz1999__Covid-19-Realtime-Stream__hive_connection.py_description.txt
  pipeline_name: Comprehensive Pipeline Description
  pipeline_description: This is a simple linear data pipeline that executes Hive database operations for COVID-19 
    realtime streaming data. The pipeline follows a sequential topology pattern with two tasks executing in strict 
    order.
  orchestrator_specific:
    job_name: comprehensive_pipeline_description
    description: This is a simple linear data pipeline that executes Hive database operations for COVID-19 realtime 
      streaming data. The pipeline follows a sequential topology pattern with two tasks executing in strict order.
    executor_type: in_process_executor
    io_manager: fs_io_manager
    dagster_version: 1.5.0
    use_assets: false
    required_resources:
      - hive_local
schedule:
  enabled: true
  schedule_expression: 00 1 * * *
  start_date:
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: hive_local_connection
    conn_type: resource
    description: Hive Local Database Connection
    config:
      resource_type: resource
      resource_module: dagster
      resource_key: hive_local_connection
      config:
        host:
        port:
        protocol: jdbc
        database: mydb
        schema:
        base_path:
        base_url:
        bucket:
        queue_name:
tasks:
  - task_id: run_after_loop
    task_name: Run After Loop
    operator_class: Op
    operator_module: dagster
    component_ref: run_after_loop
    config:
      op_decorator: '@op'
      executor:
        type: docker_executor
        module: dagster_docker
        config:
          image: bash:latest
          container_kwargs:
            cpu_count: '0.5'
            mem_limit: 1Gi
          registry:
            url:
      config_schema: {}
      required_resource_keys: []
      retry_policy:
        max_retries: 1
        delay: 0
        backoff: CONSTANT
      ins: []
      outs:
        - name: system_command_output
          dagster_type: String
          description: Output to None
    upstream_task_ids: []
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 0
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
  - task_id: hive_script_task
    task_name: Hive Script Task
    operator_class: Op
    operator_module: dagster
    component_ref: hive_script_task
    config:
      op_decorator: '@op'
      executor:
        type: docker_executor
        module: dagster_docker
        config:
          image: apache/hive:latest
          container_kwargs:
            cpu_count: '1'
            mem_limit: 2Gi
          registry:
            url:
      config_schema: {}
      required_resource_keys:
        - hive_local
      retry_policy:
        max_retries: 1
        delay: 0
        backoff: CONSTANT
      ins:
        - name: hive_script_input
          dagster_type: String
          description: /opt/hive/scripts/hive_script.sql
      outs:
        - name: hive_database_created
          dagster_type: String
          description: Output to hive_local
        - name: hive_table_created
          dagster_type: String
          description: Output to hive_local
        - name: test_data_inserted
          dagster_type: String
          description: Output to hive_local
    upstream_task_ids:
      - run_after_loop
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 0
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
