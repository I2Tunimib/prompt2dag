{
  "metadata": {
    "schema_version": "1.0",
    "analysis_timestamp": "2025-11-28T14:39:47.113719",
    "source_file": "Pipeline_Description_Dataset/M4TTRX__data-eng-project__global_dag.py_description.txt",
    "llm_provider": "deepinfra",
    "llm_model": "Qwen3-Coder",
    "analysis_results": {
      "detected_patterns": [
        "sequential",
        "parallel",
        "branching"
      ],
      "task_executors_used": [
        "bash",
        "python",
        "sql"
      ],
      "has_branching": true,
      "has_parallelism": true,
      "has_sensors": false,
      "total_components": 14,
      "complexity_score": "medium"
    },
    "orchestrator_compatibility": {
      "airflow": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential pattern fully supported",
          "Branching via BranchPythonOperator",
          "Parallelism via TaskFlow API expand()"
        ]
      },
      "prefect": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential flow with task dependencies",
          "Conditional logic via Python control flow",
          "map() for parallel execution"
        ]
      },
      "dagster": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Op graph with dependencies",
          "Dynamic graphs or branching ops",
          "DynamicOutput for fan-out"
        ]
      }
    },
    "validation_warnings": [
      "Unreachable nodes: ['create_death_table', 'create_power_plants_table']"
    ]
  },
  "pipeline_summary": {
    "name": "global_dag",
    "description": "Comprehensive ETL pipeline processing French government death records and power plant data through staged ETL pattern with mixed topology",
    "flow_patterns": [
      "sequential",
      "parallel",
      "branching"
    ],
    "task_executors": [
      "bash",
      "python",
      "sql"
    ],
    "complexity": "medium"
  },
  "components": [
    {
      "id": "extract_city_geo",
      "name": "Extract City Geographic Data",
      "category": "Extractor",
      "description": "Downloads city geographic coordinates mapping data from a static CSV endpoint.",
      "inputs": [
        "CITY_GEO_DATASET_URL"
      ],
      "outputs": [
        "city_geo_loc.csv"
      ],
      "executor_type": "bash",
      "executor_config": {
        "image": null,
        "command": [
          "curl",
          "-o",
          "city_geo_loc.csv",
          "CITY_GEO_DATASET_URL"
        ],
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "city_geo_dataset_url",
          "direction": "input",
          "kind": "api",
          "format": "csv",
          "path_pattern": "https://static.data.gouv.fr/path/to/city_geo_loc.csv",
          "connection_id": null
        },
        {
          "name": "city_geo_loc_file",
          "direction": "output",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/ingestion/city_geo_loc.csv",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "city_geo_dataset"
        ],
        "produces": [
          "city_geo_loc_file"
        ]
      }
    },
    {
      "id": "extract_nuclear_data",
      "name": "Extract Nuclear Power Plant Data",
      "category": "Extractor",
      "description": "Fetches nuclear power plant metadata and extracts CSV data from the data.gouv.fr API.",
      "inputs": [
        "NUCLEAR_DATASET_ID"
      ],
      "outputs": [
        "nuclear_plants.json",
        "nuclear.csv"
      ],
      "executor_type": "bash",
      "executor_config": {
        "image": null,
        "command": [
          "curl",
          "-o",
          "nuclear_plants.json",
          "data.gouv.fr/api/datasets/NUCLEAR_DATASET_ID"
        ],
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "nuclear_dataset_id",
          "direction": "input",
          "kind": "api",
          "format": "json",
          "path_pattern": "https://data.gouv.fr/api/datasets/{dataset_id}",
          "connection_id": null
        },
        {
          "name": "nuclear_plants_json",
          "direction": "output",
          "kind": "file",
          "format": "json",
          "path_pattern": "/opt/airflow/dags/data/ingestion/nuclear_plants.json",
          "connection_id": null
        },
        {
          "name": "nuclear_csv",
          "direction": "output",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/ingestion/nuclear.csv",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "nuclear_dataset"
        ],
        "produces": [
          "nuclear_plants_json",
          "nuclear_csv"
        ]
      }
    },
    {
      "id": "extract_thermal_data",
      "name": "Extract Thermal Power Plant Data",
      "category": "Extractor",
      "description": "Fetches thermal power plant metadata and extracts CSV data from the data.gouv.fr API.",
      "inputs": [
        "THERMAL_DATASET_ID"
      ],
      "outputs": [
        "thermal_plants.json",
        "thermal_plants_.csv"
      ],
      "executor_type": "bash",
      "executor_config": {
        "image": null,
        "command": [
          "curl",
          "-o",
          "thermal_plants.json",
          "data.gouv.fr/api/datasets/THERMAL_DATASET_ID"
        ],
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "thermal_dataset_id",
          "direction": "input",
          "kind": "api",
          "format": "json",
          "path_pattern": "https://data.gouv.fr/api/datasets/{dataset_id}",
          "connection_id": null
        },
        {
          "name": "thermal_plants_json",
          "direction": "output",
          "kind": "file",
          "format": "json",
          "path_pattern": "/opt/airflow/dags/data/ingestion/thermal_plants.json",
          "connection_id": null
        },
        {
          "name": "thermal_plants_csv",
          "direction": "output",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/ingestion/thermal_plants_.csv",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "thermal_dataset"
        ],
        "produces": [
          "thermal_plants_json",
          "thermal_plants_csv"
        ]
      }
    },
    {
      "id": "extract_death_records",
      "name": "Extract Death Records",
      "category": "Extractor",
      "description": "Fetches death record metadata and downloads multiple death data files from the data.gouv.fr API.",
      "inputs": [
        "DEATH_DATASET_ID"
      ],
      "outputs": [
        "death_resources.json",
        "death_*.txt"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": "extract_death_records.py",
        "entry_point": "extract_death_records.main",
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "death_dataset_id",
          "direction": "input",
          "kind": "api",
          "format": "json",
          "path_pattern": "https://data.gouv.fr/api/datasets/{dataset_id}",
          "connection_id": null
        },
        {
          "name": "death_resources_json",
          "direction": "output",
          "kind": "file",
          "format": "json",
          "path_pattern": "/opt/airflow/dags/data/ingestion/death_resources.json",
          "connection_id": null
        },
        {
          "name": "death_txt_files",
          "direction": "output",
          "kind": "file",
          "format": "txt",
          "path_pattern": "/opt/airflow/dags/data/ingestion/death_*.txt",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "death_dataset"
        ],
        "produces": [
          "death_resources_json",
          "death_txt_files"
        ]
      }
    },
    {
      "id": "create_death_table",
      "name": "Create Death Table",
      "category": "SQLTransform",
      "description": "Creates the target database table for death records in PostgreSQL using a SQL schema file.",
      "inputs": [
        "create_death_table.sql"
      ],
      "outputs": [],
      "executor_type": "sql",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "death_table_schema",
          "direction": "input",
          "kind": "file",
          "format": "sql",
          "path_pattern": "/opt/airflow/dags/sql/create_death_table.sql",
          "connection_id": "postgres_default"
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "postgres_default",
          "type": "database",
          "purpose": "PostgreSQL connection for executing DDL statements"
        }
      ],
      "datasets": {
        "consumes": [
          "death_table_schema"
        ],
        "produces": []
      }
    },
    {
      "id": "create_power_plants_table",
      "name": "Create Power Plants Table",
      "category": "SQLTransform",
      "description": "Creates the target database table for power plant records in PostgreSQL using a SQL schema file.",
      "inputs": [
        "create_power_plant_table.sql"
      ],
      "outputs": [],
      "executor_type": "sql",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "power_plant_table_schema",
          "direction": "input",
          "kind": "file",
          "format": "sql",
          "path_pattern": "/opt/airflow/dags/sql/create_power_plant_table.sql",
          "connection_id": "postgres_default"
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "postgres_default",
          "type": "database",
          "purpose": "PostgreSQL connection for executing DDL statements"
        }
      ],
      "datasets": {
        "consumes": [
          "power_plant_table_schema"
        ],
        "produces": []
      }
    },
    {
      "id": "load_death_data_to_redis",
      "name": "Load Death Data to Redis",
      "category": "Loader",
      "description": "Loads death records from ingestion files into Redis with deduplication tracking.",
      "inputs": [
        "death_*.txt"
      ],
      "outputs": [
        "death_raw",
        "imported_death_files"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": "load_death_data_to_redis.py",
        "entry_point": "load_death_data_to_redis.main",
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "death_txt_files",
          "direction": "input",
          "kind": "file",
          "format": "txt",
          "path_pattern": "/opt/airflow/dags/data/ingestion/death_*.txt",
          "connection_id": null
        },
        {
          "name": "death_raw_redis",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": "redis://redis:6379/0/death_raw",
          "connection_id": "redis"
        },
        {
          "name": "imported_death_files_redis",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": "redis://redis:6379/0/imported_death_files",
          "connection_id": "redis"
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "redis",
          "type": "object_storage",
          "purpose": "Redis connection for intermediate data storage"
        }
      ],
      "datasets": {
        "consumes": [
          "death_txt_files"
        ],
        "produces": [
          "death_raw_redis",
          "imported_death_files_redis"
        ]
      }
    },
    {
      "id": "cleanse_death_data",
      "name": "Cleanse Death Data",
      "category": "Transformer",
      "description": "Transforms death records with geographic mapping and date formatting using Redis data and city coordinates.",
      "inputs": [
        "death_raw",
        "city_geo_loc.csv"
      ],
      "outputs": [
        "death_insertion_queries.sql"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": "cleanse_death_data.py",
        "entry_point": "cleanse_death_data.main",
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "death_raw_redis",
          "direction": "input",
          "kind": "object",
          "format": "json",
          "path_pattern": "redis://redis:6379/0/death_raw",
          "connection_id": "redis"
        },
        {
          "name": "city_geo_loc_file",
          "direction": "input",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/ingestion/city_geo_loc.csv",
          "connection_id": null
        },
        {
          "name": "death_insertion_queries",
          "direction": "output",
          "kind": "file",
          "format": "sql",
          "path_pattern": "/opt/airflow/dags/sql/tmp/death_insertion_queries.sql",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "redis",
          "type": "object_storage",
          "purpose": "Redis connection for reading raw death data"
        }
      ],
      "datasets": {
        "consumes": [
          "death_raw_redis",
          "city_geo_loc_file"
        ],
        "produces": [
          "death_insertion_queries"
        ]
      }
    },
    {
      "id": "cleanse_power_plant_data",
      "name": "Cleanse Power Plant Data",
      "category": "Transformer",
      "description": "Cleans and transforms power plant data with column standardization for both thermal and nuclear sources.",
      "inputs": [
        "thermal_plants_.csv",
        "nuclear.csv"
      ],
      "outputs": [
        "cleaned_thermal.csv",
        "cleaned_nuclear.csv"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": "cleanse_power_plant_data.py",
        "entry_point": "cleanse_power_plant_data.main",
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "thermal_plants_csv",
          "direction": "input",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/ingestion/thermal_plants_.csv",
          "connection_id": null
        },
        {
          "name": "nuclear_csv",
          "direction": "input",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/ingestion/nuclear.csv",
          "connection_id": null
        },
        {
          "name": "cleaned_thermal_csv",
          "direction": "output",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/staging/cleaned_thermal.csv",
          "connection_id": null
        },
        {
          "name": "cleaned_nuclear_csv",
          "direction": "output",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/staging/cleaned_nuclear.csv",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "thermal_plants_csv",
          "nuclear_csv"
        ],
        "produces": [
          "cleaned_thermal_csv",
          "cleaned_nuclear_csv"
        ]
      }
    },
    {
      "id": "generate_plant_sql_queries",
      "name": "Generate Plant SQL Queries",
      "category": "SQLTransform",
      "description": "Generates SQL insertion queries for power plant data with deduplication by plant name.",
      "inputs": [
        "cleaned_thermal.csv",
        "cleaned_nuclear.csv"
      ],
      "outputs": [
        "plant_insertion_queries.sql"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": "generate_plant_sql_queries.py",
        "entry_point": "generate_plant_sql_queries.main",
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "cleaned_thermal_csv",
          "direction": "input",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/staging/cleaned_thermal.csv",
          "connection_id": null
        },
        {
          "name": "cleaned_nuclear_csv",
          "direction": "input",
          "kind": "file",
          "format": "csv",
          "path_pattern": "/opt/airflow/dags/data/staging/cleaned_nuclear.csv",
          "connection_id": null
        },
        {
          "name": "plant_insertion_queries",
          "direction": "output",
          "kind": "file",
          "format": "sql",
          "path_pattern": "/opt/airflow/dags/sql/tmp/plant_insertion_queries.sql",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "cleaned_thermal_csv",
          "cleaned_nuclear_csv"
        ],
        "produces": [
          "plant_insertion_queries"
        ]
      }
    },
    {
      "id": "check_death_data_emptiness",
      "name": "Check Death Data Emptiness",
      "category": "QualityCheck",
      "description": "Checks if death data processing produced valid SQL queries by examining file content.",
      "inputs": [
        "death_insertion_queries.sql"
      ],
      "outputs": [
        "branch_decision"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": "check_death_data_emptiness.py",
        "entry_point": "check_death_data_emptiness.main",
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "death_insertion_queries",
          "direction": "input",
          "kind": "file",
          "format": "sql",
          "path_pattern": "/opt/airflow/dags/sql/tmp/death_insertion_queries.sql",
          "connection_id": null
        },
        {
          "name": "branch_decision",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": "branch_decision",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "death_insertion_queries"
        ],
        "produces": [
          "branch_decision"
        ]
      }
    },
    {
      "id": "store_deaths_in_postgres",
      "name": "Store Deaths in PostgreSQL",
      "category": "Loader",
      "description": "Executes death data insertion into PostgreSQL when valid data exists.",
      "inputs": [
        "death_insertion_queries.sql"
      ],
      "outputs": [],
      "executor_type": "sql",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "death_insertion_queries",
          "direction": "input",
          "kind": "file",
          "format": "sql",
          "path_pattern": "/opt/airflow/dags/sql/tmp/death_insertion_queries.sql",
          "connection_id": "postgres_default"
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "postgres_default",
          "type": "database",
          "purpose": "PostgreSQL connection for executing DML statements"
        }
      ],
      "datasets": {
        "consumes": [
          "death_insertion_queries"
        ],
        "produces": []
      }
    },
    {
      "id": "store_plants_in_postgres",
      "name": "Store Plants in PostgreSQL",
      "category": "Loader",
      "description": "Loads power plant data into PostgreSQL using generated SQL insertion queries.",
      "inputs": [
        "plant_insertion_queries.sql"
      ],
      "outputs": [],
      "executor_type": "sql",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "plant_insertion_queries",
          "direction": "input",
          "kind": "file",
          "format": "sql",
          "path_pattern": "/opt/airflow/dags/sql/tmp/plant_insertion_queries.sql",
          "connection_id": "postgres_default"
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "postgres_default",
          "type": "database",
          "purpose": "PostgreSQL connection for executing DML statements"
        }
      ],
      "datasets": {
        "consumes": [
          "plant_insertion_queries"
        ],
        "produces": []
      }
    },
    {
      "id": "clean_tmp_death_files",
      "name": "Clean Temporary Death Files",
      "category": "Other",
      "description": "Cleans up temporary death data from Redis and file system after processing.",
      "inputs": [
        "death_raw",
        "death_insertion_queries.sql"
      ],
      "outputs": [],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": "clean_tmp_death_files.py",
        "entry_point": "clean_tmp_death_files.main",
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "death_raw_redis",
          "direction": "input",
          "kind": "object",
          "format": "json",
          "path_pattern": "redis://redis:6379/0/death_raw",
          "connection_id": "redis"
        },
        {
          "name": "death_insertion_queries",
          "direction": "input",
          "kind": "file",
          "format": "sql",
          "path_pattern": "/opt/airflow/dags/sql/tmp/death_insertion_queries.sql",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after all upstream tasks succeed",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 10,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "redis",
          "type": "object_storage",
          "purpose": "Redis connection for cleaning temporary data"
        }
      ],
      "datasets": {
        "consumes": [
          "death_raw_redis",
          "death_insertion_queries"
        ],
        "produces": []
      }
    }
  ],
  "flow_structure": {
    "pattern": "hybrid",
    "entry_points": [
      "extract_city_geo"
    ],
    "nodes": {
      "extract_city_geo": {
        "kind": "Task",
        "component_type_id": "extract_city_geo",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "extract_nuclear_data",
          "extract_thermal_data",
          "extract_death_records"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "extract_nuclear_data": {
        "kind": "Task",
        "component_type_id": "extract_nuclear_data",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "cleanse_power_plant_data"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "extract_thermal_data": {
        "kind": "Task",
        "component_type_id": "extract_thermal_data",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "cleanse_power_plant_data"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "extract_death_records": {
        "kind": "Task",
        "component_type_id": "extract_death_records",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "load_death_data_to_redis"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "create_death_table": {
        "kind": "Task",
        "component_type_id": "create_death_table",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "load_death_data_to_redis"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "create_power_plants_table": {
        "kind": "Task",
        "component_type_id": "create_power_plants_table",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "generate_plant_sql_queries"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "load_death_data_to_redis": {
        "kind": "Task",
        "component_type_id": "load_death_data_to_redis",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "cleanse_death_data"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "cleanse_death_data": {
        "kind": "Task",
        "component_type_id": "cleanse_death_data",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "check_death_data_emptiness"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "cleanse_power_plant_data": {
        "kind": "Task",
        "component_type_id": "cleanse_power_plant_data",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "generate_plant_sql_queries"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "generate_plant_sql_queries": {
        "kind": "Task",
        "component_type_id": "generate_plant_sql_queries",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "store_plants_in_postgres"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "check_death_data_emptiness": {
        "kind": "Branch",
        "component_type_id": null,
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "store_deaths_in_postgres",
          "staging_end"
        ],
        "branch_config": {
          "type": "conditional",
          "branches": [
            {
              "label": "death_data_exists",
              "condition": "death_data_file_not_empty",
              "next_node": "store_deaths_in_postgres"
            },
            {
              "label": "no_death_data",
              "condition": "else",
              "next_node": "staging_end"
            }
          ]
        },
        "sensor_config": null,
        "parallel_config": null
      },
      "store_deaths_in_postgres": {
        "kind": "Task",
        "component_type_id": "store_deaths_in_postgres",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "clean_tmp_death_files"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "staging_end": {
        "kind": "Virtual",
        "component_type_id": null,
        "upstream_policy": {
          "type": "all_done",
          "timeout_seconds": null
        },
        "next_nodes": [
          "clean_tmp_death_files"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "store_plants_in_postgres": {
        "kind": "Task",
        "component_type_id": "store_plants_in_postgres",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "clean_tmp_death_files"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "clean_tmp_death_files": {
        "kind": "Task",
        "component_type_id": "clean_tmp_death_files",
        "upstream_policy": {
          "type": "all_done",
          "timeout_seconds": null
        },
        "next_nodes": [],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      }
    },
    "edges": [
      {
        "from": "extract_city_geo",
        "to": "extract_nuclear_data",
        "edge_type": "success"
      },
      {
        "from": "extract_city_geo",
        "to": "extract_thermal_data",
        "edge_type": "success"
      },
      {
        "from": "extract_city_geo",
        "to": "extract_death_records",
        "edge_type": "success"
      },
      {
        "from": "extract_nuclear_data",
        "to": "cleanse_power_plant_data",
        "edge_type": "success"
      },
      {
        "from": "extract_thermal_data",
        "to": "cleanse_power_plant_data",
        "edge_type": "success"
      },
      {
        "from": "extract_death_records",
        "to": "load_death_data_to_redis",
        "edge_type": "success"
      },
      {
        "from": "create_death_table",
        "to": "load_death_data_to_redis",
        "edge_type": "success"
      },
      {
        "from": "create_power_plants_table",
        "to": "generate_plant_sql_queries",
        "edge_type": "success"
      },
      {
        "from": "load_death_data_to_redis",
        "to": "cleanse_death_data",
        "edge_type": "success"
      },
      {
        "from": "cleanse_death_data",
        "to": "check_death_data_emptiness",
        "edge_type": "success"
      },
      {
        "from": "cleanse_power_plant_data",
        "to": "generate_plant_sql_queries",
        "edge_type": "success"
      },
      {
        "from": "generate_plant_sql_queries",
        "to": "store_plants_in_postgres",
        "edge_type": "success"
      },
      {
        "from": "check_death_data_emptiness",
        "to": "store_deaths_in_postgres",
        "edge_type": "conditional",
        "condition": "death_data_exists"
      },
      {
        "from": "check_death_data_emptiness",
        "to": "staging_end",
        "edge_type": "conditional",
        "condition": "no_death_data"
      },
      {
        "from": "store_deaths_in_postgres",
        "to": "clean_tmp_death_files",
        "edge_type": "success"
      },
      {
        "from": "staging_end",
        "to": "clean_tmp_death_files",
        "edge_type": "always"
      },
      {
        "from": "store_plants_in_postgres",
        "to": "clean_tmp_death_files",
        "edge_type": "success"
      }
    ]
  },
  "parameters": {
    "pipeline": {
      "name": {
        "description": "Pipeline identifier",
        "type": "string",
        "default": "global_dag",
        "required": false,
        "constraints": null
      },
      "description": {
        "description": "Pipeline description",
        "type": "string",
        "default": "Comprehensive ETL pipeline processing French government death records and power plant data through staged ETL pattern with mixed topology",
        "required": false,
        "constraints": null
      },
      "tags": {
        "description": "Classification tags",
        "type": "array",
        "default": [
          "etl",
          "french-government",
          "data-processing",
          "staged-etl",
          "fan-out-fan-in",
          "branch-merge"
        ],
        "required": false
      }
    },
    "schedule": {
      "enabled": {
        "description": "Whether pipeline runs on schedule",
        "type": "boolean",
        "default": false,
        "required": false
      },
      "cron_expression": {
        "description": "Cron or preset (e.g., @daily, 0 0 * * *)",
        "type": "string",
        "default": null,
        "required": false
      },
      "start_date": {
        "description": "When to start scheduling",
        "type": "datetime",
        "default": null,
        "required": false,
        "format": "ISO8601"
      },
      "end_date": {
        "description": "When to stop scheduling",
        "type": "datetime",
        "default": null,
        "required": false
      },
      "timezone": {
        "description": "Schedule timezone",
        "type": "string",
        "default": null,
        "required": false
      },
      "catchup": {
        "description": "Run missed intervals",
        "type": "boolean",
        "default": false,
        "required": false
      },
      "batch_window": {
        "description": "Batch window parameter name (e.g., ds, execution_date)",
        "type": "string",
        "default": null,
        "required": false
      },
      "partitioning": {
        "description": "Data partitioning strategy (e.g., daily, hourly, monthly)",
        "type": "string",
        "default": null,
        "required": false
      }
    },
    "execution": {
      "max_active_runs": {
        "description": "Max concurrent pipeline runs",
        "type": "integer",
        "default": 1,
        "required": false
      },
      "timeout_seconds": {
        "description": "Pipeline execution timeout",
        "type": "integer",
        "default": null,
        "required": false
      },
      "retry_policy": {
        "description": "Pipeline-level retry behavior",
        "type": "object",
        "default": {
          "retries": 1,
          "retry_delay_seconds": 10
        },
        "required": false
      },
      "depends_on_past": {
        "description": "Whether execution depends on previous run success",
        "type": "boolean",
        "default": false,
        "required": false
      }
    },
    "components": {
      "extract_city_geo": {
        "CITY_GEO_DATASET_URL": {
          "description": "URL for city geographic coordinates mapping data",
          "type": "string",
          "default": null,
          "required": true,
          "constraints": "Must be a valid URL to static.data.gouv.fr CSV endpoint"
        },
        "output_file_path": {
          "description": "Path to store the downloaded city geo data",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/city_geo_loc.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "extract_nuclear_data": {
        "NUCLEAR_DATASET_ID": {
          "description": "Dataset ID for nuclear power plant data from data.gouv.fr",
          "type": "string",
          "default": null,
          "required": true,
          "constraints": "Must be a valid dataset ID from data.gouv.fr"
        },
        "output_json_path": {
          "description": "Path to store nuclear plant metadata JSON",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/nuclear_plants.json",
          "required": false,
          "constraints": "Must be a valid file path"
        },
        "output_csv_path": {
          "description": "Path to store extracted nuclear plant CSV data",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/nuclear.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "extract_thermal_data": {
        "THERMAL_DATASET_ID": {
          "description": "Dataset ID for thermal power plant data from data.gouv.fr",
          "type": "string",
          "default": null,
          "required": true,
          "constraints": "Must be a valid dataset ID from data.gouv.fr"
        },
        "output_json_path": {
          "description": "Path to store thermal plant metadata JSON",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/thermal_plants.json",
          "required": false,
          "constraints": "Must be a valid file path"
        },
        "output_csv_path": {
          "description": "Path to store extracted thermal plant CSV data",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/thermal_plants_.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "extract_death_records": {
        "DEATH_DATASET_ID": {
          "description": "Dataset ID for death records from data.gouv.fr",
          "type": "string",
          "default": null,
          "required": true,
          "constraints": "Must be a valid dataset ID from data.gouv.fr"
        },
        "max_resource": {
          "description": "Maximum number of death record resources to download",
          "type": "integer",
          "default": 5,
          "required": false,
          "constraints": "Must be a positive integer"
        },
        "output_json_path": {
          "description": "Path to store death record metadata JSON",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/death_resources.json",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "create_death_table": {
        "sql_schema_file": {
          "description": "Path to SQL schema file for creating death table",
          "type": "string",
          "default": "/opt/airflow/dags/sql/create_death_table.sql",
          "required": false,
          "constraints": "Must be a valid file path to SQL schema"
        }
      },
      "create_power_plants_table": {
        "sql_schema_file": {
          "description": "Path to SQL schema file for creating power plants table",
          "type": "string",
          "default": "/opt/airflow/dags/sql/create_power_plant_table.sql",
          "required": false,
          "constraints": "Must be a valid file path to SQL schema"
        }
      },
      "load_death_data_to_redis": {
        "redis_host": {
          "description": "Redis server hostname",
          "type": "string",
          "default": "redis",
          "required": false,
          "constraints": null
        },
        "redis_port": {
          "description": "Redis server port",
          "type": "integer",
          "default": 6379,
          "required": false,
          "constraints": "Must be a valid port number"
        },
        "redis_db": {
          "description": "Redis database number",
          "type": "integer",
          "default": 0,
          "required": false,
          "constraints": "Must be a valid database index"
        },
        "death_files_pattern": {
          "description": "Pattern to match death data files",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/death_*.txt",
          "required": false,
          "constraints": "Must be a valid file pattern"
        },
        "death_raw_key": {
          "description": "Redis key for raw death data",
          "type": "string",
          "default": "death_raw",
          "required": false,
          "constraints": null
        },
        "imported_files_key": {
          "description": "Redis key for tracking imported death files",
          "type": "string",
          "default": "imported_death_files",
          "required": false,
          "constraints": null
        }
      },
      "cleanse_death_data": {
        "redis_host": {
          "description": "Redis server hostname",
          "type": "string",
          "default": "redis",
          "required": false,
          "constraints": null
        },
        "redis_port": {
          "description": "Redis server port",
          "type": "integer",
          "default": 6379,
          "required": false,
          "constraints": "Must be a valid port number"
        },
        "redis_db": {
          "description": "Redis database number",
          "type": "integer",
          "default": 0,
          "required": false,
          "constraints": "Must be a valid database index"
        },
        "death_raw_key": {
          "description": "Redis key for raw death data",
          "type": "string",
          "default": "death_raw",
          "required": false,
          "constraints": null
        },
        "city_geo_file": {
          "description": "Path to city geographic coordinates CSV file",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/city_geo_loc.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        },
        "output_sql_path": {
          "description": "Path to output SQL insertion queries file",
          "type": "string",
          "default": "/opt/airflow/dags/sql/tmp/death_insertion_queries.sql",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "cleanse_power_plant_data": {
        "thermal_input_path": {
          "description": "Path to raw thermal plant CSV data",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/thermal_plants_.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        },
        "nuclear_input_path": {
          "description": "Path to raw nuclear plant CSV data",
          "type": "string",
          "default": "/opt/airflow/dags/data/ingestion/nuclear.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        },
        "thermal_output_path": {
          "description": "Path to cleaned thermal plant CSV data",
          "type": "string",
          "default": "/opt/airflow/dags/data/staging/thermal_clean.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        },
        "nuclear_output_path": {
          "description": "Path to cleaned nuclear plant CSV data",
          "type": "string",
          "default": "/opt/airflow/dags/data/staging/nuclear_clean.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "generate_plant_sql_queries": {
        "thermal_input_path": {
          "description": "Path to cleaned thermal plant CSV data",
          "type": "string",
          "default": "/opt/airflow/dags/data/staging/thermal_clean.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        },
        "nuclear_input_path": {
          "description": "Path to cleaned nuclear plant CSV data",
          "type": "string",
          "default": "/opt/airflow/dags/data/staging/nuclear_clean.csv",
          "required": false,
          "constraints": "Must be a valid file path"
        },
        "output_sql_path": {
          "description": "Path to output SQL insertion queries file",
          "type": "string",
          "default": "/opt/airflow/dags/sql/tmp/plant_insertion_queries.sql",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "check_death_data_emptiness": {
        "input_sql_path": {
          "description": "Path to death data SQL insertion queries file",
          "type": "string",
          "default": "/opt/airflow/dags/sql/tmp/death_insertion_queries.sql",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "store_deaths_in_postgres": {
        "input_sql_path": {
          "description": "Path to death data SQL insertion queries file",
          "type": "string",
          "default": "/opt/airflow/dags/sql/tmp/death_insertion_queries.sql",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "store_plants_in_postgres": {
        "input_sql_path": {
          "description": "Path to power plant SQL insertion queries file",
          "type": "string",
          "default": "/opt/airflow/dags/sql/tmp/plant_insertion_queries.sql",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      },
      "clean_tmp_death_files": {
        "redis_host": {
          "description": "Redis server hostname",
          "type": "string",
          "default": "redis",
          "required": false,
          "constraints": null
        },
        "redis_port": {
          "description": "Redis server port",
          "type": "integer",
          "default": 6379,
          "required": false,
          "constraints": "Must be a valid port number"
        },
        "redis_db": {
          "description": "Redis database number",
          "type": "integer",
          "default": 0,
          "required": false,
          "constraints": "Must be a valid database index"
        },
        "death_raw_key": {
          "description": "Redis key for raw death data",
          "type": "string",
          "default": "death_raw",
          "required": false,
          "constraints": null
        },
        "sql_query_file": {
          "description": "Path to temporary SQL query file to delete",
          "type": "string",
          "default": "/opt/airflow/dags/sql/tmp/death_insertion_queries.sql",
          "required": false,
          "constraints": "Must be a valid file path"
        }
      }
    },
    "environment": {
      "POSTGRES_DEFAULT_CONN": {
        "description": "PostgreSQL connection string",
        "type": "string",
        "default": null,
        "required": true,
        "associated_component_id": null
      },
      "REDIS_HOST": {
        "description": "Redis server hostname",
        "type": "string",
        "default": "redis",
        "required": false,
        "associated_component_id": null
      },
      "REDIS_PORT": {
        "description": "Redis server port",
        "type": "integer",
        "default": 6379,
        "required": false,
        "associated_component_id": null
      },
      "INGESTION_DATA_PATH": {
        "description": "Path to ingestion data directory",
        "type": "string",
        "default": "/opt/airflow/dags/data/ingestion/",
        "required": false,
        "associated_component_id": null
      },
      "STAGING_DATA_PATH": {
        "description": "Path to staging data directory",
        "type": "string",
        "default": "/opt/airflow/dags/data/staging/",
        "required": false,
        "associated_component_id": null
      },
      "SQL_QUERIES_PATH": {
        "description": "Path to SQL queries directory",
        "type": "string",
        "default": "/opt/airflow/dags/sql/tmp/",
        "required": false,
        "associated_component_id": null
      }
    }
  },
  "integrations": {
    "connections": [
      {
        "id": "data_gouv_api",
        "name": "data.gouv.fr API",
        "type": "api",
        "config": {
          "base_url": "https://data.gouv.fr/api",
          "host": null,
          "port": null,
          "protocol": "https",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null,
          "base_path": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "extract_city_geo",
          "extract_nuclear_data",
          "extract_thermal_data",
          "extract_death_records"
        ],
        "direction": "input",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [],
          "consumes": [
            "city_geo_data",
            "nuclear_plant_data",
            "thermal_plant_data",
            "death_record_data"
          ]
        }
      },
      {
        "id": "ingestion_filesystem",
        "name": "Ingestion Filesystem Storage",
        "type": "filesystem",
        "config": {
          "base_path": "/opt/airflow/dags/data/ingestion/",
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": "file",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "extract_city_geo",
          "extract_nuclear_data",
          "extract_thermal_data",
          "extract_death_records",
          "load_death_data_to_redis",
          "cleanse_death_data"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "city_geo_loc.csv",
            "nuclear_plants.json",
            "nuclear.csv",
            "thermal_plants.json",
            "thermal_plants_.csv",
            "death_resources.json",
            "death_*.txt"
          ],
          "consumes": [
            "death_*.txt",
            "city_geo_loc.csv"
          ]
        }
      },
      {
        "id": "redis_cache",
        "name": "Redis Cache",
        "type": "cache",
        "config": {
          "host": "redis",
          "port": 6379,
          "database": "0",
          "base_path": null,
          "base_url": null,
          "protocol": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "load_death_data_to_redis",
          "cleanse_death_data",
          "clean_tmp_death_files"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "death_raw",
            "imported_death_files"
          ],
          "consumes": [
            "death_raw"
          ]
        }
      },
      {
        "id": "postgres_db",
        "name": "PostgreSQL Database",
        "type": "database",
        "config": {
          "host": null,
          "port": null,
          "database": null,
          "schema": null,
          "base_path": null,
          "base_url": null,
          "protocol": "jdbc",
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "create_death_table",
          "create_power_plants_table",
          "store_deaths_in_postgres",
          "store_plants_in_postgres"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "deaths_table",
            "power_plants_table"
          ],
          "consumes": []
        }
      },
      {
        "id": "staging_filesystem",
        "name": "Staging Filesystem Storage",
        "type": "filesystem",
        "config": {
          "base_path": "/opt/airflow/dags/data/staging/",
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": "file",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "cleanse_power_plant_data",
          "generate_plant_sql_queries",
          "check_death_data_emptiness"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "cleaned_thermal_plants.csv",
            "cleaned_nuclear_plants.csv",
            "plant_insertion_queries.sql",
            "death_insertion_queries.sql"
          ],
          "consumes": [
            "thermal_plants_.csv",
            "nuclear.csv"
          ]
        }
      },
      {
        "id": "sql_template_filesystem",
        "name": "SQL Template Filesystem Storage",
        "type": "filesystem",
        "config": {
          "base_path": "/opt/airflow/dags/sql/tmp/",
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": "file",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "create_death_table",
          "create_power_plants_table",
          "check_death_data_emptiness",
          "store_deaths_in_postgres"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [],
          "consumes": [
            "create_death_table.sql",
            "create_power_plant_table.sql",
            "death_insertion_queries.sql"
          ]
        }
      }
    ],
    "data_lineage": {
      "sources": [
        "French government death records from data.gouv.fr API",
        "Thermal power plant data from data.gouv.fr API",
        "Nuclear power plant data from data.gouv.fr API",
        "City geographic coordinates from static.data.gouv.fr"
      ],
      "sinks": [
        "PostgreSQL database tables (deaths, power_plants)"
      ],
      "intermediate_datasets": [
        "ingestion/*.csv",
        "ingestion/*.json",
        "ingestion/death_*.txt",
        "Redis death_raw list",
        "staging/cleaned_*.csv",
        "sql/tmp/*.sql"
      ]
    }
  }
}