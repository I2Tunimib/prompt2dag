metadata:
  target_orchestrator: dagster
  generated_at: 2025-11-28 12:33:35.035801
  source_analysis_file: Pipeline_Description_Dataset/Sequential_Pipeline_Prompt.txt
  pipeline_name: load_and_modify_data_pipeline
  pipeline_description: This data processing pipeline executes a series of Docker-containerized tasks in a strictly 
    sequential order to transform raw CSV data through successive enrichment steps and finally save the processed data 
    as a CSV file.
  orchestrator_specific:
    job_name: load_and_modify_data_pipeline
    description: This data processing pipeline executes a series of Docker-containerized tasks in a strictly sequential 
      order to transform raw CSV data through successive enrichment steps and finally save the processed data as a CSV 
      file.
    executor_type: docker_executor
    io_manager: fs_io_manager
    dagster_version: 1.5.0
    use_assets: false
    required_resources:
      - data_volume
      - openmeteo_api
      - here_api
schedule:
  enabled: false
  schedule_expression:
  start_date:
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: data_directory
    conn_type: fs_io_manager
    description: Shared Data Directory
    config:
      resource_type: fs_io_manager
      resource_module: dagster
      resource_key: data_directory
      config:
        base_path: /app/data
        protocol: file
  - conn_id: load_modify_api
    conn_type: resource
    description: Load and Modify Service API
    config:
      resource_type: resource
      resource_module: dagster
      resource_key: load_modify_api
      config:
        base_url: http://load-modify-service:3003
        protocol: http
  - conn_id: reconciliation_api
    conn_type: resource
    description: Data Reconciliation Service API
    config:
      resource_type: resource
      resource_module: dagster
      resource_key: reconciliation_api
      config:
        base_url: http://reconciliation-service:3003
        protocol: http
        token: EnvVar('RECONCILIATION_API_TOKEN')
  - conn_id: intertwino_api
    conn_type: resource
    description: Intertwino API
    config:
      resource_type: resource
      resource_module: dagster
      resource_key: intertwino_api
      config:
        base_url: http://intertwino-api:5005
        protocol: http
  - conn_id: mongodb
    conn_type: pymongo_resource
    description: MongoDB Database
    config:
      resource_type: pymongo_resource
      resource_module: dagster_mongo
      resource_key: mongodb
      config:
        host: mongodb
        port: 27017
        database: intertwino
        schema:
        protocol: mongodb
  - conn_id: docker_network
    conn_type: resource
    description: Custom Docker Network
    config:
      resource_type: resource
      resource_module: dagster
      resource_key: docker_network
      config:
        network_name: app_network
tasks:
  - task_id: load_and_modify_data
    task_name: Load and Modify Data
    operator_class: Op
    operator_module: dagster
    component_ref: load_and_modify_data
    config:
      op_decorator: '@op'
      executor:
        type: docker_executor
        module: dagster_docker
        config:
          image: i2t-backendwithintertwino6-load-and-modify:latest
          container_kwargs:
            environment:
              DATASET_ID: '2'
              DATE_COLUMN: Fecha_id
            network_mode: app_network
            cpu_count: '1'
            mem_limit: 2Gi
          registry:
            url:
      config_schema: {}
      required_resource_keys:
        - data_volume
      retry_policy:
        max_retries: 1
        delay: 30
        backoff: CONSTANT
      ins:
        - name: input_csv
          dagster_type: String
          description: ${DATA_DIR}/*.csv
      outs:
        - name: output_json
          dagster_type: String
          description: Output to None
    upstream_task_ids: []
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 30
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
  - task_id: reconcile_city_names
    task_name: Data Reconciliation
    operator_class: Op
    operator_module: dagster
    component_ref: reconcile_city_names
    config:
      op_decorator: '@op'
      executor:
        type: docker_executor
        module: dagster_docker
        config:
          image: i2t-backendwithintertwino6-reconciliation:latest
          container_kwargs:
            environment:
              PRIMARY_COLUMN: City
              OPTIONAL_COLUMNS: County,Country
              RECONCILIATOR_ID: geocodingHere
            network_mode: app_network
            cpu_count: '1'
            mem_limit: 2Gi
          registry:
            url:
      config_schema: {}
      required_resource_keys:
        - here_api
      retry_policy:
        max_retries: 1
        delay: 30
        backoff: CONSTANT
      ins:
        - name: input_json
          dagster_type: String
          description: table_data_*.json
      outs:
        - name: output_reconciled_json
          dagster_type: String
          description: Output to None
    upstream_task_ids:
      - load_and_modify_data
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 30
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
  - task_id: enrich_with_weather
    task_name: OpenMeteo Data Extension
    operator_class: Op
    operator_module: dagster
    component_ref: enrich_with_weather
    config:
      op_decorator: '@op'
      executor:
        type: docker_executor
        module: dagster_docker
        config:
          image: i2t-backendwithintertwino6-openmeteo-extension:latest
          container_kwargs:
            environment:
              WEATHER_ATTRIBUTES: 
                apparent_temperature_max,apparent_temperature_min,precipitation_sum,precipitation_hours
            network_mode: app_network
            cpu_count: '1'
            mem_limit: 2Gi
          registry:
            url:
      config_schema: {}
      required_resource_keys:
        - openmeteo_api
      retry_policy:
        max_retries: 1
        delay: 30
        backoff: CONSTANT
      ins:
        - name: input_reconciled_json
          dagster_type: String
          description: reconciled_table_*.json
      outs:
        - name: output_weather_json
          dagster_type: String
          description: Output to None
    upstream_task_ids:
      - reconcile_city_names
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 30
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
  - task_id: extend_with_columns
    task_name: Column Extension
    operator_class: Op
    operator_module: dagster
    component_ref: extend_with_columns
    config:
      op_decorator: '@op'
      executor:
        type: docker_executor
        module: dagster_docker
        config:
          image: i2t-backendwithintertwino6-column-extension:latest
          container_kwargs:
            environment:
              EXTENDER_ID: reconciledColumnExt
            network_mode: app_network
            cpu_count: '1'
            mem_limit: 2Gi
          registry:
            url:
      config_schema: {}
      required_resource_keys: []
      retry_policy:
        max_retries: 1
        delay: 30
        backoff: CONSTANT
      ins:
        - name: input_weather_json
          dagster_type: String
          description: open_meteo_*.json
      outs:
        - name: output_column_extended_json
          dagster_type: String
          description: Output to None
    upstream_task_ids:
      - enrich_with_weather
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 30
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
  - task_id: save_final_data
    task_name: Save Final Data
    operator_class: Op
    operator_module: dagster
    component_ref: save_final_data
    config:
      op_decorator: '@op'
      executor:
        type: docker_executor
        module: dagster_docker
        config:
          image: i2t-backendwithintertwino6-save:latest
          container_kwargs:
            network_mode: app_network
            cpu_count: '1'
            mem_limit: 2Gi
          registry:
            url:
      config_schema: {}
      required_resource_keys:
        - data_volume
      retry_policy:
        max_retries: 1
        delay: 30
        backoff: CONSTANT
      ins:
        - name: input_column_extended_json
          dagster_type: String
          description: column_extended_*.json
      outs:
        - name: output_final_csv
          dagster_type: String
          description: Output to None
    upstream_task_ids:
      - extend_with_columns
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 30
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
