{
  "metadata": {
    "schema_version": "1.0",
    "analysis_timestamp": "2025-11-28T12:35:00.296219",
    "source_file": "Pipeline_Description_Dataset/peterbull__bodhi-cast__log_cleanup.py_description.txt",
    "llm_provider": "deepinfra",
    "llm_model": "Qwen3-Coder",
    "analysis_results": {
      "detected_patterns": [
        "sequential",
        "parallel"
      ],
      "task_executors_used": [
        "bash"
      ],
      "has_branching": false,
      "has_parallelism": true,
      "has_sensors": false,
      "total_components": 2,
      "complexity_score": "low"
    },
    "orchestrator_compatibility": {
      "airflow": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential pattern fully supported",
          "Parallelism via TaskFlow API expand()"
        ]
      },
      "prefect": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential flow with task dependencies",
          "map() for parallel execution"
        ]
      },
      "dagster": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Op graph with dependencies",
          "DynamicOutput for fan-out"
        ]
      }
    },
    "validation_warnings": []
  },
  "pipeline_summary": {
    "name": "airflow-log-cleanup",
    "description": "Comprehensive Pipeline Description",
    "flow_patterns": [
      "sequential",
      "parallel"
    ],
    "task_executors": [
      "bash"
    ],
    "complexity": "low"
  },
  "components": [
    {
      "id": "start_log_cleanup",
      "name": "Start Log Cleanup",
      "category": "Orchestrator",
      "description": "Initialize the log cleanup workflow as a starting point for all parallel workers",
      "inputs": [
        "dag_trigger"
      ],
      "outputs": [
        "trigger_parallel_workers"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": "0.1",
          "memory": "128Mi",
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "dag_trigger",
          "direction": "input",
          "kind": "object",
          "format": "other",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "trigger_parallel_workers",
          "direction": "output",
          "kind": "object",
          "format": "other",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "none_failed",
        "description": "Starts immediately when DAG is triggered",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 60,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "system_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "cleanup_log_directory",
      "name": "Cleanup Log Directory",
      "category": "Other",
      "description": "Execute parallel log cleanup operations across multiple workers and directories. Performs three-phase cleanup: old files, empty subdirectories, empty parent directories. Uses image default entrypoint/command",
      "inputs": [
        "directory_path",
        "max_log_age_days"
      ],
      "outputs": [
        "cleaned_directory"
      ],
      "executor_type": "bash",
      "executor_config": {
        "image": "bash:latest",
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {
          "BASE_LOG_FOLDER": "{{ airflow_config.BASE_LOG_FOLDER }}",
          "CHILD_PROCESS_LOG_DIRECTORY": "{{ airflow_config.CHILD_PROCESS_LOG_DIRECTORY }}"
        },
        "resources": {
          "cpu": "0.5",
          "memory": "256Mi",
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "directory_path",
          "direction": "input",
          "kind": "file",
          "format": "other",
          "path_pattern": "{{ directory }}",
          "connection_id": null
        },
        {
          "name": "max_log_age_days",
          "direction": "input",
          "kind": "object",
          "format": "other",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "cleaned_directory",
          "direction": "output",
          "kind": "file",
          "format": "other",
          "path_pattern": "{{ directory }}",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Executes after start task completes successfully",
        "timeout_seconds": 3600
      },
      "retry_policy": {
        "max_attempts": 1,
        "delay_seconds": 60,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "system_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": true,
        "supports_dynamic_mapping": true,
        "map_over_param": "directory",
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "airflow_filesystem",
          "type": "filesystem",
          "purpose": "Access to log directories for cleanup"
        }
      ],
      "datasets": {
        "consumes": [
          "airflow_logs"
        ],
        "produces": [
          "cleaned_airflow_logs"
        ]
      }
    }
  ],
  "flow_structure": {
    "pattern": "parallel",
    "entry_points": [
      "start_log_cleanup"
    ],
    "nodes": {
      "start_log_cleanup": {
        "kind": "Task",
        "component_type_id": "start_log_cleanup",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "cleanup_log_directory"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "cleanup_log_directory": {
        "kind": "Task",
        "component_type_id": "cleanup_log_directory",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      }
    },
    "edges": [
      {
        "from": "start_log_cleanup",
        "to": "cleanup_log_directory",
        "edge_type": "success",
        "metadata": {}
      }
    ]
  },
  "parameters": {
    "pipeline": {
      "name": {
        "description": "Pipeline identifier",
        "type": "string",
        "default": "airflow-log-cleanup",
        "required": true,
        "constraints": null
      },
      "description": {
        "description": "Pipeline description",
        "type": "string",
        "default": "Comprehensive Pipeline Description",
        "required": false,
        "constraints": null
      },
      "tags": {
        "description": "Classification tags",
        "type": "array",
        "default": [
          "teamclairvoyant",
          "airflow-maintenance-dags"
        ],
        "required": false
      }
    },
    "schedule": {
      "enabled": {
        "description": "Whether pipeline runs on schedule",
        "type": "boolean",
        "default": true,
        "required": false
      },
      "cron_expression": {
        "description": "Cron or preset (e.g., @daily, 0 0 * * *)",
        "type": "string",
        "default": "@daily",
        "required": false
      },
      "start_date": {
        "description": "When to start scheduling",
        "type": "datetime",
        "default": "days_ago(1)",
        "required": false,
        "format": "ISO8601"
      },
      "end_date": {
        "description": "When to stop scheduling",
        "type": "datetime",
        "default": null,
        "required": false
      },
      "timezone": {
        "description": "Schedule timezone",
        "type": "string",
        "default": null,
        "required": false
      },
      "catchup": {
        "description": "Run missed intervals",
        "type": "boolean",
        "default": false,
        "required": false
      },
      "batch_window": {
        "description": "Batch window parameter name (e.g., ds, execution_date)",
        "type": "string",
        "default": null,
        "required": false
      },
      "partitioning": {
        "description": "Data partitioning strategy (e.g., daily, hourly, monthly)",
        "type": "string",
        "default": "daily",
        "required": false
      }
    },
    "execution": {
      "max_active_runs": {
        "description": "Max concurrent pipeline runs",
        "type": "integer",
        "default": null,
        "required": false
      },
      "timeout_seconds": {
        "description": "Pipeline execution timeout",
        "type": "integer",
        "default": null,
        "required": false
      },
      "retry_policy": {
        "description": "Pipeline-level retry behavior",
        "type": "object",
        "default": {
          "retries": 1,
          "retry_delay_minutes": 1
        },
        "required": false
      },
      "depends_on_past": {
        "description": "Whether execution depends on previous run success",
        "type": "boolean",
        "default": false,
        "required": false
      }
    },
    "components": {
      "start_log_cleanup": {
        "name": {
          "description": "Component name",
          "type": "string",
          "default": "Start Log Cleanup",
          "required": false
        },
        "category": {
          "description": "Component category",
          "type": "string",
          "default": "Orchestrator",
          "required": false
        },
        "executor_type": {
          "description": "Execution mechanism type",
          "type": "string",
          "default": "python",
          "required": false
        }
      },
      "cleanup_log_directory": {
        "name": {
          "description": "Component name",
          "type": "string",
          "default": "Cleanup Log Directory",
          "required": false
        },
        "category": {
          "description": "Component category",
          "type": "string",
          "default": "Other",
          "required": false
        },
        "executor_type": {
          "description": "Execution mechanism type",
          "type": "string",
          "default": "bash",
          "required": false
        },
        "directory": {
          "description": "Target directory path from DIRECTORIES_TO_DELETE",
          "type": "string",
          "default": null,
          "required": true
        },
        "sleep_time": {
          "description": "Worker-specific delay (log_cleanup_id * 3 seconds) for staggered execution",
          "type": "integer",
          "default": null,
          "required": false
        },
        "lock_file_path": {
          "description": "Lock file path for worker coordination",
          "type": "string",
          "default": "/tmp/airflow_log_cleanup_worker.lock",
          "required": false
        },
        "max_log_age_days": {
          "description": "Maximum age of logs to retain (from DAG run conf or Airflow Variable)",
          "type": "integer",
          "default": null,
          "required": false
        },
        "enable_child_log_cleanup": {
          "description": "Whether to clean up child process log directories",
          "type": "boolean",
          "default": null,
          "required": false
        }
      }
    },
    "environment": {
      "ALERT_EMAIL_ADDRESSES": {
        "description": "Email addresses for failure alerts",
        "type": "array",
        "default": null,
        "required": false,
        "associated_component_id": null
      },
      "BASE_LOG_FOLDER": {
        "description": "Airflow base log folder path",
        "type": "string",
        "default": null,
        "required": false,
        "associated_component_id": "cleanup_log_directory"
      },
      "CHILD_PROCESS_LOG_DIRECTORY": {
        "description": "Airflow child process log directory path",
        "type": "string",
        "default": null,
        "required": false,
        "associated_component_id": "cleanup_log_directory"
      },
      "NUMBER_OF_WORKERS": {
        "description": "Number of parallel workers for log cleanup",
        "type": "integer",
        "default": 1,
        "required": false,
        "associated_component_id": "cleanup_log_directory"
      },
      "DIRECTORIES_TO_DELETE": {
        "description": "List of directories to perform log cleanup on",
        "type": "array",
        "default": null,
        "required": false,
        "associated_component_id": "cleanup_log_directory"
      },
      "airflow_log_cleanup__max_log_age_in_days": {
        "description": "Airflow Variable for maximum log age in days",
        "type": "integer",
        "default": null,
        "required": false,
        "associated_component_id": "cleanup_log_directory"
      },
      "airflow_log_cleanup__enable_delete_child_log": {
        "description": "Airflow Variable to enable child log deletion",
        "type": "boolean",
        "default": null,
        "required": false,
        "associated_component_id": "cleanup_log_directory"
      }
    }
  },
  "integrations": {
    "connections": [
      {
        "id": "airflow_base_log_folder",
        "name": "Airflow Base Log Folder",
        "type": "filesystem",
        "config": {
          "base_path": null,
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": "file",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "cleanup_log_directory"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [],
          "consumes": [
            "airflow_logs"
          ]
        }
      },
      {
        "id": "airflow_child_process_log_dir",
        "name": "Airflow Child Process Log Directory",
        "type": "filesystem",
        "config": {
          "base_path": null,
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": "file",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "cleanup_log_directory"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [],
          "consumes": [
            "child_process_logs"
          ]
        }
      },
      {
        "id": "worker_lock_file",
        "name": "Worker Lock File",
        "type": "filesystem",
        "config": {
          "base_path": "/tmp/airflow_log_cleanup_worker.lock",
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": "file",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "cleanup_log_directory"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "lock_status"
          ],
          "consumes": []
        }
      },
      {
        "id": "airflow_variables_store",
        "name": "Airflow Variables Store",
        "type": "other",
        "config": {
          "base_path": null,
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": null,
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "cleanup_log_directory"
        ],
        "direction": "input",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [],
          "consumes": [
            "airflow_log_cleanup__max_log_age_in_days",
            "airflow_log_cleanup__enable_delete_child_log"
          ]
        }
      },
      {
        "id": "email_alert_system",
        "name": "Email Alert System",
        "type": "other",
        "config": {
          "base_path": null,
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": null,
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "cleanup_log_directory"
        ],
        "direction": "output",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "failure_alerts"
          ],
          "consumes": []
        }
      }
    ],
    "data_lineage": {
      "sources": [
        "Airflow base log folder containing task execution logs",
        "Airflow child process log directory with scheduler subprocess logs",
        "Airflow Variables store with configuration parameters",
        "DAG run configuration providing max log age settings"
      ],
      "sinks": [
        "Cleaned filesystem with old log files removed",
        "Email alert system for failure notifications"
      ],
      "intermediate_datasets": [
        "lock_status",
        "airflow_logs",
        "child_process_logs"
      ]
    }
  }
}