# Generated by Airflow DAG generator on 2024-06-13
"""
Airflow DAG: PM2.5_Risk_Alert_Pipeline
Description: Comprehensive Pipeline Description
Pattern: sequential
"""

from datetime import datetime, timedelta

import requests
import json
import smtplib
from email.mime.text import MIMEText

import psycopg2
from bs4 import BeautifulSoup

from airflow import DAG
from airflow.decorators import task
from airflow.operators.empty import EmptyOperator
from airflow.operators.python import BranchPythonOperator
from airflow.utils.trigger_rule import TriggerRule
from airflow.models import Variable
from airflow.hooks.base import BaseHook

# Default arguments for all tasks
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "retries": 0,
    "retry_delay": timedelta(minutes=5),
    "email_on_failure": False,
    "email_on_retry": False,
}

# DAG definition
with DAG(
    dag_id="PM2.5_Risk_Alert_Pipeline",
    description="Comprehensive Pipeline Description",
    schedule_interval=None,  # Disabled schedule
    start_date=datetime(2024, 1, 1),
    catchup=False,
    default_args=default_args,
    tags=["pm2.5", "aqi", "mahidol"],
    max_active_runs=1,
) as dag:

    @task(task_id="extract_mahidol_aqi_html")
    def extract_mahidol_aqi_html() -> str:
        """
        Pulls the AQI HTML page from Mahidol University website.
        Returns the raw HTML as a string.
        """
        conn = BaseHook.get_connection("mahidol_aqi_website")
        url = conn.host  # Assuming the host field contains the full URL
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        return response.text

    @task(task_id="transform_mahidol_aqi_json")
    def transform_mahidol_aqi_json(html: str) -> dict:
        """
        Parses the HTML and extracts AQI data into a JSON‑compatible dict.
        """
        soup = BeautifulSoup(html, "html.parser")
        # Placeholder parsing logic – adapt to actual page structure
        aqi_data = {}
        for row in soup.select("table#aqi-data tr"):
            cols = row.find_all("td")
            if len(cols) >= 2:
                location = cols[0].get_text(strip=True)
                value = cols[1].get_text(strip=True)
                aqi_data[location] = {"pm25": float(value)}
        return aqi_data

    # -------------------------------------------------------------------------
    # Branch: duplicate_check_branch
    # -------------------------------------------------------------------------
    def duplicate_check_branch(**context):
        """
        Checks whether the extracted data already exists in PostgreSQL.
        Returns the task_id of the downstream task to execute.
        """
        aqi_json = context["ti"].xcom_pull(task_ids="transform_mahidol_aqi_json")
        if not aqi_json:
            return "skip_load"

        conn = BaseHook.get_connection("postgres_warehouse")
        pg_conn = psycopg2.connect(
            dbname=conn.schema,
            user=conn.login,
            password=conn.password,
            host=conn.host,
            port=conn.port,
        )
        try:
            with pg_conn.cursor() as cur:
                # Simple existence check – replace with real logic
                cur.execute("SELECT COUNT(*) FROM aqi_measurements;")
                count = cur.fetchone()[0]
                if count > 0:
                    return "skip_load"
        finally:
            pg_conn.close()
        return "load_mahidol_aqi_postgres"

    duplicate_check = BranchPythonOperator(
        task_id="duplicate_check_branch",
        python_callable=duplicate_check_branch,
        provide_context=True,
    )

    skip_load = EmptyOperator(task_id="skip_load", trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)

    @task(task_id="load_mahidol_aqi_postgres")
    def load_mahidol_aqi_postgres(aqi_json: dict):
        """
        Loads the AQI JSON data into PostgreSQL.
        """
        conn = BaseHook.get_connection("postgres_warehouse")
        pg_conn = psycopg2.connect(
            dbname=conn.schema,
            user=conn.login,
            password=conn.password,
            host=conn.host,
            port=conn.port,
        )
        try:
            with pg_conn.cursor() as cur:
                for location, data in aqi_json.items():
                    cur.execute(
                        """
                        INSERT INTO aqi_measurements (location, pm25, measured_at)
                        VALUES (%s, %s, %s)
                        """,
                        (location, data["pm25"], datetime.utcnow()),
                    )
                pg_conn.commit()
        finally:
            pg_conn.close()

    # -------------------------------------------------------------------------
    # Branch: alert_decision_branch
    # -------------------------------------------------------------------------
    def alert_decision_branch(**context):
        """
        Determines whether a PM2.5 alert should be sent.
        Returns the task_id of the downstream task to execute.
        """
        aqi_json = context["ti"].xcom_pull(task_ids="transform_mahidol_aqi_json")
        threshold = float(Variable.get("pm25_alert_threshold", default_var=35.0))
        for data in aqi_json.values():
            if data["pm25"] >= threshold:
                return "notify_pm25_email"
        return "skip_notify"

    alert_decision = BranchPythonOperator(
        task_id="alert_decision_branch",
        python_callable=alert_decision_branch,
        provide_context=True,
    )

    skip_notify = EmptyOperator(task_id="skip_notify", trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)

    @task(task_id="notify_pm25_email")
    def notify_pm25_email(aqi_json: dict):
        """
        Sends an email alert if PM2.5 exceeds the threshold.
        """
        conn = BaseHook.get_connection("smtp_gmail")
        smtp_host = conn.host
        smtp_port = conn.port or 587
        smtp_user = conn.login
        smtp_password = conn.password

        # Build email content
        subject = "PM2.5 Alert – High AQI Detected"
        body_lines = ["The following locations have PM2.5 levels above the threshold:\n"]
        threshold = float(Variable.get("pm25_alert_threshold", default_var=35.0))
        for location, data in aqi_json.items():
            if data["pm25"] >= threshold:
                body_lines.append(f"- {location}: {data['pm25']} µg/m³")
        body = "\n".join(body_lines)

        msg = MIMEText(body)
        msg["Subject"] = subject
        msg["From"] = smtp_user
        msg["To"] = Variable.get("alert_recipient_email", default_var="alerts@example.com")

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_password)
            server.send_message(msg)

    # -------------------------------------------------------------------------
    # Define task pipeline
    # -------------------------------------------------------------------------
    html = extract_mahidol_aqi_html()
    aqi_json = transform_mahidol_aqi_json(html)

    # Branches
    duplicate_check >> [load_mahidol_aqi_postgres, skip_load]
    alert_decision >> [notify_pm25_email, skip_notify]

    # Set upstream dependencies
    aqi_json >> duplicate_check
    aqi_json >> alert_decision

    # Ensure load and notify tasks receive the JSON via XCom
    load_mahidol_aqi_postgres(aqi_json)
    notify_pm25_email(aqi_json)