# Generated by Prefect Pipeline Generator
# Date: 2024-06-28
# Pipeline: download_noaa_pipeline
# Description: No description provided.
# Pattern: fanin
# Prefect version: 2.14.0

from __future__ import annotations

import pathlib
import shutil
import tempfile
from typing import List

import httpx
from ftplib import FTP

from prefect import flow, task, get_run_logger
from prefect.task_runners import ConcurrentTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.server.schemas.schedules import CronSchedule
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem


# -------------------------------------------------------------------------
# Helper Functions
# -------------------------------------------------------------------------

def _get_secret(block_name: str) -> str:
    """Load a secret block and return its value."""
    secret = Secret.load(block_name)
    return secret.get()


def _save_to_local(data: bytes, filename: str) -> pathlib.Path:
    """Save binary data to the local filesystem block."""
    local_fs: LocalFileSystem = LocalFileSystem.load("local_filesystem")
    target_path = pathlib.Path(local_fs.base_path) / filename
    target_path.parent.mkdir(parents=True, exist_ok=True)
    target_path.write_bytes(data)
    return target_path


# -------------------------------------------------------------------------
# Download Tasks
# -------------------------------------------------------------------------

@task(retries=3, retry_delay_seconds=60)
def download_bom() -> pathlib.Path:
    """
    Download BOM data using the HTTPS endpoint secret.

    Returns:
        Path to the downloaded raw BOM file.
    """
    logger = get_run_logger()
    endpoint = _get_secret("https_bom")
    logger.info("Downloading BOM data from %s", endpoint)

    with httpx.Client() as client:
        response = client.get(endpoint, timeout=120)
        response.raise_for_status()
        data = response.content

    filename = "bom_raw.dat"
    path = _save_to_local(data, filename)
    logger.info("BOM data saved to %s", path)
    return path


@task(retries=3, retry_delay_seconds=60)
def download_ecmwf() -> pathlib.Path:
    """
    Download ECMWF data using the HTTPS endpoint secret.

    Returns:
        Path to the downloaded raw ECMWF file.
    """
    logger = get_run_logger()
    endpoint = _get_secret("https_ecmwf")
    logger.info("Downloading ECMWF data from %s", endpoint)

    with httpx.Client() as client:
        response = client.get(endpoint, timeout=120)
        response.raise_for_status()
        data = response.content

    filename = "ecmwf_raw.dat"
    path = _save_to_local(data, filename)
    logger.info("ECMWF data saved to %s", path)
    return path


@task(retries=3, retry_delay_seconds=60)
def download_jma() -> pathlib.Path:
    """
    Download JMA data using the HTTPS endpoint secret.

    Returns:
        Path to the downloaded raw JMA file.
    """
    logger = get_run_logger()
    endpoint = _get_secret("https_jma")
    logger.info("Downloading JMA data from %s", endpoint)

    with httpx.Client() as client:
        response = client.get(endpoint, timeout=120)
        response.raise_for_status()
        data = response.content

    filename = "jma_raw.dat"
    path = _save_to_local(data, filename)
    logger.info("JMA data saved to %s", path)
    return path


@task(retries=3, retry_delay_seconds=60)
def download_metoffice() -> pathlib.Path:
    """
    Download MetOffice data using the HTTPS endpoint secret.

    Returns:
        Path to the downloaded raw MetOffice file.
    """
    logger = get_run_logger()
    endpoint = _get_secret("https_metoffice")
    logger.info("Downloading MetOffice data from %s", endpoint)

    with httpx.Client() as client:
        response = client.get(endpoint, timeout=120)
        response.raise_for_status()
        data = response.content

    filename = "metoffice_raw.dat"
    path = _save_to_local(data, filename)
    logger.info("MetOffice data saved to %s", path)
    return path


@task(retries=3, retry_delay_seconds=60)
def download_noaa() -> pathlib.Path:
    """
    Download NOAA data using the FTP server secret.

    Returns:
        Path to the downloaded raw NOAA file.
    """
    logger = get_run_logger()
    ftp_info = _get_secret("ftp_noaa")  # Expected format: user:pass@host/path
    logger.info("Downloading NOAA data via FTP using secret %s", ftp_info)

    # Parse the secret
    try:
        credentials, host_path = ftp_info.split("@")
        user, password = credentials.split(":")
        host, remote_path = host_path.split("/", 1)
    except Exception as exc:
        raise ValueError(f"Invalid FTP secret format: {ftp_info}") from exc

    with FTP(host) as ftp:
        ftp.login(user=user, passwd=password)
        logger.info("Connected to FTP %s", host)

        with tempfile.TemporaryFile() as tmp_file:
            ftp.retrbinary(f"RETR /{remote_path}", tmp_file.write)
            tmp_file.seek(0)
            data = tmp_file.read()

    filename = "noaa_raw.dat"
    path = _save_to_local(data, filename)
    logger.info("NOAA data saved to %s", path)
    return path


# -------------------------------------------------------------------------
# Normalization Tasks
# -------------------------------------------------------------------------

def _normalize(data_path: pathlib.Path, source_name: str) -> pathlib.Path:
    """
    Simple placeholder normalization: copy file to a new location with a
    ``_norm`` suffix.

    Args:
        data_path: Path to the raw data file.
        source_name: Identifier for logging.

    Returns:
        Path to the normalized file.
    """
    logger = get_run_logger()
    logger.info("Normalizing %s data from %s", source_name, data_path)

    normalized_filename = data_path.name.replace("_raw", "_norm")
    normalized_path = data_path.parent / normalized_filename

    # Placeholder: just copy the file
    shutil.copyfile(data_path, normalized_path)

    logger.info("Normalized %s data saved to %s", source_name, normalized_path)
    return normalized_path


@task(retries=3, retry_delay_seconds=30)
def normalize_bom(raw_path: pathlib.Path) -> pathlib.Path:
    """Normalize BOM raw data."""
    return _normalize(raw_path, "BOM")


@task(retries=3, retry_delay_seconds=30)
def normalize_ecmwf(raw_path: pathlib.Path) -> pathlib.Path:
    """Normalize ECMWF raw data."""
    return _normalize(raw_path, "ECMWF")


@task(retries=3, retry_delay_seconds=30)
def normalize_jma(raw_path: pathlib.Path) -> pathlib.Path:
    """Normalize JMA raw data."""
    return _normalize(raw_path, "JMA")


@task(retries=3, retry_delay_seconds=30)
def normalize_metoffice(raw_path: pathlib.Path) -> pathlib.Path:
    """Normalize MetOffice raw data."""
    return _normalize(raw_path, "MetOffice")


@task(retries=3, retry_delay_seconds=30)
def normalize_noaa(raw_path: pathlib.Path) -> pathlib.Path:
    """Normalize NOAA raw data."""
    return _normalize(raw_path, "NOAA")


# -------------------------------------------------------------------------
# Merge Task
# -------------------------------------------------------------------------

@task(retries=3, retry_delay_seconds=60)
def merge_climate_data(
    bom_path: pathlib.Path,
    ecmwf_path: pathlib.Path,
    jma_path: pathlib.Path,
    metoffice_path: pathlib.Path,
    noaa_path: pathlib.Path,
) -> pathlib.Path:
    """
    Merge all normalized climate datasets into a single file.

    Returns:
        Path to the merged climate data file.
    """
    logger = get_run_logger()
    logger.info("Merging normalized climate data files")

    merged_filename = "merged_climate_data.dat"
    merged_path = pathlib.Path(bom_path.parent) / merged_filename

    with merged_path.open("wb") as merged_file:
        for p in [bom_path, ecmwf_path, jma_path, metoffice_path, noaa_path]:
            logger.info("Appending %s to merged file", p)
            merged_file.write(p.read_bytes())

    logger.info("Merged climate data saved to %s", merged_path)
    return merged_path


# -------------------------------------------------------------------------
# Flow Definition
# -------------------------------------------------------------------------

@flow(
    name="download_noaa_pipeline",
    task_runner=ConcurrentTaskRunner(),
)
def download_noaa_pipeline() -> pathlib.Path:
    """
    Orchestrates the download, normalization, and merging of climate data
    from multiple sources.
    """
    # Download stage (fan-out)
    bom_raw = download_bom()
    ecmwf_raw = download_ecmwf()
    jma_raw = download_jma()
    metoffice_raw = download_metoffice()
    noaa_raw = download_noaa()

    # Normalization stage (fan-out)
    bom_norm = normalize_bom(bom_raw)
    ecmwf_norm = normalize_ecmwf(ecmwf_raw)
    jma_norm = normalize_jma(jma_raw)
    metoffice_norm = normalize_metoffice(metoffice_raw)
    noaa_norm = normalize_noaa(noaa_raw)

    # Merge stage (fan-in)
    merged_path = merge_climate_data(
        bom_path=bom_norm,
        ecmwf_path=ecmwf_norm,
        jma_path=jma_norm,
        metoffice_path=metoffice_norm,
        noaa_path=noaa_norm,
    )
    return merged_path


# -------------------------------------------------------------------------
# Deployment Specification
# -------------------------------------------------------------------------

# The deployment will run daily at midnight UTC without catchup.
DeploymentSpec(
    name="download_noaa_pipeline_deployment",
    flow=download_noaa_pipeline,
    schedule=CronSchedule(cron="0 0 * * *", timezone="UTC", day_or=True),
    tags=[],
    parameters={},
    work_pool_name="default-agent-pool",
    enforce_parameter_schema=False,
    flow_runner=ConcurrentTaskRunner(),
    description="Daily execution of the download_noaa_pipeline.",
    # Catchup is disabled by default in Prefect 2.x; to be explicit:
    is_schedule_active=True,
    # Prefect 2.x does not have a direct catchup flag; set `catchup=False` in UI or via API.
)

if __name__ == "__main__":
    # Running the flow locally for testing/debugging
    result_path = download_noaa_pipeline()
    print(f"Pipeline completed. Merged file located at: {result_path}")