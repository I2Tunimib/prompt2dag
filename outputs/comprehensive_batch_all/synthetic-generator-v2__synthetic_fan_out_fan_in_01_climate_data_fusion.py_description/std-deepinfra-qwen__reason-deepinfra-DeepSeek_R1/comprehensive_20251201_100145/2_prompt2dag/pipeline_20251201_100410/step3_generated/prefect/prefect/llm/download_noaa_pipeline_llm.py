# Generated by Prefect 2.x Code Generator
# Generation Date: [Insert Date Here]
# Prefect Version: 2.14.0

from prefect import flow, task, get_run_logger
from prefect.task_runners import ConcurrentTaskRunner
from prefect.deployments import Deployment
from prefect.infrastructure.docker import DockerContainer
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem
from prefect import context
import requests
import ftplib
import pandas as pd

# Secrets
ftp_noaa = Secret.load("ftp_noaa")
https_ecmwf = Secret.load("https_ecmwf")
https_jma = Secret.load("https_jma")
https_metoffice = Secret.load("https_metoffice")
https_bom = Secret.load("https_bom")
xcom = Secret.load("xcom")

# Local File System
parquet_output = LocalFileSystem.load("parquet_output")

@task(retries=3, name="Download BOM Data")
def download_bom():
    logger = get_run_logger()
    url = https_bom.get()
    response = requests.get(url)
    if response.status_code == 200:
        logger.info("BOM data downloaded successfully")
        return response.content
    else:
        logger.error(f"Failed to download BOM data: {response.status_code}")
        raise Exception(f"Failed to download BOM data: {response.status_code}")

@task(retries=3, name="Download ECMWF Data")
def download_ecmwf():
    logger = get_run_logger()
    url = https_ecmwf.get()
    response = requests.get(url)
    if response.status_code == 200:
        logger.info("ECMWF data downloaded successfully")
        return response.content
    else:
        logger.error(f"Failed to download ECMWF data: {response.status_code}")
        raise Exception(f"Failed to download ECMWF data: {response.status_code}")

@task(retries=3, name="Download JMA Data")
def download_jma():
    logger = get_run_logger()
    url = https_jma.get()
    response = requests.get(url)
    if response.status_code == 200:
        logger.info("JMA data downloaded successfully")
        return response.content
    else:
        logger.error(f"Failed to download JMA data: {response.status_code}")
        raise Exception(f"Failed to download JMA data: {response.status_code}")

@task(retries=3, name="Download MetOffice Data")
def download_metoffice():
    logger = get_run_logger()
    url = https_metoffice.get()
    response = requests.get(url)
    if response.status_code == 200:
        logger.info("MetOffice data downloaded successfully")
        return response.content
    else:
        logger.error(f"Failed to download MetOffice data: {response.status_code}")
        raise Exception(f"Failed to download MetOffice data: {response.status_code}")

@task(retries=3, name="Download NOAA Data")
def download_noaa():
    logger = get_run_logger()
    ftp_server = ftp_noaa.get()
    ftp = ftplib.FTP(ftp_server)
    ftp.login()
    ftp.cwd('/data')
    data = ftp.retrbinary('RETR data.txt', open('data.txt', 'wb').write)
    ftp.quit()
    logger.info("NOAA data downloaded successfully")
    return open('data.txt', 'rb').read()

@task(retries=3, name="Normalize BOM Data")
def normalize_bom(data):
    logger = get_run_logger()
    df = pd.read_csv(pd.compat.StringIO(data.decode('utf-8')))
    logger.info("BOM data normalized successfully")
    return df

@task(retries=3, name="Normalize ECMWF Data")
def normalize_ecmwf(data):
    logger = get_run_logger()
    df = pd.read_csv(pd.compat.StringIO(data.decode('utf-8')))
    logger.info("ECMWF data normalized successfully")
    return df

@task(retries=3, name="Normalize JMA Data")
def normalize_jma(data):
    logger = get_run_logger()
    df = pd.read_csv(pd.compat.StringIO(data.decode('utf-8')))
    logger.info("JMA data normalized successfully")
    return df

@task(retries=3, name="Normalize MetOffice Data")
def normalize_metoffice(data):
    logger = get_run_logger()
    df = pd.read_csv(pd.compat.StringIO(data.decode('utf-8')))
    logger.info("MetOffice data normalized successfully")
    return df

@task(retries=3, name="Normalize NOAA Data")
def normalize_noaa(data):
    logger = get_run_logger()
    df = pd.read_csv(pd.compat.StringIO(data.decode('utf-8')))
    logger.info("NOAA data normalized successfully")
    return df

@task(retries=3, name="Merge Climate Data")
def merge_climate_data(bom, ecmwf, jma, metoffice, noaa):
    logger = get_run_logger()
    merged_df = pd.concat([bom, ecmwf, jma, metoffice, noaa])
    merged_df.to_parquet(parquet_output.path + '/merged_climate_data.parquet')
    logger.info("Climate data merged and saved successfully")

@flow(name="download_noaa_pipeline", task_runner=ConcurrentTaskRunner)
def download_noaa_pipeline():
    logger = get_run_logger()
    logger.info("Starting download_noaa_pipeline")

    bom_data = download_bom()
    ecmwf_data = download_ecmwf()
    jma_data = download_jma()
    metoffice_data = download_metoffice()
    noaa_data = download_noaa()

    normalized_bom = normalize_bom(bom_data)
    normalized_ecmwf = normalize_ecmwf(ecmwf_data)
    normalized_jma = normalize_jma(jma_data)
    normalized_metoffice = normalize_metoffice(metoffice_data)
    normalized_noaa = normalize_noaa(noaa_data)

    merge_climate_data(normalized_bom, normalized_ecmwf, normalized_jma, normalized_metoffice, normalized_noaa)

    logger.info("download_noaa_pipeline completed successfully")

# Schedule Configuration
deployment = Deployment.build_from_flow(
    flow=download_noaa_pipeline,
    name="download_noaa_pipeline_deployment",
    work_pool_name="default-agent-pool",
    schedule=(None, "0 0 * * *", None, False),
    parameters={},
    tags=[],
    work_queue_name="default",
    version="1.0.0",
    description="No description provided.",
    enforce_parameter_schema=False,
)

if __name__ == "__main__":
    deployment.apply()
```
This code defines a Prefect 2.x flow named `download_noaa_pipeline` with the specified tasks and dependencies. The flow is scheduled to run daily and uses a concurrent task runner. Each task has error handling with retries set to 3. The flow is also configured to use the specified secrets and local file system for data storage.