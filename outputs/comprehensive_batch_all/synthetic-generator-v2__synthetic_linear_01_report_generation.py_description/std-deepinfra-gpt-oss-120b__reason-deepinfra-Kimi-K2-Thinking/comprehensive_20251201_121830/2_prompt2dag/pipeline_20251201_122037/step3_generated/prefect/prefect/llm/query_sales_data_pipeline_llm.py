# Generated by Prefect Pipeline Generator
# Date: 2024-06-30
# Prefect version: 2.14.0
# Pipeline: query_sales_data_pipeline

import os
import smtplib
import ssl
import datetime
from email.message import EmailMessage
from typing import List

import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import psycopg2
from psycopg2.extras import RealDictCursor

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.server.schemas.schedules import CronSchedule
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem


@task(retries=2, retry_delay_seconds=60)
def query_sales_data(query_date: datetime.date) -> pd.DataFrame:
    """
    Query daily sales data from the PostgreSQL sales database.

    Args:
        query_date: The date for which to retrieve sales data.

    Returns:
        A pandas DataFrame containing the sales records.
    """
    logger = get_run_logger()
    logger.info("Loading PostgreSQL credentials from Secret block 'postgres_sales_db'.")
    db_secret = Secret.load("postgres_sales_db")
    conn_str = db_secret.get()  # Expected format: postgresql://user:pass@host:port/dbname

    sql = """
        SELECT
            order_id,
            order_timestamp,
            product_id,
            quantity,
            total_amount
        FROM sales
        WHERE DATE(order_timestamp) = %s;
    """

    logger.info("Connecting to PostgreSQL database.")
    with psycopg2.connect(conn_str, cursor_factory=RealDictCursor) as conn:
        with conn.cursor() as cur:
            logger.info("Executing sales query for date %s.", query_date)
            cur.execute(sql, (query_date,))
            rows = cur.fetchall()

    logger.info("Fetched %d rows.", len(rows))
    df = pd.DataFrame(rows)
    return df


@task
def transform_to_csv(sales_df: pd.DataFrame, query_date: datetime.date) -> str:
    """
    Transform the sales DataFrame into a CSV file stored on the local temporary filesystem.

    Args:
        sales_df: DataFrame containing sales data.
        query_date: The date associated with the data (used for naming).

    Returns:
        The absolute path to the generated CSV file.
    """
    logger = get_run_logger()
    logger.info("Loading LocalFileSystem block 'local_tmp_fs'.")
    tmp_fs: LocalFileSystem = LocalFileSystem.load("local_tmp_fs")
    base_path = tmp_fs.basepath

    csv_filename = f"sales_{query_date}.csv"
    csv_path = os.path.join(base_path, csv_filename)

    logger.info("Writing CSV to %s.", csv_path)
    sales_df.to_csv(csv_path, index=False)
    return csv_path


@task
def generate_pdf_chart(csv_path: str, query_date: datetime.date) -> str:
    """
    Generate a PDF report containing a sales chart from the CSV data.

    Args:
        csv_path: Path to the CSV file with sales data.
        query_date: The date associated with the data (used for naming).

    Returns:
        The absolute path to the generated PDF file.
    """
    logger = get_run_logger()
    logger.info("Reading CSV data from %s.", csv_path)
    df = pd.read_csv(csv_path)

    if df.empty:
        logger.warning("CSV file %s is empty. Generating empty PDF.", csv_path)

    # Example chart: total sales amount per hour
    df["order_timestamp"] = pd.to_datetime(df["order_timestamp"])
    df["hour"] = df["order_timestamp"].dt.hour
    hourly_sales = df.groupby("hour")["total_amount"].sum()

    plt.figure(figsize=(8, 6))
    hourly_sales.plot(kind="bar", color="steelblue")
    plt.title(f"Total Sales Amount per Hour - {query_date}")
    plt.xlabel("Hour of Day")
    plt.ylabel("Total Sales Amount")
    plt.tight_layout()

    logger.info("Loading LocalFileSystem block 'local_tmp_fs' for PDF output.")
    tmp_fs: LocalFileSystem = LocalFileSystem.load("local_tmp_fs")
    pdf_filename = f"sales_report_{query_date}.pdf"
    pdf_path = os.path.join(tmp_fs.basepath, pdf_filename)

    logger.info("Saving PDF chart to %s.", pdf_path)
    with PdfPages(pdf_path) as pdf:
        pdf.savefig()
        plt.close()

    return pdf_path


@task(retries=2, retry_delay_seconds=60)
def email_sales_report(pdf_path: str, query_date: datetime.date):
    """
    Email the generated PDF sales report to management.

    Args:
        pdf_path: Path to the PDF report file.
        query_date: The date associated with the report (used in email subject).
    """
    logger = get_run_logger()
    logger.info("Loading SMTP credentials from Secret block 'email_smtp'.")
    smtp_secret = Secret.load("email_smtp")
    smtp_config = smtp_secret.get()  # Expected dict with keys: host, port, username, password, from_addr, to_addrs

    host = smtp_config["host"]
    port = smtp_config.get("port", 587)
    username = smtp_config["username"]
    password = smtp_config["password"]
    from_addr = smtp_config["from_addr"]
    to_addrs = smtp_config["to_addrs"]  # List of recipient emails

    subject = f"Daily Sales Report - {query_date}"
    body = f"Please find attached the sales report for {query_date}."

    logger.info("Composing email.")
    msg = EmailMessage()
    msg["Subject"] = subject
    msg["From"] = from_addr
    msg["To"] = ", ".join(to_addrs)
    msg.set_content(body)

    logger.info("Attaching PDF report %s.", pdf_path)
    with open(pdf_path, "rb") as f:
        pdf_data = f.read()
    msg.add_attachment(pdf_data, maintype="application", subtype="pdf", filename=os.path.basename(pdf_path))

    logger.info("Sending email via SMTP server %s:%s.", host, port)
    context = ssl.create_default_context()
    with smtplib.SMTP(host, port) as server:
        server.starttls(context=context)
        server.login(username, password)
        server.send_message(msg)

    logger.info("Email sent successfully.")


@flow(
    name="query_sales_data_pipeline",
    task_runner=SequentialTaskRunner(),
)
def query_sales_data_pipeline():
    """
    Sequential pipeline that:
    1. Queries daily sales data from PostgreSQL.
    2. Writes the data to a CSV file.
    3. Generates a PDF chart from the CSV.
    4. Emails the PDF report to management.
    """
    logger = get_run_logger()
    run_date = datetime.date.today() - datetime.timedelta(days=1)  # Assume we report on previous day
    logger.info("Pipeline execution date (reporting day): %s", run_date)

    # Step 1: Query sales data
    sales_df = query_sales_data(run_date)

    # Step 2: Transform to CSV
    csv_path = transform_to_csv(sales_df, run_date)

    # Step 3: Generate PDF chart
    pdf_path = generate_pdf_chart(csv_path, run_date)

    # Step 4: Email the report
    email_sales_report(pdf_path, run_date)


# Deployment specification
DeploymentSpec(
    name="query_sales_data_pipeline_deployment",
    flow=query_sales_data_pipeline,
    schedule=CronSchedule(cron="0 0 * * *", timezone="UTC"),  # @daily at midnight UTC
    paused=True,  # Disabled by default
    work_pool_name="default-agent-pool",
    tags=["sales", "daily-report"],
    parameters={},  # No external parameters required
)