# Generated by Prefect Pipeline Generator
# Date: 2024-06-28
# Pipeline: Daily Sales Report
# Description: Sequential pipeline that queries PostgreSQL, converts data to CSV,
# generates a PDF chart, and emails the report.

import os
import smtplib
import ssl
from datetime import datetime
from email.message import EmailMessage
from pathlib import Path
from typing import Any

import pandas as pd
import matplotlib.pyplot as plt
from sqlalchemy import create_engine, text

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.orion.schemas.schedules import CronSchedule
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem

# -------------------------------------------------------------------------
# Helper Functions
# -------------------------------------------------------------------------

def _load_secret(block_name: str) -> Secret:
    """Load a Prefect Secret block."""
    try:
        return Secret.load(block_name)
    except Exception as exc:
        raise RuntimeError(f"Unable to load secret block '{block_name}': {exc}") from exc


def _load_filesystem(block_name: str) -> LocalFileSystem:
    """Load a Prefect LocalFileSystem block."""
    try:
        return LocalFileSystem.load(block_name)
    except Exception as exc:
        raise RuntimeError(f"Unable to load filesystem block '{block_name}': {exc}") from exc


# -------------------------------------------------------------------------
# Tasks
# -------------------------------------------------------------------------

@task(retries=2, retry_delay_seconds=30, timeout_seconds=300)
def query_sales_data() -> pd.DataFrame:
    """
    Query the PostgreSQL sales database for today's sales records.

    Returns:
        pandas.DataFrame: DataFrame containing the sales data.
    """
    logger = get_run_logger()
    logger.info("Loading PostgreSQL connection secret.")
    pg_secret = _load_secret("postgres_sales_db")
    conn_str = pg_secret.get()  # Expected to be a full SQLAlchemy URL

    logger.info("Creating SQLAlchemy engine.")
    engine = create_engine(conn_str)

    query = text(
        """
        SELECT *
        FROM sales
        WHERE sale_date = CURRENT_DATE
        """
    )
    logger.info("Executing query for today's sales.")
    with engine.connect() as conn:
        df = pd.read_sql_query(query, conn)

    logger.info("Retrieved %d rows.", len(df))
    return df


@task(retries=2, retry_delay_seconds=30, timeout_seconds=300)
def transform_to_csv(sales_df: pd.DataFrame) -> str:
    """
    Transform the sales DataFrame into a CSV file stored on the local temporary filesystem.

    Args:
        sales_df (pd.DataFrame): DataFrame with sales data.

    Returns:
        str: Path to the generated CSV file.
    """
    logger = get_run_logger()
    logger.info("Loading local temporary filesystem block.")
    tmp_fs = _load_filesystem("local_tmp_fs")

    timestamp = datetime.utcnow().strftime("%Y%m%d")
    csv_filename = f"sales_report_{timestamp}.csv"
    csv_path = Path(tmp_fs.base_path) / csv_filename

    logger.info("Writing CSV to %s.", csv_path)
    sales_df.to_csv(csv_path, index=False)

    # Ensure the file is visible to other tasks via the block's base_path
    logger.info("CSV file written successfully.")
    return str(csv_path)


@task(retries=2, retry_delay_seconds=30, timeout_seconds=600)
def generate_pdf_chart(csv_path: str) -> str:
    """
    Generate a PDF chart from the CSV sales data.

    Args:
        csv_path (str): Path to the CSV file containing sales data.

    Returns:
        str: Path to the generated PDF chart.
    """
    logger = get_run_logger()
    logger.info("Loading sales data from CSV: %s", csv_path)
    df = pd.read_csv(csv_path)

    if df.empty:
        raise ValueError("CSV file contains no data; cannot generate chart.")

    # Example chart: total sales per product
    logger.info("Aggregating sales by product.")
    agg = df.groupby("product_name")["sale_amount"].sum().reset_index()

    plt.figure(figsize=(10, 6))
    plt.bar(agg["product_name"], agg["sale_amount"], color="steelblue")
    plt.title("Total Sales per Product")
    plt.xlabel("Product")
    plt.ylabel("Sales Amount")
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()

    timestamp = datetime.utcnow().strftime("%Y%m%d")
    pdf_filename = f"sales_chart_{timestamp}.pdf"
    pdf_path = Path(csv_path).parent / pdf_filename

    logger.info("Saving PDF chart to %s.", pdf_path)
    plt.savefig(pdf_path, format="pdf")
    plt.close()

    logger.info("PDF chart generated successfully.")
    return str(pdf_path)


@task(retries=2, retry_delay_seconds=30, timeout_seconds=300)
def email_sales_report(csv_path: str, pdf_path: str) -> None:
    """
    Email the sales report CSV and PDF chart to the stakeholders.

    Args:
        csv_path (str): Path to the CSV report.
        pdf_path (str): Path to the PDF chart.
    """
    logger = get_run_logger()
    logger.info("Loading SMTP credentials from secret block.")
    smtp_secret = _load_secret("email_smtp_service")
    smtp_cfg = smtp_secret.get()  # Expected to be a dict with keys: host, port, username, password, use_tls, from_addr, to_addrs

    required_keys = {"host", "port", "username", "password", "use_tls", "from_addr", "to_addrs"}
    if not required_keys.issubset(smtp_cfg):
        missing = required_keys - set(smtp_cfg.keys())
        raise KeyError(f"Missing SMTP configuration keys: {missing}")

    message = EmailMessage()
    message["Subject"] = f"Daily Sales Report - {datetime.utcnow().strftime('%Y-%m-%d')}"
    message["From"] = smtp_cfg["from_addr"]
    message["To"] = ", ".join(smtp_cfg["to_addrs"])
    message.set_content("Please find attached the daily sales CSV report and the PDF chart.")

    # Attach CSV
    logger.info("Attaching CSV report: %s", csv_path)
    with open(csv_path, "rb") as f:
        csv_data = f.read()
    message.add_attachment(csv_data, maintype="text", subtype="csv", filename=os.path.basename(csv_path))

    # Attach PDF
    logger.info("Attaching PDF chart: %s", pdf_path)
    with open(pdf_path, "rb") as f:
        pdf_data = f.read()
    message.add_attachment(pdf_data, maintype="application", subtype="pdf", filename=os.path.basename(pdf_path))

    # Send email
    logger.info("Connecting to SMTP server %s:%s", smtp_cfg["host"], smtp_cfg["port"])
    context = ssl.create_default_context()
    try:
        if smtp_cfg["use_tls"]:
            with smtplib.SMTP(smtp_cfg["host"], smtp_cfg["port"]) as server:
                server.starttls(context=context)
                server.login(smtp_cfg["username"], smtp_cfg["password"])
                server.send_message(message)
        else:
            with smtplib.SMTP_SSL(smtp_cfg["host"], smtp_cfg["port"], context=context) as server:
                server.login(smtp_cfg["username"], smtp_cfg["password"])
                server.send_message(message)
        logger.info("Email sent successfully to %s.", smtp_cfg["to_addrs"])
    except Exception as exc:
        logger.error("Failed to send email: %s", exc)
        raise


# -------------------------------------------------------------------------
# Flow Definition
# -------------------------------------------------------------------------

@flow(
    name="Daily Sales Report",
    description="Sequential pipeline that generates daily sales reports.",
    task_runner=SequentialTaskRunner(),
)
def daily_sales_report_flow() -> None:
    """
    Orchestrates the daily sales reporting pipeline.
    """
    logger = get_run_logger()
    logger.info("Starting Daily Sales Report pipeline.")

    # Step 1: Query sales data
    sales_df = query_sales_data()

    # Step 2: Transform to CSV
    csv_path = transform_to_csv(sales_df)

    # Step 3: Generate PDF chart
    pdf_path = generate_pdf_chart(csv_path)

    # Step 4: Email the report
    email_sales_report(csv_path, pdf_path)

    logger.info("Daily Sales Report pipeline completed successfully.")


# -------------------------------------------------------------------------
# Deployment Specification
# -------------------------------------------------------------------------

# The deployment will be created when this module is imported by Prefect.
# It uses a daily cron schedule in UTC and disables catchup.
DeploymentSpec(
    name="daily_sales_report_deployment",
    flow=daily_sales_report_flow,
    schedule=CronSchedule(cron="0 0 * * *", timezone="UTC", day_or=True),  # @daily at 00:00 UTC
    tags=["daily", "sales", "report"],
    parameters={},
    work_pool_name="default-agent-pool",
    description="Deployment for the Daily Sales Report flow.",
    enforce_parameter_schema=False,
    flow_runner=SequentialTaskRunner(),
    is_schedule_active=True,
    catchup=False,
)

# End of file.