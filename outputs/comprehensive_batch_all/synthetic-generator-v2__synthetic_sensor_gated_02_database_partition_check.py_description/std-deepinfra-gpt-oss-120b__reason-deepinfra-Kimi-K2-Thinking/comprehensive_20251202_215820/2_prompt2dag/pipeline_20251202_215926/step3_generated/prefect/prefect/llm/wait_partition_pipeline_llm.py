# -*- coding: utf-8 -*-
"""
Generated by Prefect pipeline generator
Pipeline: wait_partition_pipeline
Description: No description provided.
Pattern: sequential
Prefect version: 2.14.0
"""

from __future__ import annotations

import logging
from typing import Any

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.blocks.system import Secret

# ----------------------------------------------------------------------
# Helper to load the database connection secret
# ----------------------------------------------------------------------


def get_database_connection() -> str:
    """
    Retrieve the database connection string from a Prefect Secret block.

    Returns
    -------
    str
        The database connection string.
    """
    try:
        secret_block = Secret.load("database_conn")
        return secret_block.get()
    except Exception as exc:
        logging.error("Failed to load database connection secret: %s", exc)
        raise


# ----------------------------------------------------------------------
# Tasks
# ----------------------------------------------------------------------


@task(retries=2, retry_delay_seconds=30, name="Wait for Daily Orders Partition")
def wait_partition(db_conn: str) -> None:
    """
    Wait until the daily orders partition becomes available.

    Parameters
    ----------
    db_conn : str
        Database connection string.
    """
    logger = get_run_logger()
    logger.info("Checking for daily orders partition using connection: %s", db_conn)
    # Placeholder logic – replace with real implementation
    # e.g., query the source DB for the existence of today's partition
    logger.info("Partition is now available.")


@task(retries=2, retry_delay_seconds=30, name="Extract Incremental Orders")
def extract_incremental(db_conn: str) -> list[dict[str, Any]]:
    """
    Extract incremental orders from the source database.

    Parameters
    ----------
    db_conn : str
        Database connection string.

    Returns
    -------
    list[dict[str, Any]]
        List of order records.
    """
    logger = get_run_logger()
    logger.info("Extracting incremental orders using connection: %s", db_conn)
    # Placeholder extraction – replace with real query logic
    orders = [{"order_id": 1, "amount": 100.0}, {"order_id": 2, "amount": 250.0}]
    logger.info("Extracted %d orders.", len(orders))
    return orders


@task(retries=2, retry_delay_seconds=30, name="Transform Orders Data")
def transform(orders: list[dict[str, Any]]) -> list[dict[str, Any]]:
    """
    Transform raw order data into the schema required by the data warehouse.

    Parameters
    ----------
    orders : list[dict[str, Any]]
        Raw order records.

    Returns
    -------
    list[dict[str, Any]]
        Transformed order records.
    """
    logger = get_run_logger()
    logger.info("Transforming %d orders.", len(orders))
    # Placeholder transformation – replace with real logic
    transformed = [
        {
            "order_id": o["order_id"],
            "total_amount_usd": o["amount"],
            "processed_timestamp": "2024-01-01T00:00:00Z",
        }
        for o in orders
    ]
    logger.info("Transformation complete.")
    return transformed


@task(retries=2, retry_delay_seconds=30, name="Load Orders to Data Warehouse")
def load(transformed_orders: list[dict[str, Any]], db_conn: str) -> None:
    """
    Load transformed orders into the data warehouse.

    Parameters
    ----------
    transformed_orders : list[dict[str, Any]]
        Orders after transformation.
    db_conn : str
        Database connection string (could be a DW connection if different).
    """
    logger = get_run_logger()
    logger.info(
        "Loading %d transformed orders into the data warehouse using connection: %s",
        len(transformed_orders),
        db_conn,
    )
    # Placeholder load – replace with real insert logic
    logger.info("Load completed successfully.")


# ----------------------------------------------------------------------
# Flow definition
# ----------------------------------------------------------------------


@flow(
    name="wait_partition_pipeline",
    task_runner=SequentialTaskRunner(),
    description="No description provided.",
)
def wait_partition_pipeline() -> None:
    """
    Orchestrates the end‑to‑end pipeline:
    1. Wait for the daily orders partition.
    2. Extract incremental orders.
    3. Transform the extracted data.
    4. Load the transformed data into the data warehouse.
    """
    logger = get_run_logger()
    logger.info("Starting wait_partition_pipeline flow.")

    # Load shared resources
    db_connection = get_database_connection()

    # Task execution respecting dependencies
    wait_partition.submit(db_conn=db_connection)
    incremental_orders = extract_incremental.submit(db_conn=db_connection)
    transformed = transform.submit(orders=incremental_orders)
    load.submit(transformed_orders=transformed, db_conn=db_connection)

    logger.info("wait_partition_pipeline flow completed.")


# ----------------------------------------------------------------------
# Entry point
# ----------------------------------------------------------------------


if __name__ == "__main__":
    # Running the flow directly (useful for local testing)
    wait_partition_pipeline()