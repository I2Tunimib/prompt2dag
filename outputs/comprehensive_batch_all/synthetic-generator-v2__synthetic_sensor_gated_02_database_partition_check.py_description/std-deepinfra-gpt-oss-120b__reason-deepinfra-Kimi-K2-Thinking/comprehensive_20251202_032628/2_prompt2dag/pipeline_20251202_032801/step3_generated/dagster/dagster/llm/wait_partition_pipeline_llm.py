# Generated by Dagster Code Generator
# Date: 2024-06-28
# Pipeline: wait_partition_pipeline
# Description: Database Partition Check ETL
# Executor: in_process_executor
# Dagster version: 1.5.0

from typing import Any, Dict

from dagster import (
    In,
    Out,
    RetryPolicy,
    ResourceDefinition,
    ScheduleDefinition,
    DefaultScheduleStatus,
    fs_io_manager,
    job,
    op,
    in_process_executor,
)


# ----------------------------------------------------------------------
# Resources
# ----------------------------------------------------------------------
@op(required_resource_keys={"database_conn"})
def database_conn_resource(context) -> Any:
    """
    Placeholder for the primary database connection resource.

    In a real deployment, replace this stub with an actual connection
    (e.g., SQLAlchemy engine, psycopg2 connection, etc.).
    """
    # Example: return create_engine(context.resource_config["db_url"])
    raise NotImplementedError("Provide a concrete database connection implementation.")


# ----------------------------------------------------------------------
# Ops
# ----------------------------------------------------------------------
@op(
    name="wait_partition",
    description="Wait for the daily partition to become available.",
    out=Out(dagster_type=bool),
    retry_policy=RetryPolicy(max_retries=2),
    tags={"executor": "in_process_executor"},
)
def wait_partition(context) -> bool:
    """
    Simulates waiting for a daily partition in the source database.
    Returns ``True`` when the partition is ready.
    """
    # Placeholder logic – replace with actual partition check.
    context.log.info("Checking for daily partition...")
    partition_ready = True
    if not partition_ready:
        raise Exception("Partition not ready.")
    context.log.info("Partition is ready.")
    return partition_ready


@op(
    name="extract_incremental",
    description="Extract incremental orders after the partition is ready.",
    ins={"partition_ready": In(dagster_type=bool)},
    out=Out(dagster_type=Dict[str, Any]),
    required_resource_keys={"database_conn"},
    retry_policy=RetryPolicy(max_retries=2),
    tags={"executor": "in_process_executor"},
)
def extract_incremental(context, partition_ready: bool) -> Dict[str, Any]:
    """
    Extracts incremental order records from the source database.
    """
    if not partition_ready:
        raise Exception("Cannot extract orders because partition is not ready.")
    # Placeholder extraction logic.
    context.log.info("Extracting incremental orders...")
    orders = {"orders": []}  # Replace with real query results.
    context.log.info(f"Extracted {len(orders['orders'])} orders.")
    return orders


@op(
    name="transform_orders",
    description="Transform raw orders data into the warehouse schema.",
    ins={"raw_orders": In(dagster_type=Dict[str, Any])},
    out=Out(dagster_type=Dict[str, Any]),
    retry_policy=RetryPolicy(max_retries=2),
    tags={"executor": "in_process_executor"},
)
def transform_orders(context, raw_orders: Dict[str, Any]) -> Dict[str, Any]:
    """
    Applies business logic and schema transformations to the extracted orders.
    """
    context.log.info("Transforming orders data...")
    # Placeholder transformation logic.
    transformed = {"transformed_orders": raw_orders["orders"]}  # Adjust as needed.
    context.log.info(f"Transformed {len(transformed['transformed_orders'])} orders.")
    return transformed


@op(
    name="load_orders",
    description="Load transformed orders into the data warehouse.",
    ins={"orders": In(dagster_type=Dict[str, Any])},
    out=Out(dagster_type=bool),
    required_resource_keys={"database_conn"},
    retry_policy=RetryPolicy(max_retries=2),
    tags={"executor": "in_process_executor"},
)
def load_orders(context, orders: Dict[str, Any]) -> bool:
    """
    Persists the transformed orders into the target warehouse.
    """
    context.log.info("Loading orders into the warehouse...")
    # Placeholder load logic – replace with actual insert statements.
    loaded = True
    if not loaded:
        raise Exception("Failed to load orders.")
    context.log.info("Orders successfully loaded.")
    return loaded


# ----------------------------------------------------------------------
# Job Definition
# ----------------------------------------------------------------------
@job(
    name="wait_partition_pipeline",
    description="Database Partition Check ETL",
    resource_defs={
        "database_conn": ResourceDefinition.hardcoded_resource(None),  # Replace with real resource.
        "io_manager": fs_io_manager,
    },
    executor_def=in_process_executor,
)
def wait_partition_pipeline():
    """
    Sequential ETL pipeline that:
    1. Waits for the daily partition.
    2. Extracts incremental orders.
    3. Transforms the orders.
    4. Loads them into the warehouse.
    """
    partition_ready = wait_partition()
    raw_orders = extract_incremental(partition_ready)
    transformed = transform_orders(raw_orders)
    load_orders(transformed)


# ----------------------------------------------------------------------
# Schedule (disabled by default)
# ----------------------------------------------------------------------
daily_schedule = ScheduleDefinition(
    job=wait_partition_pipeline,
    cron_schedule="@daily",
    execution_timezone="UTC",
    default_status=DefaultScheduleStatus.STOPPED,
    description="Daily execution of the wait_partition_pipeline.",
)

# Export symbols for Dagster discovery
__all__ = [
    "wait_partition_pipeline",
    "daily_schedule",
    "wait_partition",
    "extract_incremental",
    "transform_orders",
    "load_orders",
    "database_conn_resource",
]