metadata:
  target_orchestrator: airflow
  generated_at: 2025-12-01 13:27:56.383691
  source_analysis_file: 
    Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_sensor_gated_02_database_partition_check.py_description.txt
  pipeline_name: wait_partition_pipeline
  pipeline_description: 'Comprehensive Pipeline Description: This is a sensor-gated daily ETL pipeline that waits for database
    partition availability before extracting, transforming, and loading incremental orders data.'
  orchestrator_specific: {}
schedule:
  enabled: true
  schedule_expression: '@daily'
  start_date: '2024-01-01'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: database_conn
    conn_type: generic
    description: Database Connection
    config:
      host: db_host
      port: 3306
      protocol: jdbc
      database: orders_db
      schema: public
      login: DB_USERNAME
      password: DB_PASSWORD
  - conn_id: data_warehouse_conn
    conn_type: snowflake
    description: Data Warehouse Connection
    config:
      host: dw_host
      port: 5432
      protocol: jdbc
      database: dw_db
      schema: public
      login: DW_USERNAME
      password: DW_PASSWORD
tasks:
  - task_id: wait_partition
    task_name: Wait for Partition
    operator_class: SQLExecuteQueryOperator
    operator_module: airflow.providers.common.sql.operators.sql
    component_ref: wait_partition
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids: []
    trigger_rule: all_success
    retries: 0
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: extract_incremental
    task_name: Extract Incremental Orders
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: extract_incremental
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - wait_partition
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: transform
    task_name: Transform Orders Data
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: transform
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - extract_incremental
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: load
    task_name: Load Orders Data
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: load
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - transform
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
