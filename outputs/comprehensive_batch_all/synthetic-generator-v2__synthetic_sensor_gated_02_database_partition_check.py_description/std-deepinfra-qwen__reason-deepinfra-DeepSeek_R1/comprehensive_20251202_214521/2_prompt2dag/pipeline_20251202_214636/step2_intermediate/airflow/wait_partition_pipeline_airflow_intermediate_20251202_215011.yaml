metadata:
  target_orchestrator: airflow
  generated_at: 2025-12-02 21:50:11.523313
  source_analysis_file: 
    Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_sensor_gated_02_database_partition_check.py_description.txt
  pipeline_name: wait_partition_pipeline
  pipeline_description: Comprehensive Pipeline Description for Database Partition Check ETL
  orchestrator_specific: {}
schedule:
  enabled: true
  schedule_expression: '@daily'
  start_date: '2024-01-01T00:00:00Z'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: database_conn
    conn_type: generic
    description: Database Connection
    config:
      host: hostname
      port: 3306
      protocol: jdbc
      database: orders_db
      schema: public
      login: DATABASE_USERNAME
      password: DATABASE_PASSWORD
  - conn_id: data_warehouse_conn
    conn_type: snowflake
    description: Data Warehouse Connection
    config:
      host: data_warehouse_host
      port: 5439
      protocol: jdbc
      database: dw_db
      schema: public
      login: DW_USERNAME
      password: DW_PASSWORD
tasks:
  - task_id: wait_partition
    task_name: Wait for Partition
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: wait_partition
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids: []
    trigger_rule: all_success
    retries: 0
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: extract_incremental
    task_name: Extract Incremental Orders
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: extract_incremental
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - wait_partition
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: transform
    task_name: Transform Orders Data
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: transform
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - extract_incremental
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: load
    task_name: Load Orders Data
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: load
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - transform
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
