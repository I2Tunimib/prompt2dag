# Generated by Prefect Pipeline Generator on 2024-06-28
# Pipeline: file_arrival_watcher
# Description: Monitors daily transaction file arrivals, validates schema, and loads data into PostgreSQL.
# Prefect version: 2.14.0

import os
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import List

import pandas as pd
import sqlalchemy
from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.orion.schemas.schedules import CronSchedule
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem
from prefect.exceptions import PrefectException


# -------------------------------------------------------------------------
# Helper Functions
# -------------------------------------------------------------------------

def _load_filesystem_block(name: str) -> LocalFileSystem:
    """
    Load a Prefect LocalFileSystem block by name.

    Args:
        name: The name of the block to load.

    Returns:
        An instance of LocalFileSystem.

    Raises:
        PrefectException: If the block cannot be loaded.
    """
    try:
        return LocalFileSystem.load(name)
    except Exception as exc:
        raise PrefectException(f"Unable to load LocalFileSystem block '{name}': {exc}") from exc


def _load_secret_block(name: str) -> Secret:
    """
    Load a Prefect Secret block by name.

    Args:
        name: The name of the block to load.

    Returns:
        An instance of Secret.

    Raises:
        PrefectException: If the block cannot be loaded.
    """
    try:
        return Secret.load(name)
    except Exception as exc:
        raise PrefectException(f"Unable to load Secret block '{name}': {exc}") from exc


def _build_sqlalchemy_engine(secret: Secret) -> sqlalchemy.engine.Engine:
    """
    Build a SQLAlchemy engine from a Prefect Secret containing DB credentials.

    The secret must be a JSON string with keys:
        - username
        - password
        - host
        - port
        - database

    Args:
        secret: Prefect Secret block containing the DB credentials.

    Returns:
        A SQLAlchemy Engine instance.

    Raises:
        PrefectException: If required keys are missing.
    """
    credentials = secret.get()
    if isinstance(credentials, str):
        import json
        credentials = json.loads(credentials)

    required_keys = {"username", "password", "host", "port", "database"}
    missing = required_keys - credentials.keys()
    if missing:
        raise PrefectException(f"Missing DB credential keys: {missing}")

    url = sqlalchemy.engine.URL.create(
        drivername="postgresql+psycopg2",
        username=credentials["username"],
        password=credentials["password"],
        host=credentials["host"],
        port=credentials["port"],
        database=credentials["database"],
    )
    return sqlalchemy.create_engine(url)


# -------------------------------------------------------------------------
# Tasks
# -------------------------------------------------------------------------

@task(retries=2, retry_delay_seconds=30, name="Wait for Transaction File")
def wait_for_file(
    filesystem: LocalFileSystem,
    watch_dir: str,
    filename_pattern: str = "transactions_*.csv",
    timeout_minutes: int = 60,
    poll_interval_seconds: int = 30,
) -> Path:
    """
    Poll a directory until a file matching the pattern appears or timeout expires.

    Args:
        filesystem: Prefect LocalFileSystem block pointing to the base directory.
        watch_dir: Relative directory (within the block's base path) to monitor.
        filename_pattern: Glob pattern for the expected file.
        timeout_minutes: Maximum minutes to wait before failing.
        poll_interval_seconds: Seconds between successive polls.

    Returns:
        Path object pointing to the discovered file.

    Raises:
        PrefectException: If timeout is reached without finding a file.
    """
    logger = get_run_logger()
    base_path = Path(filesystem.base_path) / watch_dir
    deadline = datetime.utcnow() + timedelta(minutes=timeout_minutes)

    logger.info(f"Starting watch on {base_path} for pattern '{filename_pattern}'")
    while datetime.utcnow() < deadline:
        matching_files = list(base_path.glob(filename_pattern))
        if matching_files:
            file_path = matching_files[0]
            logger.info(f"Found file: {file_path}")
            return file_path
        logger.debug("No matching file yet; sleeping...")
        time.sleep(poll_interval_seconds)

    raise PrefectException(
        f"Timeout after {timeout_minutes} minutes waiting for file matching '{filename_pattern}'"
    )


@task(retries=2, retry_delay_seconds=30, name="Validate Transaction File Schema")
def validate_schema(file_path: Path, required_columns: List[str] = None) -> pd.DataFrame:
    """
    Load the CSV file and validate that required columns exist.

    Args:
        file_path: Path to the CSV file.
        required_columns: List of column names that must be present.

    Returns:
        pandas.DataFrame containing the loaded data.

    Raises:
        PrefectException: If validation fails.
    """
    logger = get_run_logger()
    if required_columns is None:
        required_columns = ["transaction_id", "date", "amount", "currency", "account_id"]

    logger.info(f"Reading CSV file {file_path}")
    try:
        df = pd.read_csv(file_path)
    except Exception as exc:
        raise PrefectException(f"Failed to read CSV file {file_path}: {exc}") from exc

    missing = set(required_columns) - set(df.columns)
    if missing:
        raise PrefectException(f"Schema validation failed; missing columns: {missing}")

    logger.info(f"Schema validation passed for file {file_path}")
    return df


@task(retries=2, retry_delay_seconds=30, name="Load Validated Transactions to PostgreSQL")
def load_db(df: pd.DataFrame, db_secret: Secret, table_name: str = "transactions"):
    """
    Load a DataFrame into a PostgreSQL table using SQLAlchemy.

    Args:
        df: DataFrame containing validated transaction data.
        db_secret: Prefect Secret block with DB credentials.
        table_name: Destination table in PostgreSQL.

    Raises:
        PrefectException: If loading fails.
    """
    logger = get_run_logger()
    engine = _build_sqlalchemy_engine(db_secret)

    logger.info(f"Loading {len(df)} rows into PostgreSQL table '{table_name}'")
    try:
        df.to_sql(name=table_name, con=engine, if_exists="append", index=False, method="multi")
    except Exception as exc:
        raise PrefectException(f"Failed to load data into PostgreSQL: {exc}") from exc

    logger.info("Data load completed successfully")


# -------------------------------------------------------------------------
# Flow
# -------------------------------------------------------------------------

@flow(
    name="file_arrival_watcher",
    task_runner=SequentialTaskRunner(),
)
def file_arrival_watcher():
    """
    Orchestrates the daily monitoring of transaction files:
    1. Waits for the arrival of a transaction CSV file.
    2. Validates the file schema.
    3. Loads the validated data into PostgreSQL.
    """
    logger = get_run_logger()

    # Load infrastructure blocks
    filesystem = _load_filesystem_block("local_filesystem")
    db_secret = _load_secret_block("postgresql_db")

    # Configuration
    watch_directory = "incoming"  # relative to the filesystem base_path
    filename_pattern = "transactions_*.csv"

    # Task execution
    file_path = wait_for_file(
        filesystem=filesystem,
        watch_dir=watch_directory,
        filename_pattern=filename_pattern,
    )
    df = validate_schema(file_path=file_path)
    load_db(df=df, db_secret=db_secret)

    logger.info("Pipeline execution completed successfully")


# -------------------------------------------------------------------------
# Deployment
# -------------------------------------------------------------------------

DeploymentSpec(
    name="file_arrival_watcher_deployment",
    flow=file_arrival_watcher,
    schedule=CronSchedule(cron="0 0 * * *", timezone="UTC"),  # @daily at midnight UTC
    tags=["daily", "transaction", "postgresql"],
    parameters={},
    work_pool_name="default-agent-pool",
    enforce_parameter_schema=False,
    flow_runner="prefect.engine.flow_runner.FlowRunner",
    task_runner=SequentialTaskRunner(),
    description="Monitors daily transaction file arrivals, validates schema, and loads data into PostgreSQL.",
    is_schedule_active=True,
    catchup=False,
)

if __name__ == "__main__":
    # Allows local execution for testing/debugging
    file_arrival_watcher()