# Generated by Dagster Code Generator
# Date: 2024-06-13
# Dagster version: 1.5.0
# Pipeline: file_arrival_watcher

from __future__ import annotations

import os
import time
from typing import List

import pandas as pd
import psycopg2
from dagster import (
    In,
    Out,
    RetryPolicy,
    ResourceDefinition,
    ScheduleDefinition,
    asset,
    job,
    op,
    fs_io_manager,
    get_dagster_logger,
    in_process_executor,
    resource,
)


# -------------------------------------------------------------------------
# Resources
# -------------------------------------------------------------------------

@resource(config_schema={"connection_string": str})
def postgres_local(init_context) -> psycopg2.extensions.connection:
    """
    Provides a PostgreSQL connection using the supplied connection string.
    """
    conn_str = init_context.resource_config["connection_string"]
    logger = get_dagster_logger()
    logger.info("Creating PostgreSQL connection.")
    conn = psycopg2.connect(conn_str)
    try:
        yield conn
    finally:
        logger.info("Closing PostgreSQL connection.")
        conn.close()


# -------------------------------------------------------------------------
# Ops
# -------------------------------------------------------------------------

@op(
    name="wait_for_file",
    description="Polls the local filesystem until the daily transaction file appears.",
    out=Out(str, description="Path to the discovered transaction file."),
    retry_policy=RetryPolicy(max_retries=2, delay=5),
    required_resource_keys={"fs_io_manager"},
)
def wait_for_file(context) -> str:
    """
    Waits for a file matching the pattern ``transactions_YYYYMMDD.csv`` in the
    ``incoming/`` directory. Returns the absolute path once the file is found.
    """
    logger = context.log
    incoming_dir = os.path.abspath("incoming")
    today_str = time.strftime("%Y%m%d")
    expected_name = f"transactions_{today_str}.csv"
    expected_path = os.path.join(incoming_dir, expected_name)

    logger.info(f"Waiting for file: {expected_path}")

    # Simple polling loop; in production you might use inotify or a more robust watcher.
    while not os.path.isfile(expected_path):
        logger.info("File not yet present; sleeping 30 seconds.")
        time.sleep(30)

    logger.info(f"File detected: {expected_path}")
    return expected_path


@op(
    name="validate_schema",
    description="Validates the schema of the transaction CSV file.",
    ins={"file_path": In(str)},
    out=Out(pd.DataFrame, description="Validated transaction data."),
    retry_policy=RetryPolicy(max_retries=2, delay=5),
    required_resource_keys={"fs_io_manager"},
)
def validate_schema(context, file_path: str) -> pd.DataFrame:
    """
    Reads the CSV file, checks that required columns exist, and returns a
    DataFrame ready for loading. Raises an exception if validation fails.
    """
    logger = context.log
    required_columns = {"transaction_id", "account_id", "amount", "timestamp"}

    logger.info(f"Reading transaction file: {file_path}")
    df = pd.read_csv(file_path)

    missing = required_columns.difference(df.columns)
    if missing:
        raise ValueError(f"Missing required columns: {missing}")

    logger.info("Schema validation passed.")
    return df


@op(
    name="load_db",
    description="Loads validated transaction data into the PostgreSQL database.",
    ins={"transactions": In(pd.DataFrame)},
    out=Out(bool, description="True if load succeeded."),
    retry_policy=RetryPolicy(max_retries=2, delay=5),
    required_resource_keys={"postgres_local"},
)
def load_db(context, transactions: pd.DataFrame) -> bool:
    """
    Inserts the transaction DataFrame into the ``transactions`` table using
    PostgreSQL's COPY protocol via pandas ``to_sql``. Returns ``True`` on success.
    """
    logger = context.log
    conn: psycopg2.extensions.connection = context.resources.postgres_local

    logger.info("Loading transactions into PostgreSQL.")
    try:
        # Using SQLAlchemy engine for pandas to_sql convenience.
        from sqlalchemy import create_engine

        engine = create_engine(f"postgresql+psycopg2://{conn.dsn}")
        transactions.to_sql(
            name="transactions",
            con=engine,
            if_exists="append",
            index=False,
            method="multi",
        )
        logger.info("Data load completed successfully.")
        return True
    except Exception as exc:
        logger.error(f"Failed to load data: {exc}")
        raise


# -------------------------------------------------------------------------
# Job
# -------------------------------------------------------------------------

@job(
    name="file_arrival_watcher",
    description="Monitors daily transaction file arrivals, validates schema, and loads data to PostgreSQL.",
    executor_def=in_process_executor,
    resource_defs={
        "fs_io_manager": fs_io_manager,
        "postgres_local": postgres_local,
    },
)
def file_arrival_watcher():
    """
    Sequential pipeline:
    1. Wait for the daily transaction file.
    2. Validate its schema.
    3. Load the validated data into PostgreSQL.
    """
    file_path = wait_for_file()
    validated_df = validate_schema(file_path)
    load_db(validated_df)


# -------------------------------------------------------------------------
# Schedule
# -------------------------------------------------------------------------

daily_file_watcher_schedule = ScheduleDefinition(
    job=file_arrival_watcher,
    cron_schedule="@daily",
    execution_timezone="UTC",
    default_status="RUNNING",  # Enabled
    description="Runs the file_arrival_watcher job once per day at midnight UTC.",
    tags={"catchup": "false"},
)

# -------------------------------------------------------------------------
# Exported objects for Dagster discovery
# -------------------------------------------------------------------------

__all__ = [
    "file_arrival_watcher",
    "daily_file_watcher_schedule",
    "postgres_local",
    "wait_for_file",
    "validate_schema",
    "load_db",
]