{
  "metadata": {
    "schema_version": "1.0",
    "analysis_timestamp": "2025-12-01T11:15:17.409597",
    "source_file": "Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_fan_out_fan_in_06_financial_portfolio_rebalancing.py_description.txt",
    "llm_provider": "deepinfra",
    "llm_model": "gpt-oss-120b",
    "analysis_results": {
      "detected_patterns": [
        "sequential",
        "parallel"
      ],
      "task_executors_used": [
        "python"
      ],
      "has_branching": false,
      "has_parallelism": true,
      "has_sensors": false,
      "total_components": 4,
      "complexity_score": "low"
    },
    "orchestrator_compatibility": {
      "airflow": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential pattern fully supported",
          "Parallelism via TaskFlow API expand()"
        ]
      },
      "prefect": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential flow with task dependencies",
          "map() for parallel execution"
        ]
      },
      "dagster": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Op graph with dependencies",
          "DynamicOutput for fan-out"
        ]
      }
    },
    "validation_warnings": []
  },
  "pipeline_summary": {
    "name": "Portfolio Rebalancing DAG",
    "description": "Implements a financial portfolio rebalancing pipeline using a fan‑out/fan‑in pattern with 5 parallel brokerage data fetches, analysis, aggregation and trade order generation.",
    "flow_patterns": [
      "sequential",
      "parallel"
    ],
    "task_executors": [
      "python"
    ],
    "complexity": "low"
  },
  "components": [
    {
      "id": "fetch_brokerage_holdings",
      "name": "Fetch Brokerage Holdings",
      "category": "Extractor",
      "description": "Retrieves mock holdings CSV data for a given brokerage account via a simulated API call.",
      "inputs": [
        "brokerage_id (string)"
      ],
      "outputs": [
        "holdings_data (object) – dictionary with brokerage ID and holdings list"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": null,
        "network": null
      },
      "io_spec": [
        {
          "name": "brokerage_id",
          "direction": "input",
          "kind": "object",
          "format": "string",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "holdings_data",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Root task, no upstream dependencies",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": true,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": 5
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": [
          "brokerage_holdings"
        ]
      }
    },
    {
      "id": "analyze_portfolio",
      "name": "Analyze Portfolio",
      "category": "Transformer",
      "description": "Calculates portfolio metrics such as total value, allocation percentages, and risk score for each brokerage's holdings.",
      "inputs": [
        "holdings_data (object) – output of fetch_brokerage_holdings"
      ],
      "outputs": [
        "analysis_results (object) – dictionary with portfolio metrics"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": null,
        "network": null
      },
      "io_spec": [
        {
          "name": "holdings_data",
          "direction": "input",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "analysis_results",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after its corresponding fetch_brokerage_holdings task succeeds",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": true,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": 5
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "brokerage_holdings"
        ],
        "produces": [
          "portfolio_analysis"
        ]
      }
    },
    {
      "id": "aggregate_and_rebalance",
      "name": "Aggregate and Rebalance",
      "category": "Aggregator",
      "description": "Aggregates analysis results from all brokerages and computes the set of rebalancing trades needed to meet target allocations.",
      "inputs": [
        "analysis_results_list (list<object>) – outputs of all analyze_portfolio tasks"
      ],
      "outputs": [
        "rebalancing_trades (list<object>) – trade specifications with symbol, action, amount, and allocation"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": null,
        "network": null
      },
      "io_spec": [
        {
          "name": "analysis_results_list",
          "direction": "input",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "rebalancing_trades",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Executes after all analyze_portfolio tasks have completed successfully",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "portfolio_analysis"
        ],
        "produces": [
          "rebalancing_trades"
        ]
      }
    },
    {
      "id": "generate_trade_orders",
      "name": "Generate Trade Orders",
      "category": "Loader",
      "description": "Creates a timestamped CSV file containing the final trade orders derived from the rebalancing calculation.",
      "inputs": [
        "rebalancing_trades (list<object>) – output of aggregate_and_rebalance"
      ],
      "outputs": [
        "trade_orders_csv (file) – CSV file with trade instructions"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": null,
        "network": null
      },
      "io_spec": [
        {
          "name": "rebalancing_trades",
          "direction": "input",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "trade_orders_csv",
          "direction": "output",
          "kind": "file",
          "format": "csv",
          "path_pattern": "trade_orders_{{ ds_nodash }}.csv",
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after aggregate_and_rebalance completes successfully",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 2,
        "delay_seconds": 300,
        "exponential_backoff": false,
        "retry_on": [
          "timeout",
          "network_error"
        ]
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "rebalancing_trades"
        ],
        "produces": [
          "trade_orders_csv"
        ]
      }
    }
  ],
  "flow_structure": {
    "pattern": "hybrid",
    "entry_points": [
      "fetch_holdings_parallel"
    ],
    "nodes": {
      "fetch_holdings_parallel": {
        "kind": "Parallel",
        "component_type_id": null,
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "fetch_brokerage_holdings"
        ],
        "parallel_config": {
          "type": "static_parallel",
          "map_over": "brokerage_id",
          "map_source": [
            "BROKERAGE_001",
            "BROKERAGE_002",
            "BROKERAGE_003",
            "BROKERAGE_004",
            "BROKERAGE_005"
          ],
          "max_parallelism": null,
          "join_node": null
        },
        "branch_config": null,
        "sensor_config": null
      },
      "fetch_brokerage_holdings": {
        "kind": "Task",
        "component_type_id": "fetch_brokerage_holdings",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "analyze_portfolio_parallel"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "analyze_portfolio_parallel": {
        "kind": "Parallel",
        "component_type_id": null,
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "analyze_portfolio"
        ],
        "parallel_config": {
          "type": "static_parallel",
          "map_over": "brokerage_id",
          "map_source": [
            "BROKERAGE_001",
            "BROKERAGE_002",
            "BROKERAGE_003",
            "BROKERAGE_004",
            "BROKERAGE_005"
          ],
          "max_parallelism": null,
          "join_node": null
        },
        "branch_config": null,
        "sensor_config": null
      },
      "analyze_portfolio": {
        "kind": "Task",
        "component_type_id": "analyze_portfolio",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "aggregate_and_rebalance"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "aggregate_and_rebalance": {
        "kind": "Task",
        "component_type_id": "aggregate_and_rebalance",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "generate_trade_orders"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "generate_trade_orders": {
        "kind": "Task",
        "component_type_id": "generate_trade_orders",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      }
    },
    "edges": [
      {
        "from": "fetch_holdings_parallel",
        "to": "fetch_brokerage_holdings",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      },
      {
        "from": "fetch_brokerage_holdings",
        "to": "analyze_portfolio_parallel",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      },
      {
        "from": "analyze_portfolio_parallel",
        "to": "analyze_portfolio",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      },
      {
        "from": "analyze_portfolio",
        "to": "aggregate_and_rebalance",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      },
      {
        "from": "aggregate_and_rebalance",
        "to": "generate_trade_orders",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      }
    ]
  },
  "parameters": {
    "pipeline": {
      "name": {
        "description": "Pipeline identifier",
        "type": "string",
        "default": "Portfolio Rebalancing DAG",
        "required": false,
        "constraints": null
      },
      "description": {
        "description": "Comprehensive Pipeline Description",
        "type": "string",
        "default": "Implements a financial portfolio rebalancing pipeline using a fan‑out/fan‑in pattern with 5 parallel brokerage data fetches, analysis, aggregation and trade order generation.",
        "required": false,
        "constraints": null
      },
      "tags": {
        "description": "Classification tags",
        "type": "array",
        "default": [],
        "required": false
      }
    },
    "schedule": {
      "enabled": {
        "description": "Whether pipeline runs on schedule",
        "type": "boolean",
        "default": true,
        "required": false
      },
      "cron_expression": {
        "description": "Cron or preset (e.g., @daily, 0 0 * * *)",
        "type": "string",
        "default": "@daily",
        "required": false
      },
      "start_date": {
        "description": "When to start scheduling",
        "type": "datetime",
        "default": null,
        "required": false,
        "format": "ISO8601"
      },
      "end_date": {
        "description": "When to stop scheduling",
        "type": "datetime",
        "default": null,
        "required": false
      },
      "timezone": {
        "description": "Schedule timezone",
        "type": "string",
        "default": null,
        "required": false
      },
      "catchup": {
        "description": "Run missed intervals",
        "type": "boolean",
        "default": null,
        "required": false
      },
      "batch_window": {
        "description": "Batch window parameter name (e.g., ds, execution_date)",
        "type": "string",
        "default": null,
        "required": false
      },
      "partitioning": {
        "description": "Data partitioning strategy (e.g., daily, hourly, monthly)",
        "type": "string",
        "default": null,
        "required": false
      }
    },
    "execution": {
      "max_active_runs": {
        "description": "Max concurrent pipeline runs",
        "type": "integer",
        "default": null,
        "required": false
      },
      "timeout_seconds": {
        "description": "Pipeline execution timeout",
        "type": "integer",
        "default": null,
        "required": false
      },
      "retry_policy": {
        "description": "Pipeline-level retry behavior",
        "type": "object",
        "default": {
          "retries": 2,
          "retry_delay_minutes": 5
        },
        "required": false
      },
      "depends_on_past": {
        "description": "Whether execution depends on previous run success",
        "type": "boolean",
        "default": false,
        "required": false
      }
    },
    "components": {
      "fetch_brokerage_holdings": {
        "brokerage_id": {
          "description": "Identifier of the brokerage account to fetch holdings for",
          "type": "string",
          "default": null,
          "required": false,
          "constraints": "Must be one of: BROKERAGE_001, BROKERAGE_002, BROKERAGE_003, BROKERAGE_004, BROKERAGE_005"
        }
      },
      "analyze_portfolio": {
        "holdings_data": {
          "description": "Holdings dictionary received from the corresponding fetch_brokerage_holdings task",
          "type": "object",
          "default": null,
          "required": false,
          "constraints": null
        }
      },
      "aggregate_and_rebalance": {
        "analysis_results": {
          "description": "List of analysis result dictionaries from all analyze_portfolio tasks",
          "type": "array",
          "default": null,
          "required": false,
          "constraints": null
        }
      },
      "generate_trade_orders": {
        "rebalancing_trades": {
          "description": "List of trade dictionaries produced by aggregate_and_rebalance",
          "type": "array",
          "default": null,
          "required": false,
          "constraints": null
        }
      }
    },
    "environment": {}
  },
  "integrations": {
    "connections": [
      {
        "id": "brokerage_api_mock",
        "name": "Mock Brokerage API",
        "type": "api",
        "config": {
          "base_path": null,
          "base_url": "https://mock-brokerage.api",
          "host": "mock-brokerage.api",
          "port": null,
          "protocol": "https",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "fetch_brokerage_holdings"
        ],
        "direction": "input",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "holdings_data_BROKERAGE_001",
            "holdings_data_BROKERAGE_002",
            "holdings_data_BROKERAGE_003",
            "holdings_data_BROKERAGE_004",
            "holdings_data_BROKERAGE_005"
          ],
          "consumes": []
        }
      },
      {
        "id": "local_filesystem",
        "name": "Local Filesystem",
        "type": "filesystem",
        "config": {
          "base_path": "/tmp",
          "base_url": null,
          "host": null,
          "port": null,
          "protocol": "file",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "none",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": null
        },
        "used_by_components": [
          "generate_trade_orders"
        ],
        "direction": "output",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "trade_orders_YYYYMMDD.csv"
          ],
          "consumes": [
            "rebalancing_trades"
          ]
        }
      }
    ],
    "data_lineage": {
      "sources": [
        "Mock brokerage API providing holdings CSV data for each brokerage account (BROKERAGE_001‑005)"
      ],
      "sinks": [
        "Local CSV file (trade_orders_YYYYMMDD.csv) containing the final rebalancing trade orders"
      ],
      "intermediate_datasets": [
        "holdings_data_{brokerage_id} – dictionary of mock holdings per brokerage",
        "portfolio_metrics_{brokerage_id} – calculated metrics per brokerage",
        "rebalancing_trades – aggregated list of trades needed to meet target allocations"
      ]
    }
  }
}