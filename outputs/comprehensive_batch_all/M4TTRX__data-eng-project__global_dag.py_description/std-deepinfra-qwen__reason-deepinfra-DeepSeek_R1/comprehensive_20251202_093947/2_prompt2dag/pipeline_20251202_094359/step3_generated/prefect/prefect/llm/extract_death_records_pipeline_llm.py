# Generated by Prefect 2.14.0
# Pipeline Name: extract_death_records_pipeline
# Description: No description provided.
# Pattern: fanout
# Schedule Configuration: Disabled
# Work Pool: default-agent-pool
# Task Runner: ConcurrentTaskRunner

from prefect import flow, task, get_run_logger
from prefect.task_runners import ConcurrentTaskRunner
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem
from prefect.infrastructure.docker import DockerContainer
from prefect.exceptions import PrefectException
import os

# Load secrets and resources
data_gouv_fr_api = Secret.load("data-gouv-fr-api")
static_data_gouv_fr = Secret.load("static-data-gouv-fr")
redis = Secret.load("redis")
postgresql = Secret.load("postgresql")
ingestion_directory = LocalFileSystem.load("ingestion-directory")
staging_directory = LocalFileSystem.load("staging-directory")
sql_tmp_directory = LocalFileSystem.load("sql-tmp-directory")

@task(retries=1)
def cleanse_power_plant_data():
    """Cleanse Power Plant Data"""
    logger = get_run_logger()
    logger.info("Cleaning power plant data...")
    # Add your data cleansing logic here
    return "Power plant data cleansed"

@task(retries=1)
def generate_plant_insert_queries():
    """Generate Plant Insert Queries"""
    logger = get_run_logger()
    logger.info("Generating plant insert queries...")
    # Add your query generation logic here
    return "Plant insert queries generated"

@task(retries=1)
def extract_nuclear_plants():
    """Extract Nuclear Plants"""
    logger = get_run_logger()
    logger.info("Extracting nuclear plants...")
    # Add your extraction logic here
    return "Nuclear plants extracted"

@task(retries=1)
def create_power_plant_table():
    """Create Power Plant Table"""
    logger = get_run_logger()
    logger.info("Creating power plant table...")
    # Add your table creation logic here
    return "Power plant table created"

@task(retries=1)
def extract_city_geo_data():
    """Extract City Geo Data"""
    logger = get_run_logger()
    logger.info("Extracting city geo data...")
    # Add your extraction logic here
    return "City geo data extracted"

@task(retries=1)
def extract_thermal_plants():
    """Extract Thermal Plants"""
    logger = get_run_logger()
    logger.info("Extracting thermal plants...")
    # Add your extraction logic here
    return "Thermal plants extracted"

@task(retries=1)
def store_plants_in_postgres():
    """Store Plants in PostgreSQL"""
    logger = get_run_logger()
    logger.info("Storing plants in PostgreSQL...")
    # Add your storage logic here
    return "Plants stored in PostgreSQL"

@task(retries=1)
def clean_tmp_death_files():
    """Clean Temporary Death Files"""
    logger = get_run_logger()
    logger.info("Cleaning temporary death files...")
    # Add your file cleaning logic here
    return "Temporary death files cleaned"

@task(retries=1)
def check_death_data_emptiness():
    """Check Death Data Emptiness"""
    logger = get_run_logger()
    logger.info("Checking death data emptiness...")
    # Add your data emptiness check logic here
    return "Death data is not empty"

@task(retries=1)
def store_deaths_in_postgres():
    """Store Deaths in PostgreSQL"""
    logger = get_run_logger()
    logger.info("Storing deaths in PostgreSQL...")
    # Add your storage logic here
    return "Deaths stored in PostgreSQL"

@task(retries=1)
def create_death_table():
    """Create Death Table"""
    logger = get_run_logger()
    logger.info("Creating death table...")
    # Add your table creation logic here
    return "Death table created"

@task(retries=1)
def extract_death_records():
    """Extract Death Records"""
    logger = get_run_logger()
    logger.info("Extracting death records...")
    # Add your extraction logic here
    return "Death records extracted"

@task(retries=1)
def load_death_records_to_redis():
    """Load Death Records to Redis"""
    logger = get_run_logger()
    logger.info("Loading death records to Redis...")
    # Add your loading logic here
    return "Death records loaded to Redis"

@task(retries=1)
def cleanse_death_data():
    """Cleanse Death Data"""
    logger = get_run_logger()
    logger.info("Cleaning death data...")
    # Add your data cleansing logic here
    return "Death data cleansed"

@flow(name="extract_death_records_pipeline", task_runner=ConcurrentTaskRunner())
def extract_death_records_pipeline():
    """Extract Death Records Pipeline"""
    logger = get_run_logger()
    logger.info("Starting extract_death_records_pipeline...")

    ingestion_pipeline_start = extract_death_records.submit()
    extract_nuclear_plants.submit(wait_for=[ingestion_pipeline_start])
    extract_thermal_plants.submit(wait_for=[ingestion_pipeline_start])
    extract_city_geo_data.submit(wait_for=[ingestion_pipeline_start])

    staging_pipeline_start = create_death_table.submit()
    create_power_plant_table.submit(wait_for=[staging_pipeline_start])
    load_death_records_to_redis.submit(wait_for=[staging_pipeline_start])

    cleanse_death_data_task = cleanse_death_data.submit(wait_for=[load_death_records_to_redis])
    check_death_data_emptiness_task = check_death_data_emptiness.submit(wait_for=[cleanse_death_data_task])
    store_deaths_in_postgres.submit(wait_for=[check_death_data_emptiness_task])

    store_plants_in_postgres.submit(wait_for=[create_power_plant_table])
    clean_tmp_death_files.submit(wait_for=[store_plants_in_postgres])

    logger.info("extract_death_records_pipeline completed.")

if __name__ == "__main__":
    extract_death_records_pipeline()