metadata:
  target_orchestrator: prefect
  generated_at: 2025-12-01 03:49:58.308994
  source_analysis_file: Pipeline_Description_Dataset/M4TTRX__data-eng-project__global_dag.py_description.txt
  pipeline_name: extract_data_from_gouv_pipeline
  pipeline_description: No description provided.
  orchestrator_specific:
    flow_name: extract_data_from_gouv_pipeline
    deployment_name: extract_data_from_gouv_pipeline_deployment
    work_pool: default-agent-pool
    task_runner: ConcurrentTaskRunner
    prefect_version: 2.14.0
schedule:
  enabled: false
  schedule_expression:
  start_date: days_ago(0)
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: data_gouv_api
    conn_type: Secret
    description: data.gouv.fr API
    config:
      block_type: Secret
      block_module: prefect.blocks.system
      block_name: data_gouv_api
      config:
        base_url: https://data.gouv.fr/api/1
        protocol: https
        token_secret_name: DATA_GOUV_API_TOKEN
  - conn_id: redis_cache
    conn_type: Secret
    description: Redis Cache
    config:
      block_type: Secret
      block_module: prefect.blocks.system
      block_name: redis_cache
      config:
        host: redis
        port: 6379
        protocol: redis
  - conn_id: postgresql_db
    conn_type: Secret
    description: PostgreSQL Database
    config:
      block_type: Secret
      block_module: prefect.blocks.system
      block_name: postgresql_db
      config:
        host: postgres
        port: 5432
        database: etl_db
        protocol: jdbc
        schema: public
        username_secret_name: POSTGRES_USER
        password_secret_name: POSTGRES_PASSWORD
  - conn_id: ingestion_filesystem
    conn_type: LocalFileSystem
    description: Ingestion Filesystem
    config:
      block_type: LocalFileSystem
      block_module: prefect.filesystems
      block_name: ingestion_filesystem
      config:
        base_path: /opt/airflow/dags/data/ingestion
        protocol: file
  - conn_id: staging_filesystem
    conn_type: LocalFileSystem
    description: Staging Filesystem
    config:
      block_type: LocalFileSystem
      block_module: prefect.filesystems
      block_name: staging_filesystem
      config:
        base_path: /opt/airflow/dags/data/staging
        protocol: file
  - conn_id: sql_tmp_filesystem
    conn_type: LocalFileSystem
    description: SQL Temporary Filesystem
    config:
      block_type: LocalFileSystem
      block_module: prefect.filesystems
      block_name: sql_tmp_filesystem
      config:
        base_path: /opt/airflow/dags/sql/tmp
        protocol: file
tasks:
  - task_id: extract_data_from_gouv
    task_name: Extract Data from data.gouv.fr
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: extract_data_from_gouv
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/extract_data.py
      retries: 1
      retry_delay_seconds: 10
      task_runner: ConcurrentTaskRunner
    upstream_task_ids:
      - ingestion_pipeline_start
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: download_city_geo
    task_name: Download City Geographic Coordinates
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: download_city_geo
    config:
      task_decorator: '@task'
      infrastructure:
        config:
          command:
            - curl
            - -o
            - /opt/airflow/dags/data/ingestion/city_geo_loc.csv
            - CITY_GEO_DATASET_URL
          shell: /bin/bash
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - ingestion_pipeline_start
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: fetch_nuclear_data
    task_name: Fetch Nuclear Power Plant Data
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: fetch_nuclear_data
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/fetch_nuclear_data.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - ingestion_pipeline_start
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: fetch_thermal_data
    task_name: Fetch Thermal Power Plant Data
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: fetch_thermal_data
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/fetch_thermal_data.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - ingestion_pipeline_start
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: fetch_death_records
    task_name: Fetch Death Records
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: fetch_death_records
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/fetch_death_records.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - ingestion_pipeline_start
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: create_death_table
    task_name: Create Death Table
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: create_death_table
    config:
      task_decorator: '@task'
      infrastructure:
        config:
          query: /opt/airflow/dags/sql/create_death_table.sql
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - staging_pipeline_start
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: create_power_plants_table
    task_name: Create Power Plants Table
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: create_power_plants_table
    config:
      task_decorator: '@task'
      infrastructure:
        config:
          query: /opt/airflow/dags/sql/create_power_plant_table.sql
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - staging_pipeline_start
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: load_death_records_to_redis
    task_name: Load Death Records to Redis
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: load_death_records_to_redis
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/load_death_records_to_redis.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - staging_pipeline_start
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: cleanse_death_data
    task_name: Cleanse Death Data
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: cleanse_death_data
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/cleanse_death_data.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - create_death_table
      - load_death_records_to_redis
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: cleanse_power_plant_data
    task_name: Cleanse Power Plant Data
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: cleanse_power_plant_data
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/cleanse_power_plant_data.py
      retries: 1
      retry_delay_seconds: 10
      task_runner: ConcurrentTaskRunner
    upstream_task_ids:
      - create_power_plants_table
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: generate_plant_persist_sql
    task_name: Generate Plant Persist SQL
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: generate_plant_persist_sql
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/generate_plant_persist_sql.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - cleanse_power_plant_data
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: check_death_data_emptiness
    task_name: Check Death Data Emptiness
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: check_death_data_emptiness
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/check_death_data_emptiness.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - cleanse_death_data
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: store_deaths_in_postgres
    task_name: Store Deaths in PostgreSQL
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: store_deaths_in_postgres
    config:
      task_decorator: '@task'
      infrastructure:
        config:
          query: /opt/airflow/dags/sql/tmp/death_insertion_queries.sql
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - check_death_data_emptiness
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: staging_end
    task_name: Staging End
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: staging_end
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/staging_end.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - check_death_data_emptiness
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: store_plants_in_postgres
    task_name: Store Plants in PostgreSQL
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: store_plants_in_postgres
    config:
      task_decorator: '@task'
      infrastructure:
        config:
          query: /opt/airflow/dags/sql/tmp/plant_insertion_queries.sql
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - generate_plant_persist_sql
      - staging_end
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
  - task_id: clean_tmp_death_files
    task_name: Clean Temporary Death Files
    operator_class: Process
    operator_module: prefect.infrastructure.process
    component_ref: clean_tmp_death_files
    config:
      task_decorator: '@task'
      infrastructure:
        type: Process
        module: prefect.infrastructure.process
        config:
          fn: path/to/clean_tmp_death_files.py
      retries: 1
      retry_delay_seconds: 10
    upstream_task_ids:
      - store_deaths_in_postgres
      - store_plants_in_postgres
    trigger_rule: wait_for='all'
    retries: 1
    retry_delay_seconds: 10
    validation_warnings: []
