# Generated by Dagster Code Generator
# Date: 2024-06-13
# Description: Dagster job for "Airflow Database Cleanup" pipeline.
# This file defines resources, ops, job, and schedule according to the provided specification.

from dagster import (
    op,
    job,
    In,
    Out,
    RetryPolicy,
    ResourceDefinition,
    ConfigurableResource,
    InitResourceContext,
    get_dagster_logger,
    fs_io_manager,
    in_process_executor,
    ScheduleDefinition,
    define_asset_job,
    Definitions,
)
from dagster import schedule
from datetime import datetime
import logging
import smtplib
from typing import Dict, Any


# -------------------------------------------------------------------------
# Resources
# -------------------------------------------------------------------------

class AirflowMetastoreDBResource(ConfigurableResource):
    """Resource for connecting to Airflow's MetaStore database."""

    connection_string: str

    def get_connection(self):
        """Create and return a database connection.
        In a real implementation, this would return a SQLAlchemy engine or similar.
        """
        logger = get_dagster_logger()
        logger.info("Connecting to Airflow MetaStore DB with %s", self.connection_string)
        # Placeholder: return a mock connection object
        return {"connection_string": self.connection_string}


class EmailSMTPResource(ConfigurableResource):
    """Resource for sending alert emails via an SMTP server."""

    host: str
    port: int = 587
    username: str
    password: str
    use_tls: bool = True
    from_address: str

    def send_email(self, to_address: str, subject: str, body: str) -> None:
        """Send an email using the configured SMTP server."""
        logger = get_dagster_logger()
        logger.info("Sending email to %s via %s:%s", to_address, self.host, self.port)
        message = f"From: {self.from_address}\nTo: {to_address}\nSubject: {subject}\n\n{body}"
        try:
            with smtplib.SMTP(self.host, self.port) as server:
                if self.use_tls:
                    server.starttls()
                server.login(self.username, self.password)
                server.sendmail(self.from_address, [to_address], message)
            logger.info("Email sent successfully.")
        except Exception as e:
            logger.error("Failed to send email: %s", e)
            raise


# -------------------------------------------------------------------------
# Ops
# -------------------------------------------------------------------------

@op(
    name="extract_cleanup_configuration",
    description="Extracts cleanup configuration such as retention periods from environment or config.",
    out=Out(dict),
    retry_policy=RetryPolicy(max_retries=1),
)
def extract_cleanup_configuration(context) -> Dict[str, Any]:
    """
    Returns a dictionary containing cleanup parameters.
    For demonstration, we return a static configuration.
    """
    logger = context.log
    logger.info("Extracting cleanup configuration.")
    # In a real scenario, this could read from a config file, env vars, or a DB.
    config = {
        "retention_days": 30,  # Keep metadata for the last 30 days
        "tables_to_clean": [
            "dag_run",
            "task_instance",
            "log",
            "xcom",
        ],
    }
    logger.debug("Cleanup configuration: %s", config)
    return config


@op(
    name="cleanup_airflow_metadb",
    description="Deletes old metadata entries from Airflow MetaStore tables based on the provided configuration.",
    ins={"config": In(dict)},
    out=Out(bool),
    retry_policy=RetryPolicy(max_retries=1),
)
def cleanup_airflow_metadb(context, config: Dict[str, Any]) -> bool:
    """
    Performs cleanup of Airflow MetaStore tables.
    Returns True if cleanup succeeded, False otherwise.
    """
    logger = context.log
    db_resource: AirflowMetastoreDBResource = context.resources.airflow_metastore_db
    email_resource: EmailSMTPResource = context.resources.email_smtp_server

    logger.info("Starting Airflow MetaStore cleanup with config: %s", config)

    # Obtain a DB connection (placeholder)
    connection = db_resource.get_connection()

    # Placeholder cleanup logic
    try:
        for table in config["tables_to_clean"]:
            logger.info(
                "Cleaning table '%s' older than %d days.", table, config["retention_days"]
            )
            # Here you would execute a DELETE statement like:
            # DELETE FROM {table} WHERE execution_date < NOW() - INTERVAL '{retention_days} days';
            # For demonstration we just log the action.
        logger.info("Cleanup completed successfully.")
        return True
    except Exception as exc:
        logger.error("Cleanup failed: %s", exc)
        # Send alert email
        try:
            email_resource.send_email(
                to_address="ops@example.com",
                subject="Airflow MetaStore Cleanup Failure",
                body=f"The cleanup job failed with error: {exc}",
            )
        except Exception as email_exc:
            logger.error("Failed to send alert email: %s", email_exc)
        raise


# -------------------------------------------------------------------------
# Job
# -------------------------------------------------------------------------

@job(
    name="airflow_database_cleanup",
    description="Maintenance workflow that periodically cleans old metadata entries from Airflow's MetaStore database tables to prevent excessive data accumulation.",
    executor_def=in_process_executor,
    resource_defs={
        "airflow_metastore_db": AirflowMetastoreDBResource,
        "email_smtp_server": EmailSMTPResource,
        "io_manager": fs_io_manager,
    },
    # The following config schema can be overridden at schedule or run time.
    config_schema={
        "airflow_metastore_db": {
            "connection_string": str,
        },
        "email_smtp_server": {
            "host": str,
            "port": int,
            "username": str,
            "password": str,
            "use_tls": bool,
            "from_address": str,
        },
    },
)
def airflow_database_cleanup():
    """
    Dagster job that orchestrates the extraction of cleanup configuration and the
    subsequent cleanup of Airflow MetaStore tables.
    """
    config = extract_cleanup_configuration()
    cleanup_airflow_metadb(config)


# -------------------------------------------------------------------------
# Schedule
# -------------------------------------------------------------------------

daily_cleanup_schedule = ScheduleDefinition(
    job=airflow_database_cleanup,
    cron_schedule="0 0 * * *",  # @daily at 00:00 UTC
    execution_timezone="UTC",
    name="daily_airflow_cleanup_schedule",
    description="Runs the Airflow Database Cleanup job daily at midnight UTC.",
    default_status="RUNNING",  # Enabled
    catchup=False,
)


# -------------------------------------------------------------------------
# Definitions (for Dagster UI / CLI)
# -------------------------------------------------------------------------

defs = Definitions(
    jobs=[airflow_database_cleanup],
    schedules=[daily_cleanup_schedule],
    resources={
        "airflow_metastore_db": AirflowMetastoreDBResource(
            connection_string="postgresql://airflow:airflow@localhost:5432/airflow"
        ),
        "email_smtp_server": EmailSMTPResource(
            host="smtp.example.com",
            port=587,
            username="alert_user",
            password="secure_password",
            use_tls=True,
            from_address="alerts@example.com",
        ),
    },
)