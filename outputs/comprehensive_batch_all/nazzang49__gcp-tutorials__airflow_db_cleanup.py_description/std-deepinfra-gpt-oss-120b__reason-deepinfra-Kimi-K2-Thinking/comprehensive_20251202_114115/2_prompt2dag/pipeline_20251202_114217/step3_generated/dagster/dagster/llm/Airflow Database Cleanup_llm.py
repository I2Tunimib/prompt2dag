# Generated by Dagster Code Generator
# Date: 2024-06-20
# Description: Dagster job for Airflow Database Cleanup

from dagster import (
    op,
    job,
    In,
    Out,
    RetryPolicy,
    ResourceDefinition,
    InitResourceContext,
    ConfigurableResource,
    InMemoryIOManager,
    fs_io_manager,
    in_process_executor,
    ScheduleDefinition,
    Definitions,
)
from dagster import ScheduleDefinition, DefaultScheduleStatus
from datetime import datetime
import logging


# ----------------------------------------------------------------------
# Resource definitions
# ----------------------------------------------------------------------


class AirflowMetastoreDBResource(ConfigurableResource):
    """Placeholder resource for interacting with the Airflow MetaStore database."""

    def cleanup(self, cleanup_config: dict) -> None:
        """Perform cleanup operations on the Airflow MetaStore DB.

        Args:
            cleanup_config (dict): Configuration dict produced by ``load_cleanup_configuration``.
        """
        # In a real implementation, this would execute SQL statements or call an API.
        logging.info("Cleaning up Airflow MetaStore DB with config: %s", cleanup_config)


class SMTPEmailAlertResource(ConfigurableResource):
    """Placeholder resource for sending email alerts via SMTP."""

    def send_alert(self, subject: str, body: str) -> None:
        """Send an email alert.

        Args:
            subject (str): Email subject line.
            body (str): Email body content.
        """
        # In a real implementation, this would send an email using smtplib or a third‑party service.
        logging.info("Sending email alert – Subject: %s | Body: %s", subject, body)


# ----------------------------------------------------------------------
# Ops
# ----------------------------------------------------------------------


@op(
    name="load_cleanup_configuration",
    description="Load configuration required for cleaning up the Airflow MetaStore database.",
    out=Out(dict),
    retry_policy=RetryPolicy(max_retries=1),
)
def load_cleanup_configuration(context) -> dict:
    """Load cleanup configuration.

    Returns a dictionary that downstream ops can consume. In a production setting,
    this could read from a file, environment variables, or a configuration service.
    """
    # Example static configuration; replace with real loading logic as needed.
    config = {
        "tables_to_truncate": ["dag_run", "task_instance", "log"],
        "retain_days": 30,
    }
    context.log.info("Loaded cleanup configuration: %s", config)
    return config


@op(
    name="cleanup_airflow_metadb",
    description="Execute cleanup of the Airflow MetaStore database using the loaded configuration.",
    ins={"cleanup_config": In(dict)},
    out=Out(None),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"airflow_metastore_db", "smtp_email_alert"},
)
def cleanup_airflow_metadb(context, cleanup_config: dict) -> None:
    """Perform the actual cleanup of the Airflow MetaStore DB.

    Args:
        cleanup_config (dict): Configuration dict from ``load_cleanup_configuration``.
    """
    try:
        context.resources.airflow_metastore_db.cleanup(cleanup_config)
        context.log.info("Airflow MetaStore DB cleanup completed successfully.")
    except Exception as exc:  # pragma: no cover
        # If something goes wrong, send an alert and re‑raise to trigger retry logic.
        subject = "Airflow MetaStore Cleanup Failure"
        body = f"An error occurred during cleanup: {exc}"
        context.resources.smtp_email_alert.send_alert(subject, body)
        context.log.error("Cleanup failed: %s", exc)
        raise


# ----------------------------------------------------------------------
# Job definition
# ----------------------------------------------------------------------


@job(
    name="airflow_database_cleanup",
    description="No description provided.",
    executor_def=in_process_executor,
    resource_defs={
        "airflow_metastore_db": AirflowMetastoreDBResource(),
        "smtp_email_alert": SMTPEmailAlertResource(),
        "io_manager": fs_io_manager,
    },
    # The following required_resources list from the spec is kept for documentation.
    # Dagster resolves resources via the ``resource_defs`` mapping above.
)
def airflow_database_cleanup_job():
    """Dagster job orchestrating the Airflow database cleanup workflow."""
    config = load_cleanup_configuration()
    cleanup_airflow_metadb(cleanup_config=config)


# ----------------------------------------------------------------------
# Schedule definition
# ----------------------------------------------------------------------


daily_cleanup_schedule = ScheduleDefinition(
    job=airflow_database_cleanup_job,
    cron_schedule="@daily",
    execution_timezone="UTC",
    default_status=DefaultScheduleStatus.RUNNING,
    description="Daily schedule for Airflow Database Cleanup (UTC).",
    # ``catchup`` is handled by Dagster's schedule configuration; setting default_status to RUNNING
    # and not providing a start date ensures no backfill on deployment.
)


# ----------------------------------------------------------------------
# Definitions bundle
# ----------------------------------------------------------------------


defs = Definitions(
    jobs=[airflow_database_cleanup_job],
    schedules=[daily_cleanup_schedule],
    resources={
        "airflow_metastore_db": AirflowMetastoreDBResource(),
        "smtp_email_alert": SMTPEmailAlertResource(),
        "io_manager": fs_io_manager,
    },
)