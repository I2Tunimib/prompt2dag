# Generated by Prefect Pipeline Generator
# Date: 2024-06-28
# Pipeline: Airflow Database Cleanup
# Prefect version: 2.14.0

import logging
from typing import Dict

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.server.schemas.schedules import CronSchedule
from prefect.blocks.system import Secret


@task(retries=1, name="Load Cleanup Configuration")
def load_cleanup_configuration() -> Dict[str, str]:
    """
    Load cleanup configuration required for the Airflow MetaDB cleanup.

    The configuration is retrieved from a Prefect Secret block named
    ``airflow_metastore_db``.  The secret is expected to contain a JSON string
    or plain text that can be interpreted as a database URI.

    Returns:
        dict: A dictionary containing configuration values, e.g. ``{"db_uri": "..."}``.

    Raises:
        Exception: If the secret cannot be loaded or parsed.
    """
    logger = get_run_logger()
    logger.info("Loading cleanup configuration from secret block.")

    try:
        secret_block = Secret.load("airflow_metastore_db")
        secret_value = secret_block.get()
        logger.debug("Raw secret value retrieved.")
    except Exception as exc:
        logger.error("Failed to load secret 'airflow_metastore_db': %s", exc)
        raise

    # In a real implementation you might parse JSON; here we assume the secret
    # directly contains the DB URI.
    config = {"db_uri": secret_value.strip()}
    logger.info("Cleanup configuration loaded successfully.")
    return config


@task(retries=1, name="Cleanup Airflow MetaDB")
def cleanup_airflow_metadb(config: Dict[str, str]) -> None:
    """
    Perform cleanup operations on the Airflow MetaDB.

    Args:
        config (dict): Configuration dictionary containing at least ``db_uri``.

    Raises:
        ValueError: If required configuration keys are missing.
        Exception: If any step of the cleanup process fails.
    """
    logger = get_run_logger()
    logger.info("Starting Airflow MetaDB cleanup.")

    db_uri = config.get("db_uri")
    if not db_uri:
        logger.error("Database URI ('db_uri') missing from configuration.")
        raise ValueError("Missing 'db_uri' in cleanup configuration.")

    # Placeholder for actual cleanup logic.
    # For example, you could run SQL statements via SQLAlchemy or invoke a
    # Docker container that performs the cleanup.
    try:
        logger.debug("Connecting to Airflow MetaDB at %s", db_uri)
        # Example: run cleanup commands here.
        # e.g., engine = create_engine(db_uri); with engine.begin(): ...
        logger.info("Airflow MetaDB cleanup completed successfully.")
    except Exception as exc:
        logger.error("Error during Airflow MetaDB cleanup: %s", exc)
        raise


@flow(name="airflow_database_cleanup", task_runner=SequentialTaskRunner())
def airflow_database_cleanup_flow() -> None:
    """
    Orchestrates the Airflow database cleanup pipeline.

    The flow loads the cleanup configuration and then executes the cleanup
    task.  Tasks are run sequentially as defined by the ``SequentialTaskRunner``.
    """
    config = load_cleanup_configuration()
    cleanup_airflow_metadb(config)


# -------------------------------------------------------------------------
# Deployment specification
# -------------------------------------------------------------------------
DeploymentSpec(
    name="airflow_database_cleanup_deployment",
    flow=airflow_database_cleanup_flow,
    schedule=CronSchedule(cron="0 0 * * *", timezone="UTC"),
    work_pool_name="default-agent-pool",
    tags=["airflow", "cleanup"],
    description="Daily Airflow MetaDB cleanup flow.",
    catchup=False,
)