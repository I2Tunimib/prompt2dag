# Generated by Airflow DAG Generator on 2024-06-13
# DAG: Airflow Database Cleanup
# Description: Sequential pipeline that loads cleanup configuration and then cleans up the Airflow MetaDB.

from __future__ import annotations

import logging
from datetime import datetime
from typing import Any, Dict

from airflow import DAG
from airflow.decorators import task
from airflow.exceptions import AirflowException
from airflow.utils.email import send_email
from airflow.utils.dates import days_ago
from airflow.hooks.base import BaseHook
from sqlalchemy import create_engine, text

# -------------------------------------------------------------------------
# Default arguments for the DAG
# -------------------------------------------------------------------------
DEFAULT_ARGS: Dict[str, Any] = {
    "owner": "airflow",
    "depends_on_past": False,
    "retries": 1,
    "retry_delay": 300,  # seconds
    "email_on_failure": True,
    "email": ["admin@example.com"],  # replace with real recipients
    "on_failure_callback": lambda context: send_email(
        to=DEFAULT_ARGS["email"],
        subject=f"Airflow DAG Failed: {context['dag'].dag_id}",
        html_content=f"""
        <p>Task <strong>{context['task_instance'].task_id}</strong> in DAG 
        <strong>{context['dag'].dag_id}</strong> failed.</p>
        <p>Execution date: {context['execution_date']}</p>
        <p>Log URL: {context['task_instance'].log_url}</p>
        """
    ),
}

# -------------------------------------------------------------------------
# DAG definition
# -------------------------------------------------------------------------
with DAG(
    dag_id="airflow_database_cleanup",
    description="No description provided.",
    schedule_interval="@daily",
    start_date=days_ago(1),
    catchup=False,
    default_args=DEFAULT_ARGS,
    tags=["maintenance", "cleanup"],
    max_active_runs=1,
    timezone="UTC",
) as dag:

    @task(task_id="load_cleanup_configuration", retries=1)
    def load_cleanup_configuration() -> Dict[str, Any]:
        """
        Load cleanup configuration.
        This could be from a file, a remote service, or environment variables.
        Returns a dictionary with configuration values.
        """
        try:
            # Placeholder: replace with real configuration loading logic
            config = {
                "tables_to_cleanup": ["dag_run", "task_instance"],
                "retention_days": 30,
            }
            logging.info("Cleanup configuration loaded: %s", config)
            return config
        except Exception as exc:
            logging.exception("Failed to load cleanup configuration")
            raise AirflowException("Error loading cleanup configuration") from exc

    @task(task_id="cleanup_airflow_metadb", retries=1)
    def cleanup_airflow_metadb(config: Dict[str, Any]) -> None:
        """
        Perform cleanup operations on the Airflow MetaDB.
        Uses the ``airflow_metastore_db`` connection defined in Airflow.
        """
        try:
            # Retrieve DB connection details from Airflow connection
            conn = BaseHook.get_connection("airflow_metastore_db")
            sql_alchemy_conn = conn.get_uri()
            engine = create_engine(sql_alchemy_conn)

            tables = config.get("tables_to_cleanup", [])
            retention_days = config.get("retention_days", 30)

            with engine.begin() as conn:
                for table in tables:
                    # Example cleanup: delete rows older than retention period
                    cleanup_sql = text(
                        f"""
                        DELETE FROM {table}
                        WHERE execution_date < (CURRENT_DATE - INTERVAL ':days days')
                        """
                    )
                    result = conn.execute(cleanup_sql, {"days": retention_days})
                    logging.info(
                        "Cleaned %d rows from %s older than %d days",
                        result.rowcount,
                        table,
                        retention_days,
                    )
        except Exception as exc:
            logging.exception("Failed to clean up Airflow MetaDB")
            raise AirflowException("Error during Airflow MetaDB cleanup") from exc

    # -------------------------------------------------------------------------
    # Task pipeline
    # -------------------------------------------------------------------------
    config = load_cleanup_configuration()
    cleanup_airflow_metadb(config)

    # Define explicit dependency (TaskFlow API handles this via upstream/downstream)
    # config >> cleanup_airflow_metadb  # not needed as we passed the output directly

# End of DAG definition.