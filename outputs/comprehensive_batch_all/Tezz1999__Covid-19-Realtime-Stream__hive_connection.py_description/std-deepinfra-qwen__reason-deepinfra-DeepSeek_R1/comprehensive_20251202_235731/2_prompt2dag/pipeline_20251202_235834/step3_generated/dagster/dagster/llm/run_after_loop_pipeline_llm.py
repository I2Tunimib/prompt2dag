# Generated by Dagster Code Generator
# Generation Metadata:
# - Job Name: run_after_loop_pipeline
# - Description: No description provided.
# - Executor Type: in_process_executor
# - IO Manager: fs_io_manager
# - Dagster Version: 1.5.0
# - Use Assets: False
# - Required Resources: hive_local

from dagster import job, op, Out, In, RetryPolicy, ResourceDefinition, fs_io_manager

# Define the run_after_loop op
@op(
    name="run_after_loop",
    description="Run After Loop",
    out=Out(str, description="Output of the run_after_loop op"),
    retry_policy=RetryPolicy(max_retries=0),
    required_resource_keys={"local_shell"}
)
def run_after_loop(context):
    """
    Executes a shell command or script.
    """
    result = context.resources.local_shell.execute("echo 'Running after loop'")
    return result

# Define the hive_script_task op
@op(
    name="hive_script_task",
    description="Hive Script Task",
    ins={"input_data": In(str, description="Input data from the run_after_loop op")},
    out=Out(str, description="Output of the hive_script_task op"),
    retry_policy=RetryPolicy(max_retries=0),
    required_resource_keys={"hive_local"}
)
def hive_script_task(context, input_data):
    """
    Executes a Hive script using the Hive Local Database.
    """
    result = context.resources.hive_local.execute("SELECT * FROM some_table")
    return result

# Define the job
@job(
    name="run_after_loop_pipeline",
    description="No description provided.",
    executor_def=ResourceDefinition.in_process_executor,
    resource_defs={
        "local_shell": ResourceDefinition.mock_resource(),
        "hive_local": ResourceDefinition.mock_resource(),
        "io_manager": fs_io_manager
    }
)
def run_after_loop_pipeline():
    """
    Defines the run_after_loop_pipeline job with the specified task dependencies.
    """
    hive_script_task(run_after_loop())