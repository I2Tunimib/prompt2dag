# Generated by Prefect Pipeline Generator
# Date: 2024-06-28
# Pipeline: run_system_check_pipeline
# Description: Sequential pipeline executing Hive operations for COVID-19 realtime streaming data.

import subprocess
import logging
from pathlib import Path

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.server.schemas.schedules import CronSchedule
from prefect.blocks.system import Secret

# Configure logger
logger = logging.getLogger(__name__)


@task(retries=0, retry_delay_seconds=0)
def run_system_check() -> None:
    """
    Perform a simple system health check.

    This task runs a shell command to verify that the environment is ready.
    """
    log = get_run_logger()
    command = ["echo", "System check passed"]
    log.info("Executing system check command: %s", " ".join(command))

    try:
        result = subprocess.run(
            command,
            check=True,
            capture_output=True,
            text=True,
        )
        log.info("System check output: %s", result.stdout.strip())
    except subprocess.CalledProcessError as exc:
        log.error("System check failed: %s", exc.stderr.strip())
        raise


@task(retries=0, retry_delay_seconds=0)
def execute_hive_script() -> None:
    """
    Execute a Hive script using the Hive connection stored in a Prefect Secret block.

    The Hive connection secret should contain the necessary JDBC URL or connection
    string required by the `hive` CLI.
    """
    log = get_run_logger()

    # Retrieve Hive connection details from Prefect Secret block
    try:
        hive_secret = Secret.load("hive_local_conn")
        hive_conn_str = hive_secret.get()
        log.info("Retrieved Hive connection string from secret.")
    except Exception as exc:
        log.error("Failed to load Hive connection secret: %s", exc)
        raise

    # Path to the Hive script (placeholder - adjust as needed)
    hive_script_path = Path("/opt/hive/scripts/system_check.hql")
    if not hive_script_path.is_file():
        log.error("Hive script not found at %s", hive_script_path)
        raise FileNotFoundError(f"Hive script not found: {hive_script_path}")

    # Construct the Hive command
    command = [
        "hive",
        "-e",
        f"SET hive.connection={hive_conn_str};",
        "-f",
        str(hive_script_path),
    ]
    log.info("Executing Hive script with command: %s", " ".join(command))

    try:
        result = subprocess.run(
            command,
            check=True,
            capture_output=True,
            text=True,
        )
        log.info("Hive script executed successfully. Output:\n%s", result.stdout.strip())
    except subprocess.CalledProcessError as exc:
        log.error("Hive script execution failed: %s", exc.stderr.strip())
        raise


@flow(
    name="run_system_check_pipeline",
    task_runner=SequentialTaskRunner(),
)
def run_system_check_pipeline() -> None:
    """
    Prefect flow orchestrating a system check followed by Hive script execution.

    The flow runs tasks sequentially:
    1. run_system_check
    2. execute_hive_script (depends on the successful completion of the system check)
    """
    run_system_check()
    execute_hive_script()


# Deployment specification with schedule and runtime configuration
DeploymentSpec(
    name="run_system_check_pipeline_deployment",
    flow=run_system_check_pipeline,
    schedule=CronSchedule(
        cron="00 1 * * *",
        timezone="UTC",
        day_or=True,
    ),
    tags=["daily", "hive", "system-check"],
    work_pool_name="default-agent-pool",
    enforce_parameter_schema=False,
    parameters={},
    flow_run_name="run_system_check_pipeline_{timestamp}",
    description="Daily execution at 01:00 UTC to run system checks and Hive scripts.",
    is_schedule_active=True,
    catchup=False,
)