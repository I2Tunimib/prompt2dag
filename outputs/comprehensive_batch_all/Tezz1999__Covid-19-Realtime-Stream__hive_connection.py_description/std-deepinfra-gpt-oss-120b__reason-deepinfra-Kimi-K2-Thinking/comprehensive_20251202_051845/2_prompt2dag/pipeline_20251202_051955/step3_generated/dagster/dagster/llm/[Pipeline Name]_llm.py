# Generated by Dagster Pipeline Generator
# Date: 2024-06-28
# Pipeline: covid_hive_pipeline
# Description: Simple linear data pipeline that executes Hive database operations for COVID-19 realtime streaming data.

from dagster import (
    op,
    job,
    In,
    Out,
    Nothing,
    ResourceDefinition,
    fs_io_manager,
    in_process_executor,
    ScheduleDefinition,
    ScheduleStatus,
    schedule,
    InitResourceContext,
)


# ----------------------------------------------------------------------
# Resources
# ----------------------------------------------------------------------
@ResourceDefinition
def hive_local_resource(context: InitResourceContext) -> dict:
    """
    Stub resource representing a local Hive connection.

    In a real deployment, this would establish a connection to a Hive
    server (e.g., via PyHive or similar library) and return a client
    object that can be used by ops.
    """
    # Placeholder connection details
    return {"connection_string": "jdbc:hive2://localhost:10000/default"}


# ----------------------------------------------------------------------
# Ops
# ----------------------------------------------------------------------
@op(
    name="run_system_check",
    description="Performs a system health check before executing Hive scripts.",
    out=Out(Nothing),
    retry_policy=None,
)
def run_system_check() -> Nothing:
    """
    Execute any necessary pre‑flight checks (e.g., network connectivity,
    Hive service availability). This op does not produce an output
    other than signalling successful completion.
    """
    # Example placeholder logic
    # In production, replace with real checks and raise exceptions on failure.
    return None


@op(
    name="run_hive_script",
    description="Executes the Hive script that processes COVID‑19 realtime streaming data.",
    ins={"system_check": In(Nothing)},
    out=Out(Nothing),
    retry_policy=None,
)
def run_hive_script(context, system_check: Nothing) -> Nothing:
    """
    Run the Hive script using the ``hive_local`` resource.

    Args:
        context: Dagster op context providing access to resources.
        system_check: Input placeholder ensuring this op runs after the system check.

    Returns:
        Nothing – the op signals completion via its successful execution.
    """
    hive_conn = context.resources.hive_local
    # Placeholder for actual Hive script execution.
    # Replace with real logic, e.g., using PyHive:
    # cursor = hive_conn.cursor()
    # cursor.execute("YOUR HIVE SCRIPT HERE")
    context.log.info(f"Executing Hive script with connection: {hive_conn}")
    return None


# ----------------------------------------------------------------------
# Job
# ----------------------------------------------------------------------
@job(
    name="covid_hive_pipeline",
    description="Simple linear data pipeline that executes Hive database operations for COVID-19 realtime streaming data.",
    executor_def=in_process_executor,
    resource_defs={"hive_local": hive_local_resource, "io_manager": fs_io_manager},
)
def covid_hive_job():
    """
    Sequential job that first runs a system check and then executes a Hive script.
    """
    system_check_result = run_system_check()
    run_hive_script(system_check_result)


# ----------------------------------------------------------------------
# Schedule
# ----------------------------------------------------------------------
@schedule(
    cron_schedule="00 1 * * *",
    job=covid_hive_job,
    execution_timezone="UTC",
    default_status=ScheduleStatus.RUNNING,
    catchup=False,
    description="Daily execution at 01:00 UTC.",
)
def covid_hive_schedule():
    """
    Schedule that triggers the ``covid_hive_job`` every day at 01:00 UTC.
    """
    return {}  # No additional run config needed.