# Generated by Prefect Pipeline Generator
# Date: 2024-06-28
# Prefect version: 2.14.0
# Pipeline: run_system_check_pipeline

import subprocess
from typing import Any

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.server.schemas.schedules import CronSchedule
from prefect.blocks.system import Secret


@task(retries=0, name="Run System Check")
def run_system_check() -> str:
    """
    Execute the system check command in a subprocess.

    Returns
    -------
    str
        Standard output from the system check command.

    Raises
    ------
    RuntimeError
        If the subprocess exits with a non-zero status.
    """
    logger = get_run_logger()
    command = ["bash", "-c", "echo 'Running system check...'"]  # Replace with actual command

    logger.info("Executing system check command: %s", " ".join(command))
    try:
        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            check=True,
        )
        logger.info("System check completed successfully.")
        logger.debug("System check output: %s", result.stdout.strip())
        return result.stdout.strip()
    except subprocess.CalledProcessError as exc:
        logger.error(
            "System check failed with exit code %s. Stderr: %s",
            exc.returncode,
            exc.stderr,
        )
        raise RuntimeError("System check failed") from exc


@task(retries=0, name="Run Hive Script")
def run_hive_script(system_check_output: str) -> str:
    """
    Execute a Hive script using a secret connection string.

    Parameters
    ----------
    system_check_output : str
        Output from the previous system check task (used for logging or conditional logic).

    Returns
    -------
    str
        Standard output from the Hive script execution.

    Raises
    ------
    RuntimeError
        If the Hive subprocess exits with a non-zero status.
    """
    logger = get_run_logger()
    logger.info("Received system check output: %s", system_check_output)

    # Load Hive connection secret
    try:
        hive_secret: Secret = Secret.load("hive_local_conn")
        hive_conn_str: str = hive_secret.get()
        logger.debug("Loaded Hive connection string from secret.")
    except Exception as exc:
        logger.error("Failed to load Hive connection secret: %s", exc)
        raise RuntimeError("Unable to retrieve Hive connection secret") from exc

    # Placeholder Hive command; replace with actual script/command as needed
    hive_command = [
        "bash",
        "-c",
        f"echo 'Running Hive script with connection: {hive_conn_str}'",
    ]

    logger.info("Executing Hive command: %s", " ".join(hive_command))
    try:
        result = subprocess.run(
            hive_command,
            capture_output=True,
            text=True,
            check=True,
        )
        logger.info("Hive script completed successfully.")
        logger.debug("Hive script output: %s", result.stdout.strip())
        return result.stdout.strip()
    except subprocess.CalledProcessError as exc:
        logger.error(
            "Hive script failed with exit code %s. Stderr: %s",
            exc.returncode,
            exc.stderr,
        )
        raise RuntimeError("Hive script execution failed") from exc


@flow(
    name="run_system_check_pipeline",
    task_runner=SequentialTaskRunner(),
)
def run_system_check_pipeline() -> Any:
    """
    Prefect flow orchestrating the system check followed by a Hive script execution.

    The flow runs tasks sequentially:
    1. ``run_system_check`` – performs a system health check.
    2. ``run_hive_script`` – runs a Hive script that depends on the system check.
    """
    logger = get_run_logger()
    logger.info("Starting run_system_check_pipeline flow.")

    # Execute the first task
    system_check_result = run_system_check()

    # Execute the dependent Hive script task
    hive_result = run_hive_script(system_check_result)

    logger.info("Flow completed. Hive script output: %s", hive_result)
    return {"system_check": system_check_result, "hive_script": hive_result}


# Deployment specification with schedule and work pool configuration
DeploymentSpec(
    name="run_system_check_pipeline_deployment",
    flow=run_system_check_pipeline,
    schedule=CronSchedule(cron="00 1 * * *", timezone="UTC"),
    tags=[],
    work_pool_name="default-agent-pool",
    enforce_parameter_schema=False,
    description="Deployment for the run_system_check_pipeline flow.",
    parameters={},
    flow_name="run_system_check_pipeline",
    paused=False,
    catchup=False,
)

if __name__ == "__main__":
    # Optional: run the flow locally for testing
    run_system_check_pipeline()