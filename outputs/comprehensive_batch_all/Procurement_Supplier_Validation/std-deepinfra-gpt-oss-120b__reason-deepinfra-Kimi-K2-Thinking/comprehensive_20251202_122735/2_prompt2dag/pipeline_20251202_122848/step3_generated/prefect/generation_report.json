{
  "generation_timestamp": "2025-12-02T12:32:03.261939",
  "pipeline_name": "load_and_modify_data_pipeline",
  "orchestrator": "prefect",
  "detected_pattern": "sequential",
  "task_count": 3,
  "strategies": {
    "template": {
      "strategy": "template",
      "orchestrator": "prefect",
      "success": true,
      "output_path": "/Users/abubakarialidu/Desktop/Prompt2DAG/New_Experiments_2/outputs/comprehensive_batch_all/Procurement_Supplier_Validation/std-deepinfra-gpt-oss-120b__reason-deepinfra-Kimi-K2-Thinking/comprehensive_20251202_122735/2_prompt2dag/pipeline_20251202_122848/step3_generated/prefect/prefect/template/load_and_modify_data_pipeline_template.py",
      "generation_time_ms": 41.25213623046875,
      "token_usage": {},
      "warnings": [],
      "errors": [],
      "metadata": {
        "pattern": "sequential",
        "template_used": "pattern_sequential.py.jinja2",
        "task_count": 3
      }
    },
    "llm": {
      "strategy": "llm",
      "orchestrator": "prefect",
      "success": true,
      "output_path": "/Users/abubakarialidu/Desktop/Prompt2DAG/New_Experiments_2/outputs/comprehensive_batch_all/Procurement_Supplier_Validation/std-deepinfra-gpt-oss-120b__reason-deepinfra-Kimi-K2-Thinking/comprehensive_20251202_122735/2_prompt2dag/pipeline_20251202_122848/step3_generated/prefect/prefect/llm/load_and_modify_data_pipeline_llm.py",
      "generation_time_ms": 13313.945055007935,
      "token_usage": {
        "input_tokens": 694,
        "output_tokens": 1951
      },
      "warnings": [],
      "errors": [],
      "metadata": {
        "pattern": "sequential",
        "llm_model": "openai/gpt-oss-120b",
        "task_count": 3
      }
    },
    "hybrid": {
      "strategy": "hybrid",
      "orchestrator": "prefect",
      "success": true,
      "output_path": "/Users/abubakarialidu/Desktop/Prompt2DAG/New_Experiments_2/outputs/comprehensive_batch_all/Procurement_Supplier_Validation/std-deepinfra-gpt-oss-120b__reason-deepinfra-Kimi-K2-Thinking/comprehensive_20251202_122735/2_prompt2dag/pipeline_20251202_122848/step3_generated/prefect/prefect/hybrid/load_and_modify_data_pipeline_hybrid.py",
      "generation_time_ms": 3231.837034225464,
      "token_usage": {
        "input_tokens": 616,
        "output_tokens": 599
      },
      "warnings": [],
      "errors": [],
      "metadata": {
        "pattern": "sequential",
        "task_snippets_count": 3,
        "llm_model": "openai/gpt-oss-120b",
        "task_count": 3
      }
    }
  },
  "summary": {
    "total_strategies": 3,
    "successful": 3,
    "failed": 0,
    "fastest_ms": 41.25213623046875,
    "total_tokens": 3860
  }
}