metadata:
  target_orchestrator: airflow
  generated_at: 2025-12-02 12:31:31.217963
  source_analysis_file: Pipeline_Description_Dataset/Procurement_Supplier_Validation.txt
  pipeline_name: load_and_modify_data_pipeline
  pipeline_description: No description provided.
  orchestrator_specific: {}
schedule:
  enabled: false
  schedule_expression:
  start_date:
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: filesystem_data_dir
    conn_type: fs
    description: Shared Data Directory (DATA_DIR)
    config:
      base_path: /data
      base_url:
      host:
      port:
      protocol: file
      database:
      schema:
      bucket:
      queue_name:
  - conn_id: api_load_modify_service
    conn_type: http
    description: Load‑and‑Modify Service API
    config:
      base_path:
      base_url: http://load-modify-service:3003
      host: load-modify-service
      port: 3003
      protocol: http
      database:
      schema:
      bucket:
      queue_name:
  - conn_id: api_reconciliation_service
    conn_type: http
    description: Entity Reconciliation Service API
    config:
      base_path:
      base_url: http://reconciliation-service:3003
      host: reconciliation-service
      port: 3003
      protocol: http
      database:
      schema:
      bucket:
      queue_name:
  - conn_id: api_save_service
    conn_type: http
    description: Save Service API
    config:
      base_path:
      base_url: http://save-service:3003
      host: save-service
      port: 3003
      protocol: http
      database:
      schema:
      bucket:
      queue_name:
  - conn_id: mongodb_instance
    conn_type: mongo
    description: MongoDB Instance
    config:
      base_path:
      base_url:
      host: mongo
      port: 27017
      protocol: mongodb
      database:
      schema:
      bucket:
      queue_name:
  - conn_id: intertwino_api
    conn_type: http
    description: Intertwino API
    config:
      base_path:
      base_url: http://intertwino-api:5005
      host: intertwino-api
      port: 5005
      protocol: http
      database:
      schema:
      bucket:
      queue_name:
  - conn_id: docker_network_app
    conn_type: generic
    description: Custom Docker Network (app_network)
    config:
      base_path:
      base_url:
      host:
      port:
      protocol:
      database:
      schema:
      bucket:
      queue_name:
  - conn_id: wikidata_api
    conn_type: http
    description: Wikidata Entity API
    config:
      base_path:
      base_url: https://www.wikidata.org/w/api.php
      host: www.wikidata.org
      port: 443
      protocol: https
      database:
      schema:
      bucket:
      queue_name:
tasks:
  - task_id: load_and_modify_data
    task_name: Load and Modify Supplier Data
    operator_class: DockerOperator
    operator_module: airflow.providers.docker.operators.docker
    component_ref: load_and_modify_data
    config:
      image: i2t-backendwithintertwino6-load-and-modify:latest
      environment:
        DATASET_ID: '2'
        TABLE_NAME_PREFIX: JOT_
        DATA_DIR: ${DATA_DIR}
      network_mode: app_network
      auto_remove: true
      docker_url: unix://var/run/docker.sock
    upstream_task_ids: []
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 0
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
  - task_id: reconcile_supplier_names
    task_name: Entity Reconciliation (Wikidata)
    operator_class: DockerOperator
    operator_module: airflow.providers.docker.operators.docker
    component_ref: reconcile_supplier_names
    config:
      image: i2t-backendwithintertwino6-reconciliation:latest
      environment:
        PRIMARY_COLUMN: supplier_name
        RECONCILIATOR_ID: wikidataEntity
        DATASET_ID: '2'
        DATA_DIR: ${DATA_DIR}
      network_mode: app_network
      auto_remove: true
      docker_url: unix://var/run/docker.sock
    upstream_task_ids:
      - load_and_modify_data
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 0
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
  - task_id: save_validated_data
    task_name: Save Final Validated Supplier Data
    operator_class: DockerOperator
    operator_module: airflow.providers.docker.operators.docker
    component_ref: save_validated_data
    config:
      image: i2t-backendwithintertwino6-save:latest
      environment:
        DATASET_ID: '2'
        DATA_DIR: ${DATA_DIR}
      network_mode: app_network
      auto_remove: true
      docker_url: unix://var/run/docker.sock
    upstream_task_ids:
      - reconcile_supplier_names
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 0
    validation_warnings:
      - Uses image default command - ensure Dockerfile has ENTRYPOINT/CMD
