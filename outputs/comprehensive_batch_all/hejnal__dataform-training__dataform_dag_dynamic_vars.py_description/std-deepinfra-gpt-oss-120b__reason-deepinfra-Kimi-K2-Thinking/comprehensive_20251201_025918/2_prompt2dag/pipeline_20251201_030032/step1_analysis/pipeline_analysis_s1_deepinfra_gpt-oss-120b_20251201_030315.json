{
  "metadata": {
    "schema_version": "1.0",
    "analysis_timestamp": "2025-12-01T03:03:15.552113",
    "source_file": "Pipeline_Description_Dataset/hejnal__dataform-training__dataform_dag_dynamic_vars.py_description.txt",
    "llm_provider": "deepinfra",
    "llm_model": "gpt-oss-120b",
    "analysis_results": {
      "detected_patterns": [
        "sequential",
        "sensor_driven",
        "event_driven"
      ],
      "task_executors_used": [
        "python",
        "custom"
      ],
      "has_branching": false,
      "has_parallelism": false,
      "has_sensors": true,
      "total_components": 6,
      "complexity_score": "low"
    },
    "orchestrator_compatibility": {
      "airflow": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential pattern fully supported",
          "Native sensor support"
        ]
      },
      "prefect": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Sequential flow with task dependencies",
          "wait_for() or custom sensors"
        ]
      },
      "dagster": {
        "supported": true,
        "confidence": "high",
        "notes": [
          "Op graph with dependencies",
          "Sensors via run_status_sensor"
        ]
      }
    },
    "validation_warnings": []
  },
  "pipeline_summary": {
    "name": "Data Transformation Pipeline",
    "description": "Google Cloud Dataform-based data transformation pipeline that orchestrates parameterized SQL workflow executions.",
    "flow_patterns": [
      "sequential",
      "sensor_driven",
      "event_driven"
    ],
    "task_executors": [
      "python",
      "custom"
    ],
    "complexity": "low"
  },
  "components": [
    {
      "id": "initialize_pipeline",
      "name": "Initialize Pipeline",
      "category": "Other",
      "description": "Marks the start of the pipeline execution.",
      "inputs": [
        "Dataset trigger \"dataform-training-data-ingestion\""
      ],
      "outputs": [
        "Trigger for parameter parsing task"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "dataform_training_data_ingestion",
          "direction": "input",
          "kind": "dataset",
          "format": "other",
          "path_pattern": "dataform-training-data-ingestion",
          "connection_id": null
        },
        {
          "name": "parameter_parsing_trigger",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "No upstream dependencies",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 0,
        "delay_seconds": 0,
        "exponential_backoff": false,
        "retry_on": []
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [
          "dataform-training-data-ingestion"
        ],
        "produces": []
      }
    },
    {
      "id": "parse_input_parameters",
      "name": "Parse Input Parameters",
      "category": "Transformer",
      "description": "Parses DAG run configuration and logical date, producing compilation configuration via XCom.",
      "inputs": [
        "DAG run configuration parameters",
        "Logical date (DD/MM/YYYY)"
      ],
      "outputs": [
        "Compilation configuration XCom (date and description)"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "dag_run_config",
          "direction": "input",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "logical_date",
          "direction": "input",
          "kind": "object",
          "format": "string",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "compilation_config_xcom",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after pipeline initialization",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 0,
        "delay_seconds": 0,
        "exponential_backoff": false,
        "retry_on": []
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "create_compilation_result",
      "name": "Create Dataform Compilation Result",
      "category": "Enricher",
      "description": "Calls Google Cloud Dataform API to create a compilation result using parsed parameters.",
      "inputs": [
        "Compilation configuration XCom (date, description)"
      ],
      "outputs": [
        "Compilation result name (used for workflow invocation)"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "compilation_config_xcom",
          "direction": "input",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "compilation_result_name",
          "direction": "output",
          "kind": "object",
          "format": "string",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after parsing input parameters",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 0,
        "delay_seconds": 0,
        "exponential_backoff": false,
        "retry_on": []
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "modelling_cloud_default",
          "type": "gcp",
          "purpose": "Google Cloud Dataform API access"
        }
      ],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "trigger_workflow_invocation",
      "name": "Trigger Dataform Workflow Invocation",
      "category": "Orchestrator",
      "description": "Initiates a Dataform workflow execution using the compilation result, with async mode and incremental table refresh enabled.",
      "inputs": [
        "Compilation result name"
      ],
      "outputs": [
        "Workflow invocation ID"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "compilation_result_name",
          "direction": "input",
          "kind": "object",
          "format": "string",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "workflow_invocation_id",
          "direction": "output",
          "kind": "object",
          "format": "string",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after compilation result is created",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 0,
        "delay_seconds": 0,
        "exponential_backoff": false,
        "retry_on": []
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "modelling_cloud_default",
          "type": "gcp",
          "purpose": "Google Cloud Dataform API access"
        }
      ],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "monitor_workflow_state",
      "name": "Monitor Workflow Invocation State",
      "category": "Sensor",
      "description": "Polls the Dataform workflow until it reaches a terminal state (SUCCEEDED or FAILED).",
      "inputs": [
        "Workflow invocation ID"
      ],
      "outputs": [
        "Sensor completion signal (success or failure)"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "workflow_invocation_id",
          "direction": "input",
          "kind": "object",
          "format": "string",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "sensor_completion",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after workflow invocation is triggered",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 0,
        "delay_seconds": 0,
        "exponential_backoff": false,
        "retry_on": []
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [
        {
          "id": "modelling_cloud_default",
          "type": "gcp",
          "purpose": "Google Cloud Dataform API access"
        }
      ],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    },
    {
      "id": "finalize_pipeline",
      "name": "Finalize Pipeline",
      "category": "Other",
      "description": "Marks successful completion of the pipeline after the sensor confirms termination.",
      "inputs": [
        "Sensor completion signal"
      ],
      "outputs": [
        "Pipeline termination"
      ],
      "executor_type": "python",
      "executor_config": {
        "image": null,
        "command": null,
        "script_path": null,
        "entry_point": null,
        "environment": {},
        "resources": {
          "cpu": null,
          "memory": null,
          "gpu": null
        },
        "network": null
      },
      "io_spec": [
        {
          "name": "sensor_completion",
          "direction": "input",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        },
        {
          "name": "pipeline_termination",
          "direction": "output",
          "kind": "object",
          "format": "json",
          "path_pattern": null,
          "connection_id": null
        }
      ],
      "upstream_policy": {
        "type": "all_success",
        "description": "Runs after workflow state sensor completes",
        "timeout_seconds": null
      },
      "retry_policy": {
        "max_attempts": 0,
        "delay_seconds": 0,
        "exponential_backoff": false,
        "retry_on": []
      },
      "concurrency": {
        "supports_parallelism": false,
        "supports_dynamic_mapping": false,
        "map_over_param": null,
        "max_parallel_instances": null
      },
      "connections": [],
      "datasets": {
        "consumes": [],
        "produces": []
      }
    }
  ],
  "flow_structure": {
    "pattern": "sequential",
    "entry_points": [
      "initialize_pipeline"
    ],
    "nodes": {
      "initialize_pipeline": {
        "kind": "Task",
        "component_type_id": "initialize_pipeline",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "parse_input_parameters"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "parse_input_parameters": {
        "kind": "Task",
        "component_type_id": "parse_input_parameters",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "create_compilation_result"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "create_compilation_result": {
        "kind": "Task",
        "component_type_id": "create_compilation_result",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "trigger_workflow_invocation"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "trigger_workflow_invocation": {
        "kind": "Task",
        "component_type_id": "trigger_workflow_invocation",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "monitor_workflow_state"
        ],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      },
      "monitor_workflow_state": {
        "kind": "Sensor",
        "component_type_id": null,
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [
          "finalize_pipeline"
        ],
        "sensor_config": {
          "sensor_type": "custom",
          "target": "Dataform workflow invocation ID",
          "poke_interval_seconds": 60,
          "timeout_seconds": 3600,
          "mode": "poke"
        },
        "branch_config": null,
        "parallel_config": null
      },
      "finalize_pipeline": {
        "kind": "Task",
        "component_type_id": "finalize_pipeline",
        "upstream_policy": {
          "type": "all_success",
          "timeout_seconds": null
        },
        "next_nodes": [],
        "branch_config": null,
        "sensor_config": null,
        "parallel_config": null
      }
    },
    "edges": [
      {
        "from": "initialize_pipeline",
        "to": "parse_input_parameters",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      },
      {
        "from": "parse_input_parameters",
        "to": "create_compilation_result",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      },
      {
        "from": "create_compilation_result",
        "to": "trigger_workflow_invocation",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      },
      {
        "from": "trigger_workflow_invocation",
        "to": "monitor_workflow_state",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      },
      {
        "from": "monitor_workflow_state",
        "to": "finalize_pipeline",
        "edge_type": "success",
        "condition": null,
        "metadata": {}
      }
    ]
  },
  "parameters": {
    "pipeline": {
      "name": {
        "description": "Pipeline identifier",
        "type": "string",
        "default": "Data Transformation Pipeline",
        "required": false,
        "constraints": null
      },
      "description": {
        "description": "Pipeline description",
        "type": "string",
        "default": "Google Cloud Dataform-based data transformation pipeline that orchestrates parameterized SQL workflow executions.",
        "required": false,
        "constraints": null
      },
      "tags": {
        "description": "Classification tags",
        "type": "array",
        "default": [],
        "required": false
      }
    },
    "schedule": {
      "enabled": {
        "description": "Whether pipeline runs on schedule",
        "type": "boolean",
        "default": null,
        "required": false
      },
      "cron_expression": {
        "description": "Cron or preset (e.g., @daily, 0 0 * * *)",
        "type": "string",
        "default": null,
        "required": false
      },
      "start_date": {
        "description": "When to start scheduling",
        "type": "datetime",
        "default": null,
        "required": false,
        "format": "ISO8601"
      },
      "end_date": {
        "description": "When to stop scheduling",
        "type": "datetime",
        "default": null,
        "required": false
      },
      "timezone": {
        "description": "Schedule timezone",
        "type": "string",
        "default": null,
        "required": false
      },
      "catchup": {
        "description": "Run missed intervals",
        "type": "boolean",
        "default": null,
        "required": false
      },
      "batch_window": {
        "description": "Batch window parameter name (e.g., ds, execution_date)",
        "type": "string",
        "default": null,
        "required": false
      },
      "partitioning": {
        "description": "Data partitioning strategy (e.g., daily, hourly, monthly)",
        "type": "string",
        "default": null,
        "required": false
      }
    },
    "execution": {
      "max_active_runs": {
        "description": "Max concurrent pipeline runs",
        "type": "integer",
        "default": null,
        "required": false
      },
      "timeout_seconds": {
        "description": "Pipeline execution timeout",
        "type": "integer",
        "default": null,
        "required": false
      },
      "retry_policy": {
        "description": "Pipeline-level retry behavior",
        "type": "object",
        "default": null,
        "required": false
      },
      "depends_on_past": {
        "description": "Whether execution depends on previous run success",
        "type": "boolean",
        "default": false,
        "required": false
      }
    },
    "components": {
      "initialize_pipeline": {
        "description": {
          "description": "Marks the start of the pipeline execution.",
          "type": "string",
          "default": null,
          "required": false,
          "constraints": null
        }
      },
      "parse_input_parameters": {
        "description_param": {
          "description": "Description parameter passed via DAG run configuration.",
          "type": "string",
          "default": "Default Description",
          "required": false,
          "constraints": null
        },
        "logical_date": {
          "description": "Logical execution date formatted as DD/MM/YYYY.",
          "type": "string",
          "default": null,
          "required": false,
          "constraints": "Format: DD/MM/YYYY"
        }
      },
      "create_compilation_result": {
        "gcp_conn_id": {
          "description": "Google Cloud connection identifier for Dataform API access.",
          "type": "string",
          "default": "modelling_cloud_default",
          "required": false,
          "constraints": null
        }
      },
      "trigger_workflow_invocation": {
        "asynchronous": {
          "description": "Run the workflow invocation in asynchronous mode.",
          "type": "boolean",
          "default": true,
          "required": false,
          "constraints": null
        },
        "gcp_conn_id": {
          "description": "Google Cloud connection identifier for Dataform API access.",
          "type": "string",
          "default": "modelling_cloud_default",
          "required": false,
          "constraints": null
        },
        "fully_refresh_incremental_tables_enabled": {
          "description": "Enable full refresh of incremental tables during workflow execution.",
          "type": "boolean",
          "default": true,
          "required": false,
          "constraints": null
        }
      },
      "monitor_workflow_state": {
        "expected_statuses": {
          "description": "Set of terminal statuses to monitor for workflow completion.",
          "type": "array",
          "default": [
            "SUCCEEDED",
            "FAILED"
          ],
          "required": false,
          "constraints": "Values: SUCCEEDED, FAILED"
        },
        "gcp_conn_id": {
          "description": "Google Cloud connection identifier for Dataform API access.",
          "type": "string",
          "default": "modelling_cloud_default",
          "required": false,
          "constraints": null
        }
      },
      "finalize_pipeline": {
        "description": {
          "description": "Marks successful completion of the pipeline after the sensor confirms termination.",
          "type": "string",
          "default": null,
          "required": false,
          "constraints": null
        }
      }
    },
    "environment": {}
  },
  "integrations": {
    "connections": [
      {
        "id": "gcp_dataform_api",
        "name": "Google Cloud Dataform API",
        "type": "api",
        "config": {
          "base_path": null,
          "base_url": "https://dataform.googleapis.com",
          "host": "dataform.googleapis.com",
          "port": 443,
          "protocol": "https",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "iam",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": "/path/to/gcp/credentials.json"
        },
        "used_by_components": [
          "create_compilation_result",
          "trigger_workflow_invocation",
          "monitor_workflow_state"
        ],
        "direction": "both",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "Compilation result name",
            "Workflow invocation ID"
          ],
          "consumes": [
            "Compilation parameters (date, description)",
            "Compilation result name"
          ]
        }
      },
      {
        "id": "bigquery_dataset_trigger",
        "name": "BigQuery Dataset Trigger – dataform‑training‑data‑ingestion",
        "type": "data_warehouse",
        "config": {
          "base_path": null,
          "base_url": "https://bigquery.googleapis.com",
          "host": "bigquery.googleapis.com",
          "port": 443,
          "protocol": "https",
          "database": null,
          "schema": null,
          "bucket": null,
          "queue_name": null
        },
        "authentication": {
          "type": "iam",
          "token_env_var": null,
          "username_env_var": null,
          "password_env_var": null,
          "credentials_path": "/path/to/gcp/credentials.json"
        },
        "used_by_components": [
          "initialize_pipeline"
        ],
        "direction": "input",
        "rate_limit": {
          "requests_per_second": null,
          "burst": null
        },
        "datasets": {
          "produces": [
            "Dataset update event"
          ],
          "consumes": []
        }
      }
    ],
    "data_lineage": {
      "sources": [
        "BigQuery dataset \"dataform-training-data-ingestion\" – provides the trigger event that starts the pipeline.",
        "DAG run configuration parameters and logical date supplied at pipeline start."
      ],
      "sinks": [
        "Dataform workflow execution – represented by the workflow invocation ID and its final state (SUCCEEDED or FAILED).",
        "Pipeline completion marker (finalize_pipeline task)."
      ],
      "intermediate_datasets": [
        "Compilation result name generated by the Dataform CreateCompilationResult API call.",
        "Workflow invocation ID returned by the Dataform CreateWorkflowInvocation API call."
      ]
    }
  }
}