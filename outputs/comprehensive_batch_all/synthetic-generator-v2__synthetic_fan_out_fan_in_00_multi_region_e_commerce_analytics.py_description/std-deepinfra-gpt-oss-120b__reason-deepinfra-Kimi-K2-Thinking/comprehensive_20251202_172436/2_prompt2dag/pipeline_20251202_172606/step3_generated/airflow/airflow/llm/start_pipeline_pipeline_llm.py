# Generated by Airflow DAG Generator on 2024-06-13
# DAG: start_pipeline_pipeline
# Description: No description provided.
# Pattern: fanout_fanin

import logging
from datetime import datetime

from airflow import DAG
from airflow.decorators import task
from airflow.exceptions import AirflowException
from airflow.utils.dates import days_ago
from airflow.hooks.base import BaseHook

# Default arguments applied to all tasks unless overridden
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 0,
    "retry_delay": 300,  # 5 minutes
    "start_date": days_ago(1),
}

# DAG definition
with DAG(
    dag_id="start_pipeline_pipeline",
    description="No description provided.",
    schedule_interval="@daily",
    catchup=False,
    default_args=default_args,
    tags=["fanout_fanin"],
    is_paused_upon_creation=True,  # Disabled by default
    max_active_runs=1,
) as dag:

    @task(task_id="start_pipeline")
    def start_pipeline():
        """Initial task to mark the start of the pipeline."""
        try:
            logging.info("Pipeline execution started.")
            return "started"
        except Exception as exc:
            raise AirflowException(f"Start pipeline failed: {exc}")

    @task(task_id="ingest_apac", retries=2)
    def ingest_apac(_):
        """Ingest APAC sales CSV files from the configured FS connection."""
        try:
            conn = BaseHook.get_connection("regional_sales_apac")
            logging.info("Ingesting APAC sales data from %s", conn.host)
            # Placeholder for actual ingestion logic
            return {"region": "APAC", "data": []}
        except Exception as exc:
            raise AirflowException(f"APAC ingestion failed: {exc}")

    @task(task_id="ingest_eu", retries=2)
    def ingest_eu(_):
        """Ingest EU sales CSV files from the configured FS connection."""
        try:
            conn = BaseHook.get_connection("regional_sales_eu")
            logging.info("Ingesting EU sales data from %s", conn.host)
            # Placeholder for actual ingestion logic
            return {"region": "EU", "data": []}
        except Exception as exc:
            raise AirflowException(f"EU ingestion failed: {exc}")

    @task(task_id="ingest_us_east", retries=2)
    def ingest_us_east(_):
        """Ingest US‑East sales CSV files from the configured FS connection."""
        try:
            conn = BaseHook.get_connection("regional_sales_us_east")
            logging.info("Ingesting US‑East sales data from %s", conn.host)
            # Placeholder for actual ingestion logic
            return {"region": "US_EAST", "data": []}
        except Exception as exc:
            raise AirflowException(f"US‑East ingestion failed: {exc}")

    @task(task_id="ingest_us_west", retries=2)
    def ingest_us_west(_):
        """Ingest US‑West sales CSV files from the configured FS connection."""
        try:
            conn = BaseHook.get_connection("regional_sales_us_west")
            logging.info("Ingesting US‑West sales data from %s", conn.host)
            # Placeholder for actual ingestion logic
            return {"region": "US_WEST", "data": []}
        except Exception as exc:
            raise AirflowException(f"US‑West ingestion failed: {exc}")

    @task(task_id="convert_currency_apac", retries=2)
    def convert_currency_apac(apac_data):
        """Convert APAC sales figures to USD."""
        try:
            logging.info("Converting APAC currency to USD.")
            # Placeholder conversion logic
            apac_data["converted"] = True
            return apac_data
        except Exception as exc:
            raise AirflowException(f"APAC currency conversion failed: {exc}")

    @task(task_id="convert_currency_eu", retries=2)
    def convert_currency_eu(eu_data):
        """Convert EU sales figures to USD."""
        try:
            logging.info("Converting EU currency to USD.")
            # Placeholder conversion logic
            eu_data["converted"] = True
            return eu_data
        except Exception as exc:
            raise AirflowException(f"EU currency conversion failed: {exc}")

    @task(task_id="convert_currency_us_east", retries=2)
    def convert_currency_us_east(us_east_data):
        """Convert US‑East sales figures to USD (identity conversion)."""
        try:
            logging.info("Converting US‑East currency to USD.")
            # Placeholder conversion logic (no change needed)
            us_east_data["converted"] = True
            return us_east_data
        except Exception as exc:
            raise AirflowException(f"US‑East currency conversion failed: {exc}")

    @task(task_id="convert_currency_us_west", retries=2)
    def convert_currency_us_west(us_west_data):
        """Convert US‑West sales figures to USD (identity conversion)."""
        try:
            logging.info("Converting US‑West currency to USD.")
            # Placeholder conversion logic (no change needed)
            us_west_data["converted"] = True
            return us_west_data
        except Exception as exc:
            raise AirflowException(f"US‑West currency conversion failed: {exc}")

    @task(task_id="aggregate_global_revenue", retries=2)
    def aggregate_global_revenue(apac, eu, us_east, us_west):
        """Aggregate all regional revenues into a global report."""
        try:
            logging.info("Aggregating global revenue from all regions.")
            # Placeholder aggregation logic
            aggregated = {
                "APAC": apac,
                "EU": eu,
                "US_EAST": us_east,
                "US_WEST": us_west,
                "timestamp": datetime.utcnow().isoformat(),
            }
            # Simulate storing the report
            conn = BaseHook.get_connection("global_report_storage")
            logging.info("Storing aggregated report to %s", conn.host)
            return aggregated
        except Exception as exc:
            raise AirflowException(f"Global aggregation failed: {exc}")

    @task(task_id="end_pipeline")
    def end_pipeline(_):
        """Final task to mark the end of the pipeline."""
        try:
            logging.info("Pipeline execution completed successfully.")
            return "completed"
        except Exception as exc:
            raise AirflowException(f"End pipeline failed: {exc}")

    # -------------------------------------------------------------------------
    # Define task flow
    # -------------------------------------------------------------------------
    start = start_pipeline()

    # Fan‑out ingestion
    ingest_us_east_task = ingest_us_east(start)
    ingest_us_west_task = ingest_us_west(start)
    ingest_eu_task = ingest_eu(start)
    ingest_apac_task = ingest_apac(start)

    # Currency conversion
    convert_us_east = convert_currency_us_east(ingest_us_east_task)
    convert_us_west = convert_currency_us_west(ingest_us_west_task)
    convert_eu = convert_currency_eu(ingest_eu_task)
    convert_apac = convert_currency_apac(ingest_apac_task)

    # Fan‑in aggregation
    aggregated = aggregate_global_revenue(
        convert_apac, convert_eu, convert_us_east, convert_us_west
    )

    # End of pipeline
    end = end_pipeline(aggregated)

    # Explicit dependencies (optional, as >> already defines them)
    start >> [ingest_us_east_task, ingest_us_west_task, ingest_eu_task, ingest_apac_task]
    ingest_us_east_task >> convert_us_east
    ingest_us_west_task >> convert_us_west
    ingest_eu_task >> convert_eu
    ingest_apac_task >> convert_apac
    [convert_us_east, convert_us_west, convert_eu, convert_apac] >> aggregated
    aggregated >> end