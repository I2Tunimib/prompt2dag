# Generated by Dagster Code Generator
# Date: 2023-10-05
# Dagster Version: 1.5.0

from dagster import (
    job,
    op,
    Out,
    In,
    RetryPolicy,
    multiprocess_executor,
    fs_io_manager,
    resource,
    schedule,
)

# Resources
@resource
def local_filesystem():
    """Local File System resource."""
    pass

@resource
def data_warehouse():
    """Data Warehouse resource."""
    pass

@resource
def power_bi():
    """Power BI resource."""
    pass

@resource
def tableau():
    """Tableau resource."""
    pass

# Ops
@op(
    out={"claims_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"local_filesystem"},
)
def extract_claims(context):
    """Extract claims data from the local filesystem."""
    claims_data = context.resources.local_filesystem.load("claims_data")
    return claims_data

@op(
    out={"providers_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"local_filesystem"},
)
def extract_providers(context):
    """Extract providers data from the local filesystem."""
    providers_data = context.resources.local_filesystem.load("providers_data")
    return providers_data

@op(
    out={"joined_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"local_filesystem"},
)
def transform_join(context, claims_data, providers_data):
    """Transform and join claims and providers data."""
    joined_data = claims_data.join(providers_data)
    return joined_data

@op(
    out={"warehouse_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"data_warehouse"},
)
def load_warehouse(context, joined_data):
    """Load transformed data into the data warehouse."""
    context.resources.data_warehouse.load(joined_data)
    return joined_data

@op(
    out={"bi_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"power_bi", "tableau"},
)
def refresh_bi(context, joined_data):
    """Refresh Power BI and Tableau with the latest data."""
    context.resources.power_bi.refresh(joined_data)
    context.resources.tableau.refresh(joined_data)
    return joined_data

# Job
@job(
    name="extract_claims_pipeline",
    description="No description provided.",
    executor_def=multiprocess_executor,
    resource_defs={
        "local_filesystem": local_filesystem,
        "data_warehouse": data_warehouse,
        "power_bi": power_bi,
        "tableau": tableau,
        "io_manager": fs_io_manager,
    },
)
def extract_claims_pipeline():
    """Dagster job to extract, transform, and load claims data."""
    claims_data = extract_claims()
    providers_data = extract_providers()
    joined_data = transform_join(claims_data, providers_data)
    load_warehouse(joined_data)
    refresh_bi(joined_data)

# Schedule
@schedule(
    job=extract_claims_pipeline,
    cron_schedule="@daily",
    execution_timezone="UTC",
    name="extract_claims_pipeline_schedule",
    catchup=False,
)
def extract_claims_pipeline_schedule(_context):
    return {}