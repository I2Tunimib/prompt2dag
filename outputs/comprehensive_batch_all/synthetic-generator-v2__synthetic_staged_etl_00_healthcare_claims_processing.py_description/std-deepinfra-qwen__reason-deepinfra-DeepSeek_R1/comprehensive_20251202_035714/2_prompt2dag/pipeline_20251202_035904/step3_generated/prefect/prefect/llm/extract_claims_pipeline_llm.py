# Generated by Prefect 2.x Code Generator
# Date: 2023-10-05
# Prefect Version: 2.14.0

from prefect import flow, task, get_run_logger
from prefect.task_runners import ConcurrentTaskRunner
from prefect.deployments import Deployment
from prefect.infrastructure import LocalFileSystem, Secret
from prefect.orion.schemas.schedules import CronSchedule
from prefect.blocks.system import Secret as PrefectSecret

# Define the tasks
@task(retries=2, name="Extract Claims Data")
def extract_claims():
    logger = get_run_logger()
    logger.info("Extracting claims data...")
    # Placeholder for actual data extraction logic
    return "claims_data"

@task(retries=2, name="Extract Providers Data")
def extract_providers():
    logger = get_run_logger()
    logger.info("Extracting providers data...")
    # Placeholder for actual data extraction logic
    return "providers_data"

@task(retries=2, name="Transform and Join Data")
def transform_join(claims_data, providers_data):
    logger = get_run_logger()
    logger.info("Transforming and joining data...")
    # Placeholder for actual data transformation and joining logic
    return "transformed_data"

@task(retries=2, name="Load Data to Warehouse")
def load_warehouse(transformed_data):
    logger = get_run_logger()
    logger.info("Loading data to warehouse...")
    # Placeholder for actual data loading logic
    data_warehouse = PrefectSecret.load("data_warehouse")
    # Use data_warehouse to load data
    return "data_loaded"

@task(retries=2, name="Refresh BI Tools")
def refresh_bi(transformed_data):
    logger = get_run_logger()
    logger.info("Refreshing BI tools...")
    # Placeholder for actual BI tool refresh logic
    power_bi = PrefectSecret.load("power_bi")
    tableau = PrefectSecret.load("tableau")
    # Use power_bi and tableau to refresh BI tools
    return "bi_refreshed"

# Define the flow
@flow(name="extract_claims_pipeline", task_runner=ConcurrentTaskRunner)
def extract_claims_pipeline():
    logger = get_run_logger()
    logger.info("Starting extract_claims_pipeline...")

    claims_data = extract_claims()
    providers_data = extract_providers()
    transformed_data = transform_join(claims_data, providers_data)
    load_warehouse(transformed_data)
    refresh_bi(transformed_data)

# Define the deployment
deployment = Deployment.build_from_flow(
    flow=extract_claims_pipeline,
    name="extract_claims_pipeline_deployment",
    work_pool_name="default-agent-pool",
    schedule=CronSchedule(cron="0 0 * * *", timezone="UTC", catchup=False),
)

if __name__ == "__main__":
    deployment.apply()
```
```python
# This is a placeholder for the actual deployment application
# To run the deployment, use the following command:
# prefect deployment apply extract_claims_pipeline_deployment.yaml