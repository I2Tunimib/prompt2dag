# Generated by Dagster Code Generator
# Date: 2024-06-28
# Pipeline: RunELT_Alert
# Description: Comprehensive Pipeline Description
# Executor: in_process_executor
# Resources: snowflake_conn, slack_api

from dagster import (
    op,
    job,
    In,
    Out,
    RetryPolicy,
    ConfigurableResource,
    ResourceDefinition,
    ScheduleDefinition,
    DefaultScheduleStatus,
    Definitions,
    fs_io_manager,
    InProcessExecutor,
)
from typing import Any


class SnowflakeResource(ConfigurableResource):
    """Resource for connecting to Snowflake Data Warehouse."""

    account: str
    user: str
    password: str
    warehouse: str
    database: str
    schema: str

    def execute_ctas(self, query: str) -> None:
        """Execute a CTAS (Create Table As Select) statement.

        In a production setting this would run the query via a Snowflake connector.
        """
        # Placeholder implementation – replace with actual Snowflake client logic.
        print(f"[Snowflake] Executing CTAS query: {query}")


class SlackResource(ConfigurableResource):
    """Resource for sending messages via Slack."""

    webhook_url: str

    def send_message(self, text: str) -> None:
        """Send a message to a Slack channel using the configured webhook."""
        # Placeholder implementation – replace with actual HTTP request to Slack webhook.
        print(f"[Slack] Sending message: {text}")


@op(
    name="create_analytics_table",
    description="Create Analytics Table via CTAS",
    required_resource_keys={"snowflake_conn"},
    out=Out(str),
)
def create_analytics_table(context) -> str:
    """Create an analytics table in Snowflake using a CTAS statement.

    Returns:
        The name of the newly created table.
    """
    table_name = "ANALYTICS_TABLE"
    ctas_query = f"""
        CREATE OR REPLACE TABLE {table_name} AS
        SELECT *
        FROM SOURCE_TABLE
        WHERE EVENT_DATE = CURRENT_DATE()
    """
    context.resources.snowflake_conn.execute_ctas(ctas_query)
    context.log.info(f"Analytics table `{table_name}` created successfully.")
    return table_name


@op(
    name="slack_failure_notifier",
    description="Slack Failure Notifier",
    required_resource_keys={"slack_api"},
    retry_policy=RetryPolicy(max_retries=3, delay=5),
    ins={"upstream_result": In(str, description="Result from the upstream CTAS op")},
    out=Out(None),
)
def slack_failure_notifier(context, upstream_result: str) -> None:
    """Notify a Slack channel if the upstream CTAS operation fails.

    The retry policy ensures up to three attempts with a 5‑second delay between tries.
    """
    # In a real implementation you would inspect the upstream result or context for failure.
    # Here we simply send a notification assuming the upstream op succeeded.
    message = f":warning: The analytics table `{upstream_result}` was created, but please verify its contents."
    context.resources.slack_api.send_message(message)
    context.log.info("Slack notification sent.")


@job(
    name="runelt_alert",
    description="Comprehensive Pipeline Description",
    resource_defs={
        "snowflake_conn": SnowflakeResource(),
        "slack_api": SlackResource(),
        "io_manager": fs_io_manager,
    },
    executor_def=InProcessExecutor(),
)
def runelt_alert():
    """Dagster job that creates an analytics table and notifies Slack on completion."""
    analytics_table = create_analytics_table()
    slack_failure_notifier(analytics_table)


daily_schedule = ScheduleDefinition(
    job=runelt_alert,
    cron_schedule="@daily",  # equivalent to "0 0 * * *"
    execution_timezone="UTC",
    default_status=DefaultScheduleStatus.RUNNING,
    description="Daily execution of the RunELT_Alert pipeline.",
)


defs = Definitions(
    jobs=[runelt_alert],
    schedules=[daily_schedule],
    resources={
        "snowflake_conn": SnowflakeResource(),
        "slack_api": SlackResource(),
        "io_manager": fs_io_manager,
    },
)