# Generated by Dagster code generator
# Date: 2024-06-28
# Description: regulatory_report_router pipeline implementation

from typing import List, Dict, Any

import pandas as pd
from dagster import (
    op,
    job,
    In,
    Out,
    Output,
    RetryPolicy,
    ResourceDefinition,
    fs_io_manager,
    ConfigurableResource,
    InitResourceContext,
    ScheduleDefinition,
    DefaultScheduleStatus,
    multiprocess_executor,
    Definitions,
)


# ----------------------------------------------------------------------
# Resource definitions
# ----------------------------------------------------------------------


class FatcaAPIResource(ConfigurableResource):
    """Placeholder resource for interacting with the FATCA regulatory system."""

    api_key: str

    def submit_report(self, report_data: Any) -> str:
        # In a real implementation, this would make an HTTP request to the FATCA API.
        # Here we just simulate a successful submission.
        return f"fatca_report_{hash(str(report_data)) % 10000}"


class IRSAPIResource(ConfigurableResource):
    """Placeholder resource for interacting with the IRS regulatory system."""

    api_key: str

    def submit_report(self, report_data: Any) -> str:
        # Simulate IRS report submission.
        return f"irs_report_{hash(str(report_data)) % 10000}"


class SecureArchiveStorageResource(ConfigurableResource):
    """Placeholder resource for storing reports in a secure S3 bucket."""

    bucket_name: str
    aws_access_key_id: str
    aws_secret_access_key: str

    def store_report(self, report_name: str, data: Any) -> str:
        # Simulate storing the report and returning a storage URI.
        return f"s3://{self.bucket_name}/{report_name}.json"


# ----------------------------------------------------------------------
# Ops
# ----------------------------------------------------------------------


@op(
    name="extract_transaction_csv",
    description="Read transaction data from a CSV file on the local filesystem.",
    out=Out(pandas.DataFrame),
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"local_filesystem_csv"},
)
def extract_transaction_csv(context) -> pd.DataFrame:
    """Load the CSV file containing financial transactions."""
    csv_path = context.op_config.get("csv_path", "data/transactions.csv")
    context.log.info(f"Reading transaction CSV from {csv_path}")
    df = pd.read_csv(csv_path)
    context.log.debug(f"Loaded {len(df)} transaction rows")
    return df


@op(
    name="determine_account_routing",
    description="Split transactions into FATCA (international) and IRS (domestic) streams.",
    ins={"transactions": In(pandas.DataFrame)},
    out={"fatca": Out(List[Dict]), "irs": Out(List[Dict])},
    retry_policy=RetryPolicy(max_retries=2),
)
def determine_account_routing(context, transactions: pd.DataFrame):
    """Route each transaction based on the account type."""
    fatca_records: List[Dict] = []
    irs_records: List[Dict] = []

    for _, row in transactions.iterrows():
        record = row.to_dict()
        if record.get("account_type") == "international":
            fatca_records.append(record)
        else:
            irs_records.append(record)

    context.log.info(
        f"Routing complete: {len(fatca_records)} FATCA, {len(irs_records)} IRS records"
    )
    yield Output(value=fatca_records, output_name="fatca")
    yield Output(value=irs_records, output_name="irs")


@op(
    name="generate_fatca_report",
    description="Generate a FATCA report from international transactions.",
    ins={"fatca_transactions": In(List[Dict])},
    out=Out(dict),
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"fatca_api"},
)
def generate_fatca_report(context, fatca_transactions: List[Dict]) -> Dict:
    """Create a FATCA report and submit it via the FATCA API."""
    if not fatca_transactions:
        context.log.warning("No FATCA transactions to process.")
        return {}

    # Placeholder aggregation logic
    total_amount = sum(t.get("amount", 0) for t in fatca_transactions)
    report = {
        "record_count": len(fatca_transactions),
        "total_amount": total_amount,
        "currency": "USD",
    }

    # Submit using the resource
    submission_id = context.resources.fatca_api.submit_report(report)
    context.log.info(f"FATCA report submitted, id={submission_id}")
    report["submission_id"] = submission_id
    return report


@op(
    name="generate_irs_report",
    description="Generate an IRS report from domestic transactions.",
    ins={"irs_transactions": In(List[Dict])},
    out=Out(dict),
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"irs_api"},
)
def generate_irs_report(context, irs_transactions: List[Dict]) -> Dict:
    """Create an IRS report and submit it via the IRS API."""
    if not irs_transactions:
        context.log.warning("No IRS transactions to process.")
        return {}

    total_amount = sum(t.get("amount", 0) for t in irs_transactions)
    report = {
        "record_count": len(irs_transactions),
        "total_amount": total_amount,
        "currency": "USD",
    }

    submission_id = context.resources.irs_api.submit_report(report)
    context.log.info(f"IRS report submitted, id={submission_id}")
    report["submission_id"] = submission_id
    return report


@op(
    name="archive_regulatory_reports",
    description="Archive both FATCA and IRS reports to secure storage.",
    ins={
        "fatca_report": In(dict),
        "irs_report": In(dict),
    },
    out=Out(str),
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"secure_archive_storage"},
)
def archive_regulatory_reports(context, fatca_report: Dict, irs_report: Dict) -> str:
    """Store the generated reports in a secure S3 bucket."""
    storage = context.resources.secure_archive_storage
    archive_paths = []

    if fatca_report:
        path = storage.store_report("fatca_report", fatca_report)
        archive_paths.append(path)
        context.log.info(f"Archived FATCA report to {path}")

    if irs_report:
        path = storage.store_report("irs_report", irs_report)
        archive_paths.append(path)
        context.log.info(f"Archived IRS report to {path}")

    return ", ".join(archive_paths)


# ----------------------------------------------------------------------
# Job definition
# ----------------------------------------------------------------------


@job(
    name="regulatory_report_router",
    description=(
        "This regulatory reporting pipeline processes financial transaction data and routes it "
        "to appropriate regulatory systems based on account type, following a branchâ€‘merge pattern. "
        "It extracts CSV data, branches processing for international (FATCA) and domestic (IRS) accounts, "
        "runs parallel reporting workflows, and merges results for archival."
    ),
    executor_def=multiprocess_executor,
    resource_defs={
        "local_filesystem_csv": fs_io_manager,
        "fatca_api": FatcaAPIResource,
        "irs_api": IRSAPIResource,
        "secure_archive_storage": SecureArchiveStorageResource,
    },
    config={
        "ops": {
            "extract_transaction_csv": {
                "config": {"csv_path": "data/transactions.csv"}
            }
        }
    },
)
def regulatory_report_router():
    # Extraction
    transactions = extract_transaction_csv()

    # Routing (branch)
    routing = determine_account_routing(transactions)

    # Parallel report generation
    fatca_report = generate_fatca_report(routing.fatca)
    irs_report = generate_irs_report(routing.irs)

    # Archival (merge)
    archive_regulatory_reports(fatca_report, irs_report)


# ----------------------------------------------------------------------
# Schedule definition
# ----------------------------------------------------------------------


daily_schedule = ScheduleDefinition(
    job=regulatory_report_router,
    cron_schedule="@daily",
    timezone="UTC",
    default_status=DefaultScheduleStatus.RUNNING,
    execution_timezone="UTC",
    description="Daily execution of the regulatory_report_router job.",
    # Dagster's schedule does not have a direct `catchup` flag; it is controlled via `default_status`.
    # Setting default_status to RUNNING ensures the schedule runs forward without backfilling.
)


# ----------------------------------------------------------------------
# Definitions (for Dagster UI / CLI)
# ----------------------------------------------------------------------


defs = Definitions(
    jobs=[regulatory_report_router],
    schedules=[daily_schedule],
    resources={
        "fatca_api": FatcaAPIResource.configure_at_launch(),
        "irs_api": IRSAPIResource.configure_at_launch(),
        "secure_archive_storage": SecureArchiveStorageResource.configure_at_launch(),
    },
)