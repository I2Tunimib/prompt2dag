{
  "generation_timestamp": "2025-12-01T09:04:45.805154",
  "pipeline_name": "regulatory_report_router",
  "orchestrator": "dagster",
  "detected_pattern": "fanout_fanin",
  "task_count": 5,
  "strategies": {
    "template": {
      "strategy": "template",
      "orchestrator": "dagster",
      "success": false,
      "output_path": null,
      "generation_time_ms": 78.85122299194336,
      "token_usage": {},
      "warnings": [],
      "errors": [
        "'pattern_analysis' is undefined"
      ],
      "metadata": {}
    },
    "llm": {
      "strategy": "llm",
      "orchestrator": "dagster",
      "success": true,
      "output_path": "/Users/abubakarialidu/Desktop/Prompt2DAG/New_Experiments_2/outputs/comprehensive_batch_all/synthetic-generator-v2__synthetic_branch_merge_03_regulatory_report_router.py_description/std-deepinfra-gpt-oss-120b__reason-deepinfra-Kimi-K2-Thinking/comprehensive_20251201_085717/2_prompt2dag/pipeline_20251201_085854/step3_generated/dagster/dagster/llm/regulatory_report_router_llm.py",
      "generation_time_ms": 12852.667093276978,
      "token_usage": {
        "input_tokens": 731,
        "output_tokens": 2322
      },
      "warnings": [],
      "errors": [],
      "metadata": {
        "pattern": "fanout_fanin",
        "llm_model": "openai/gpt-oss-120b",
        "task_count": 5
      }
    },
    "hybrid": {
      "strategy": "hybrid",
      "orchestrator": "dagster",
      "success": true,
      "output_path": "/Users/abubakarialidu/Desktop/Prompt2DAG/New_Experiments_2/outputs/comprehensive_batch_all/synthetic-generator-v2__synthetic_branch_merge_03_regulatory_report_router.py_description/std-deepinfra-gpt-oss-120b__reason-deepinfra-Kimi-K2-Thinking/comprehensive_20251201_085717/2_prompt2dag/pipeline_20251201_085854/step3_generated/dagster/dagster/hybrid/regulatory_report_router_hybrid.py",
      "generation_time_ms": 12816.738843917847,
      "token_usage": {
        "input_tokens": 896,
        "output_tokens": 2880
      },
      "warnings": [],
      "errors": [],
      "metadata": {
        "pattern": "fanout_fanin",
        "task_snippets_count": 5,
        "llm_model": "openai/gpt-oss-120b",
        "task_count": 5
      }
    }
  },
  "summary": {
    "total_strategies": 3,
    "successful": 2,
    "failed": 1,
    "fastest_ms": 12816.738843917847,
    "total_tokens": 6829
  }
}