# Generated by Airflow DAG generator on 2024-06-13 12:00:00 UTC
"""
DAG: start_backup_process_pipeline
Description: No description provided.
Pattern: fanout_fanin
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.utils.task_group import TaskGroup
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.utils.email import send_email
from airflow.models import Variable
import logging


def _failure_callback(context):
    """Send email on task failure."""
    dag_id = context.get('dag').dag_id
    task_id = context.get('task_instance').task_id
    execution_date = context.get('execution_date')
    log_url = context.get('task_instance').log_url

    subject = f"[Airflow] DAG {dag_id} - Task {task_id} Failed"
    html_content = f"""
    <p>Task <strong>{task_id}</strong> in DAG <strong>{dag_id}</strong> failed.</p>
    <p>Execution date: {execution_date}</p>
    <p>Log URL: <a href="{log_url}">{log_url}</a></p>
    """
    # Email address can be stored in Airflow Variable or connection
    recipients = Variable.get("alert_email", default_var="airflow@example.com")
    send_email(to=recipients, subject=subject, html_content=html_content)


default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
    "on_failure_callback": _failure_callback,
}


with DAG(
    dag_id="start_backup_process_pipeline",
    description="No description provided.",
    schedule=None,  # Disabled schedule; can be enabled by setting a cron expression
    start_date=datetime(2023, 1, 1),
    catchup=False,
    default_args=default_args,
    tags=["fanout_fanin", "backup"],
    is_paused_upon_creation=True,
    render_template_as_native_obj=True,
) as dag:

    # -------------------------------------------------------------------------
    # Python task: Start Backup Process
    # -------------------------------------------------------------------------
    def start_backup_process(**kwargs):
        """Initial step to trigger backup workflow."""
        logging.info("Starting backup process...")
        # Insert any initialization logic here
        return "started"

    start_backup = PythonOperator(
        task_id="start_backup_process",
        python_callable=start_backup_process,
        provide_context=True,
    )

    # -------------------------------------------------------------------------
    # Python task: Determine Backup Strategy
    # -------------------------------------------------------------------------
    def determine_backup_strategy(**kwargs):
        """Decide whether to run a full or incremental backup."""
        logging.info("Determining backup strategy...")
        # Example logic: choose based on a variable or external condition
        strategy = Variable.get("backup_strategy", default_var="full")
        logging.info(f"Selected backup strategy: {strategy}")
        # Push XCom for downstream tasks if needed
        kwargs["ti"].xcom_push(key="strategy", value=strategy)
        return strategy

    determine_strategy = PythonOperator(
        task_id="determine_backup_strategy",
        python_callable=determine_backup_strategy,
        provide_context=True,
    )

    # -------------------------------------------------------------------------
    # Bash task: Perform Full Backup
    # -------------------------------------------------------------------------
    perform_full = BashOperator(
        task_id="perform_full_backup",
        bash_command="echo 'Performing full backup...'; sleep 10; echo 'Full backup completed.'",
        retries=2,
        retry_delay=timedelta(minutes=5),
    )

    # -------------------------------------------------------------------------
    # Bash task: Perform Incremental Backup
    # -------------------------------------------------------------------------
    perform_incremental = BashOperator(
        task_id="perform_incremental_backup",
        bash_command="echo 'Performing incremental backup...'; sleep 5; echo 'Incremental backup completed.'",
        retries=2,
        retry_delay=timedelta(minutes=5),
    )

    # -------------------------------------------------------------------------
    # Bash task: Validate Backup Integrity
    # -------------------------------------------------------------------------
    validate_integrity = BashOperator(
        task_id="validate_backup_integrity",
        bash_command="echo 'Validating backup integrity...'; sleep 3; echo 'Backup integrity validated.'",
        retries=2,
        retry_delay=timedelta(minutes=5),
    )

    # -------------------------------------------------------------------------
    # Python task: Finalize Backup Workflow
    # -------------------------------------------------------------------------
    def finalize_backup_workflow(**kwargs):
        """Wrap up the backup process, e.g., cleanup or notifications."""
        logging.info("Finalizing backup workflow...")
        # Example: retrieve strategy from XCom
        strategy = kwargs["ti"].xcom_pull(key="strategy", task_ids="determine_backup_strategy")
        logging.info(f"Backup strategy used: {strategy}")
        # Insert any finalization logic here
        return "finalized"

    finalize_backup = PythonOperator(
        task_id="finalize_backup_workflow",
        python_callable=finalize_backup_workflow,
        provide_context=True,
    )

    # -------------------------------------------------------------------------
    # Define task dependencies (fanout -> fanin)
    # -------------------------------------------------------------------------
    start_backup >> determine_strategy

    # Fan‑out: both backup types run after strategy determination
    determine_strategy >> [perform_full, perform_incremental]

    # Fan‑in: validation waits for both backup executions
    [perform_full, perform_incremental] >> validate_integrity

    # Final step
    validate_integrity >> finalize_backup

    # End of DAG definition.