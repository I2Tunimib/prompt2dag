# Generated by Prefect pipeline generator on 2024-06-12 10:45:00 UTC
# Pipeline: start_backup_process_pipeline
# Description: No description provided.
# Pattern: fanout_fanin
# Prefect version: 2.14.0

from __future__ import annotations

import subprocess
from datetime import datetime
from typing import Any

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.orion.schemas.schedules import CronSchedule


@task(retries=2, retry_delay_seconds=60, description="Initialize the backup process.")
def start_backup_process() -> dict[str, Any]:
    """
    Starts the backup process by performing any necessary initialization steps.

    Returns
    -------
    dict
        Contextual information about the started process (e.g., start timestamp).
    """
    logger = get_run_logger()
    logger.info("Starting backup process...")
    try:
        # Example placeholder command; replace with real initialization logic.
        subprocess.run(["echo", "Backup process initialized"], check=True)
    except subprocess.CalledProcessError as exc:
        logger.error(f"Failed to start backup process: {exc}")
        raise
    return {"started_at": datetime.utcnow().isoformat()}


@task(retries=2, retry_delay_seconds=60, description="Determine which backup strategy to use.")
def date_check_task(start_info: dict[str, Any]) -> str:
    """
    Determines the backup strategy based on the current date or other criteria.

    Parameters
    ----------
    start_info : dict
        Information returned from the start_backup_process task.

    Returns
    -------
    str
        The chosen backup strategy ('full' or 'incremental').
    """
    logger = get_run_logger()
    logger.info("Evaluating backup strategy...")
    # Placeholder logic: use full backup on the first day of the month, otherwise incremental.
    today = datetime.utcnow()
    strategy = "full" if today.day == 1 else "incremental"
    logger.info(f"Selected backup strategy: {strategy}")
    return strategy


@task(retries=2, retry_delay_seconds=60, description="Perform a full backup of the system.")
def full_backup_task(strategy: str) -> str:
    """
    Executes a full backup if the strategy dictates it.

    Parameters
    ----------
    strategy : str
        The backup strategy selected by ``date_check_task``.

    Returns
    -------
    str
        Path to the full backup artifact.
    """
    logger = get_run_logger()
    if strategy != "full":
        logger.info("Skipping full backup (strategy is not 'full').")
        return ""
    logger.info("Performing full backup...")
    try:
        # Replace with the actual full backup command.
        subprocess.run(["echo", "Full backup completed"], check=True)
    except subprocess.CalledProcessError as exc:
        logger.error(f"Full backup failed: {exc}")
        raise
    backup_path = "/backups/full/backup_full.tar.gz"
    logger.info(f"Full backup stored at {backup_path}")
    return backup_path


@task(retries=2, retry_delay_seconds=60, description="Perform an incremental backup of the system.")
def incremental_backup_task(strategy: str) -> str:
    """
    Executes an incremental backup if the strategy dictates it.

    Parameters
    ----------
    strategy : str
        The backup strategy selected by ``date_check_task``.

    Returns
    -------
    str
        Path to the incremental backup artifact.
    """
    logger = get_run_logger()
    if strategy != "incremental":
        logger.info("Skipping incremental backup (strategy is not 'incremental').")
        return ""
    logger.info("Performing incremental backup...")
    try:
        # Replace with the actual incremental backup command.
        subprocess.run(["echo", "Incremental backup completed"], check=True)
    except subprocess.CalledProcessError as exc:
        logger.error(f"Incremental backup failed: {exc}")
        raise
    backup_path = "/backups/incremental/backup_incremental.tar.gz"
    logger.info(f"Incremental backup stored at {backup_path}")
    return backup_path


@task(retries=2, retry_delay_seconds=60, description="Verify the integrity of backup artifacts.")
def verify_backup_task(full_backup_path: str, incremental_backup_path: str) -> bool:
    """
    Verifies that the backup artifacts are complete and not corrupted.

    Parameters
    ----------
    full_backup_path : str
        Path to the full backup artifact (may be empty if not performed).
    incremental_backup_path : str
        Path to the incremental backup artifact (may be empty if not performed).

    Returns
    -------
    bool
        ``True`` if verification succeeds, otherwise raises an exception.
    """
    logger = get_run_logger()
    logger.info("Starting backup verification...")
    try:
        # Placeholder verification logic.
        if full_backup_path:
            subprocess.run(["echo", f"Verifying {full_backup_path}"], check=True)
        if incremental_backup_path:
            subprocess.run(["echo", f"Verifying {incremental_backup_path}"], check=True)
    except subprocess.CalledProcessError as exc:
        logger.error(f"Backup verification failed: {exc}")
        raise
    logger.info("Backup verification completed successfully.")
    return True


@task(retries=2, retry_delay_seconds=60, description="Finalize the backup workflow.")
def backup_complete(verification_passed: bool) -> None:
    """
    Marks the backup workflow as complete after successful verification.

    Parameters
    ----------
    verification_passed : bool
        Result from ``verify_backup_task`` indicating successful verification.
    """
    logger = get_run_logger()
    if not verification_passed:
        logger.error("Backup verification did not pass; cannot complete workflow.")
        raise RuntimeError("Backup verification failed.")
    logger.info("Backup workflow completed successfully.")


@flow(
    name="start_backup_process_pipeline",
    task_runner=SequentialTaskRunner(),
    description="No description provided."
)
def start_backup_process_pipeline() -> None:
    """
    Orchestrates the full backup workflow using a fan‑out/fan‑in pattern.

    The flow executes the following steps:
    1. Initialize the backup process.
    2. Determine the backup strategy.
    3. Run the appropriate backup tasks (full and/or incremental).
    4. Verify the generated backup artifacts.
    5. Mark the workflow as complete.
    """
    logger = get_run_logger()
    logger.info("Pipeline execution started.")

    # Step 1: Start backup process
    start_info = start_backup_process()

    # Step 2: Determine backup strategy
    strategy = date_check_task(start_info)

    # Step 3: Perform backups (fan‑out)
    full_path = full_backup_task(strategy)
    incremental_path = incremental_backup_task(strategy)

    # Step 4: Verify backups (fan‑in)
    verification = verify_backup_task(full_path, incremental_path)

    # Step 5: Complete workflow
    backup_complete(verification)

    logger.info("Pipeline execution finished.")


# Deployment specification with daily schedule
DeploymentSpec(
    name="start_backup_process_pipeline_deployment",
    flow=start_backup_process_pipeline,
    schedule=CronSchedule(cron="0 0 * * *", timezone="UTC"),  # @daily at midnight UTC
    tags=["backup", "daily"],
    work_pool_name="default-agent-pool",
    description="Daily backup pipeline deployment."
)


if __name__ == "__main__":
    # Allows local execution for testing/debugging
    start_backup_process_pipeline()