# Generated by Prefect 2.x Code Generator
# Date: 2023-10-05
# Prefect Version: 2.14.0
# Flow Name: get_airvisual_data_hourly_pipeline
# Deployment Name: get_airvisual_data_hourly_pipeline_deployment
# Work Pool: default-agent-pool
# Task Runner: SequentialTaskRunner

from prefect import flow, task, get_run_logger
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem
from prefect.task_runners import SequentialTaskRunner
from prefect import flow, task
import requests
import pandas as pd
import psycopg2
from psycopg2 import sql

# Task: Fetch AirVisual Data
@task(retries=2, name="Fetch AirVisual Data")
def get_airvisual_data_hourly():
    logger = get_run_logger()
    airvisual_api_key = Secret.load("airvisual_api").get()
    url = f"https://api.airvisual.com/v2/nearest_city?key={airvisual_api_key}"
    response = requests.get(url)
    response.raise_for_status()
    data = response.json()
    logger.info("Fetched AirVisual data successfully")
    return data

# Task: Read and Validate AirVisual Data
@task(retries=2, name="Read and Validate AirVisual Data")
def read_data_airvisual(data):
    logger = get_run_logger()
    df = pd.DataFrame(data['data'])
    if df.empty:
        logger.warning("No data to process")
        return None
    logger.info("Read and validated AirVisual data successfully")
    return df

# Task: Load AirVisual Data to PostgreSQL
@task(retries=2, name="Load AirVisual Data to PostgreSQL")
def load_data_airvisual_to_postgresql(df):
    logger = get_run_logger()
    postgresql_db = Secret.load("postgresql_db").get()
    conn = psycopg2.connect(postgresql_db)
    cursor = conn.cursor()
    table_name = "airvisual_data"
    columns = ["city", "state", "country", "location", "current_weather", "pollution"]
    insert_query = sql.SQL("INSERT INTO {} ({}) VALUES ({})").format(
        sql.Identifier(table_name),
        sql.SQL(", ").join(map(sql.Identifier, columns)),
        sql.SQL(", ").join(sql.Placeholder() * len(columns))
    )
    for _, row in df.iterrows():
        cursor.execute(insert_query, row.to_list())
    conn.commit()
    cursor.close()
    conn.close()
    logger.info("Loaded AirVisual data to PostgreSQL successfully")

# Flow: get_airvisual_data_hourly_pipeline
@flow(name="get_airvisual_data_hourly_pipeline", task_runner=SequentialTaskRunner())
def get_airvisual_data_hourly_pipeline():
    logger = get_run_logger()
    logger.info("Starting get_airvisual_data_hourly_pipeline")

    # Fetch AirVisual Data
    data = get_airvisual_data_hourly()

    # Read and Validate AirVisual Data
    df = read_data_airvisual(data)

    # Load AirVisual Data to PostgreSQL
    if df is not None:
        load_data_airvisual_to_postgresql(df)

    logger.info("Completed get_airvisual_data_hourly_pipeline")

if __name__ == "__main__":
    get_airvisual_data_hourly_pipeline()