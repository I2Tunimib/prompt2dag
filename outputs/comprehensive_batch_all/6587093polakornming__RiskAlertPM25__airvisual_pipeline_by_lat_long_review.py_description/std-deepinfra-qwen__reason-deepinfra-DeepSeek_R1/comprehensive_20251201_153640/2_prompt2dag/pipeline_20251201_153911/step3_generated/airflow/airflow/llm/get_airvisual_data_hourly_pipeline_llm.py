# Generated by Airflow DAG Code Generator
# Date: 2023-10-05
# Author: Airflow Expert
# Description: Airflow DAG for fetching, reading, and loading AirVisual data to PostgreSQL

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.http.operators.http import SimpleHttpOperator
from airflow.providers.docker.operators.docker import DockerOperator
from airflow.exceptions import AirflowException
import requests
import pandas as pd
from datetime import datetime, timedelta
import os

# Default arguments for the DAG
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

# Define the DAG
with DAG(
    dag_id='get_airvisual_data_hourly_pipeline',
    default_args=default_args,
    schedule_interval=None,
    start_date=days_ago(1),
    catchup=False,
    tags=['airvisual', 'data_pipeline'],
) as dag:

    # Task: Fetch AirVisual Data
    def fetch_airvisual_data(**kwargs):
        try:
            response = requests.get('https://api.airvisual.com/v2/cities', params={'key': 'your_api_key'})
            response.raise_for_status()
            data = response.json()
            with open('/tmp/airvisual_data.json', 'w') as f:
                f.write(data)
            return data
        except requests.exceptions.RequestException as e:
            raise AirflowException(f"Error fetching AirVisual data: {e}")

    get_airvisual_data_hourly = PythonOperator(
        task_id='get_airvisual_data_hourly',
        python_callable=fetch_airvisual_data,
        provide_context=True,
        retries=2,
    )

    # Task: Read and Validate AirVisual Data
    def read_and_validate_airvisual_data(**kwargs):
        try:
            with open('/tmp/airvisual_data.json', 'r') as f:
                data = f.read()
            df = pd.read_json(data)
            if df.empty:
                raise ValueError("Data is empty")
            return df
        except Exception as e:
            raise AirflowException(f"Error reading and validating AirVisual data: {e}")

    read_data_airvisual = PythonOperator(
        task_id='read_data_airvisual',
        python_callable=read_and_validate_airvisual_data,
        provide_context=True,
        retries=2,
    )

    # Task: Load AirVisual Data to PostgreSQL
    def load_airvisual_data_to_postgresql(**kwargs):
        try:
            df = kwargs['ti'].xcom_pull(task_ids='read_data_airvisual')
            df.to_sql('airvisual_data', con='postgresql://user:password@host:port/dbname', if_exists='append', index=False)
        except Exception as e:
            raise AirflowException(f"Error loading AirVisual data to PostgreSQL: {e}")

    load_data_airvisual_to_postgresql = PythonOperator(
        task_id='load_data_airvisual_to_postgresql',
        python_callable=load_airvisual_data_to_postgresql,
        provide_context=True,
        retries=2,
    )

    # Set task dependencies
    get_airvisual_data_hourly >> read_data_airvisual >> load_data_airvisual_to_postgresql