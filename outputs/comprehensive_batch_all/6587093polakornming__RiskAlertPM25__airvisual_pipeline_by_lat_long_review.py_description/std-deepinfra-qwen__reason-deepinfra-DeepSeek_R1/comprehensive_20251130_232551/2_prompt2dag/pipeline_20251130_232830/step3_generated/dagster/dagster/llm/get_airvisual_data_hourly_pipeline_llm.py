# Generated by Dagster Code Generator
# Generation Metadata:
# - Job Name: get_airvisual_data_hourly_pipeline
# - Description: No description provided.
# - Executor Type: in_process_executor
# - IO Manager: fs_io_manager
# - Dagster Version: 1.5.0
# - Use Assets: False
# - Required Resources: postgres_conn, local_filesystem

from dagster import job, op, Out, In, RetryPolicy, resource, fs_io_manager, in_process_executor
from dagster_postgres import postgres_resource

@resource
def airvisual_api(context):
    # Placeholder for AirVisual API resource
    pass

@resource
def postgres_conn(context):
    # Placeholder for PostgreSQL connection resource
    pass

@resource
def local_filesystem(context):
    # Placeholder for local filesystem resource
    pass

@op(
    name="get_airvisual_data_hourly",
    description="Fetch AirVisual Data",
    out={"airvisual_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"airvisual_api", "local_filesystem"}
)
def get_airvisual_data_hourly(context):
    """
    Fetches data from the AirVisual API and saves it to the local filesystem.
    """
    # Fetch data from AirVisual API
    airvisual_data = context.resources.airvisual_api.fetch_data()
    
    # Save data to local filesystem
    context.resources.local_filesystem.save_data(airvisual_data)
    
    return airvisual_data

@op(
    name="read_data_airvisual",
    description="Read and Validate AirVisual Data",
    ins={"airvisual_data": In()},
    out={"validated_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"local_filesystem"}
)
def read_data_airvisual(context, airvisual_data):
    """
    Reads and validates the AirVisual data from the local filesystem.
    """
    # Read data from local filesystem
    data = context.resources.local_filesystem.read_data(airvisual_data)
    
    # Validate data
    validated_data = validate_data(data)
    
    return validated_data

@op(
    name="load_data_airvisual_to_postgresql",
    description="Load AirVisual Data to PostgreSQL",
    ins={"validated_data": In()},
    out={"load_status": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"postgresql_db"}
)
def load_data_airvisual_to_postgresql(context, validated_data):
    """
    Loads the validated AirVisual data into the PostgreSQL database.
    """
    # Load data into PostgreSQL
    load_status = context.resources.postgresql_db.load_data(validated_data)
    
    return load_status

@job(
    name="get_airvisual_data_hourly_pipeline",
    description="No description provided.",
    executor_def=in_process_executor,
    resource_defs={
        "airvisual_api": airvisual_api,
        "postgresql_db": postgres_resource.configured({"config": {"host": "localhost", "user": "user", "password": "password", "dbname": "database"}}),
        "local_filesystem": fs_io_manager,
        "postgres_conn": postgres_conn
    }
)
def get_airvisual_data_hourly_pipeline():
    """
    Dagster job to fetch, read, and load AirVisual data into PostgreSQL.
    """
    airvisual_data = get_airvisual_data_hourly()
    validated_data = read_data_airvisual(airvisual_data)
    load_data_airvisual_to_postgresql(validated_data)

def validate_data(data):
    """
    Placeholder function to validate the AirVisual data.
    """
    # Implement data validation logic here
    return data