metadata:
  target_orchestrator: airflow
  generated_at: 2025-12-02 01:46:57.258553
  source_analysis_file: 
    Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_fan_out_only_01_data_replication_to_environments.py_description.txt
  pipeline_name: dump_prod_csv_pipeline
  pipeline_description: No description provided.
  orchestrator_specific: {}
schedule:
  enabled: true
  schedule_expression: '@daily'
  start_date: '2024-01-01T00:00:00Z'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: local_filesystem
    conn_type: fs
    description: Local Filesystem
    config:
      base_path: /tmp
      protocol: file
  - conn_id: prod_db
    conn_type: generic
    description: Production Database
    config:
      host: prod-db-host
      port: 5432
      database: prod_db
      schema: public
      login: PROD_DB_USERNAME
      password: PROD_DB_PASSWORD
  - conn_id: dev_db
    conn_type: generic
    description: Development Database
    config:
      host: dev-db-host
      port: 5432
      database: dev_db
      schema: public
      login: DEV_DB_USERNAME
      password: DEV_DB_PASSWORD
  - conn_id: staging_db
    conn_type: generic
    description: Staging Database
    config:
      host: staging-db-host
      port: 5432
      database: staging_db
      schema: public
      login: STAGING_DB_USERNAME
      password: STAGING_DB_PASSWORD
  - conn_id: qa_db
    conn_type: generic
    description: QA Database
    config:
      host: qa-db-host
      port: 5432
      database: qa_db
      schema: public
      login: QA_DB_USERNAME
      password: QA_DB_PASSWORD
tasks:
  - task_id: dump_prod_csv
    task_name: Dump Production CSV
    operator_class: BashOperator
    operator_module: airflow.operators.bash
    component_ref: dump_prod_csv
    config:
      bash_command:
        - bash
        - dump_script.sh
      retry_delay: timedelta(seconds=300)
    upstream_task_ids: []
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: copy_dev
    task_name: Copy to Development
    operator_class: BashOperator
    operator_module: airflow.operators.bash
    component_ref: copy_dev
    config:
      bash_command:
        - bash
        - load_dev_script.sh
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - dump_prod_csv
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: copy_staging
    task_name: Copy to Staging
    operator_class: BashOperator
    operator_module: airflow.operators.bash
    component_ref: copy_staging
    config:
      bash_command:
        - bash
        - load_staging_script.sh
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - dump_prod_csv
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: copy_qa
    task_name: Copy to QA
    operator_class: BashOperator
    operator_module: airflow.operators.bash
    component_ref: copy_qa
    config:
      bash_command:
        - bash
        - load_qa_script.sh
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - dump_prod_csv
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
