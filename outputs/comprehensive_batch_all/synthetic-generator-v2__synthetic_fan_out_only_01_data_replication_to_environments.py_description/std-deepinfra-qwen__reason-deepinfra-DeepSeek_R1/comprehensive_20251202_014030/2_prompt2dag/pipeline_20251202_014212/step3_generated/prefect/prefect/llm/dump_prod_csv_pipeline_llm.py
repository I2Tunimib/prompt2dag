# Generated by Prefect 2.x Code Generator
# Date: 2023-10-05
# Prefect Version: 2.14.0

import os
from prefect import flow, task, get_run_logger
from prefect.task_runners import ConcurrentTaskRunner
from prefect.deployments import Deployment
from prefect.filesystems import LocalFileSystem
from prefect.blocks.system import Secret
from prefect.infrastructure.docker import DockerContainer
from prefect.infrastructure.process import Process

# Load secrets
prod_db = Secret.load("prod_db")
dev_db = Secret.load("dev_db")
staging_db = Secret.load("staging_db")
qa_db = Secret.load("qa_db")

# Load local filesystem
local_filesystem = LocalFileSystem.load("local_filesystem")

@task(retries=2, name="Dump Production CSV")
def dump_prod_csv():
    logger = get_run_logger()
    logger.info("Dumping production CSV...")
    # Example command to dump CSV from production database
    command = f"pg_dump -U {prod_db.get()} -d prod_db -F c -f /path/to/prod_dump.csv"
    process = Process(command=command)
    process.run()
    logger.info("Production CSV dumped successfully.")

@task(retries=2, name="Copy to Development")
def copy_dev():
    logger = get_run_logger()
    logger.info("Copying to development...")
    # Example command to copy CSV to development database
    command = f"pg_restore -U {dev_db.get()} -d dev_db -F c /path/to/prod_dump.csv"
    process = Process(command=command)
    process.run()
    logger.info("Copied to development successfully.")

@task(retries=2, name="Copy to QA")
def copy_qa():
    logger = get_run_logger()
    logger.info("Copying to QA...")
    # Example command to copy CSV to QA database
    command = f"pg_restore -U {qa_db.get()} -d qa_db -F c /path/to/prod_dump.csv"
    process = Process(command=command)
    process.run()
    logger.info("Copied to QA successfully.")

@task(retries=2, name="Copy to Staging")
def copy_staging():
    logger = get_run_logger()
    logger.info("Copying to staging...")
    # Example command to copy CSV to staging database
    command = f"pg_restore -U {staging_db.get()} -d staging_db -F c /path/to/prod_dump.csv"
    process = Process(command=command)
    process.run()
    logger.info("Copied to staging successfully.")

@flow(name="dump_prod_csv_pipeline", task_runner=ConcurrentTaskRunner)
def dump_prod_csv_pipeline():
    logger = get_run_logger()
    logger.info("Starting dump_prod_csv_pipeline...")

    # Run dump_prod_csv task
    dump_prod_csv_result = dump_prod_csv()

    # Run copy tasks in parallel
    copy_dev.submit(dump_prod_csv_result)
    copy_qa.submit(dump_prod_csv_result)
    copy_staging.submit(dump_prod_csv_result)

    logger.info("dump_prod_csv_pipeline completed successfully.")

# Schedule the flow
if __name__ == "__main__":
    deployment = Deployment.build_from_flow(
        flow=dump_prod_csv_pipeline,
        name="dump_prod_csv_pipeline_deployment",
        work_pool_name="default-agent-pool",
        schedule={"interval": 86400, "timezone": "UTC", "catchup": False},
    )
    deployment.apply()