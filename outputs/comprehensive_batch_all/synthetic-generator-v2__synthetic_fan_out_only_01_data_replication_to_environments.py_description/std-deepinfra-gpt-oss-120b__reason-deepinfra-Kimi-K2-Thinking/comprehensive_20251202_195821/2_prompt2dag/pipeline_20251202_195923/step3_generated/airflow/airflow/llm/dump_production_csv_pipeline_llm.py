# Generated by Airflow DAG generator on 2024-06-28
"""
Airflow DAG: dump_production_csv_pipeline
Description: No description provided.
Pattern: fanout
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.utils.timezone import utc
from airflow.operators.bash import BashOperator
from airflow.utils.email import send_email
import logging

# ----------------------------------------------------------------------
# Default arguments applied to all tasks
# ----------------------------------------------------------------------
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
    "email_on_failure": False,
    "email_on_retry": False,
}


def _failure_callback(context):
    """
    Callback executed when a task fails.
    Sends a log entry and optionally an email notification.
    """
    dag_id = context.get("dag").dag_id
    task_id = context.get("task_instance").task_id
    execution_date = context.get("execution_date")
    log_msg = (
        f"Task failed: dag_id={dag_id}, task_id={task_id}, "
        f"execution_date={execution_date}"
    )
    logging.error(log_msg)

    # Example email notification (requires proper Airflow email config)
    # send_email(
    #     to=["alert@example.com"],
    #     subject=f"[Airflow] Task Failure: {task_id}",
    #     html_content=log_msg,
    # )


# ----------------------------------------------------------------------
# DAG definition
# ----------------------------------------------------------------------
with DAG(
    dag_id="dump_production_csv_pipeline",
    description="No description provided.",
    schedule="@daily",                     # Cron expression
    start_date=datetime(2024, 1, 1, tzinfo=utc),
    catchup=False,
    default_args=default_args,
    tags=["fanout"],
    is_paused_upon_creation=True,          # Disabled by default
) as dag:

    # ------------------------------------------------------------------
    # Task: Dump Production Database to CSV
    # ------------------------------------------------------------------
    dump_production_csv = BashOperator(
        task_id="dump_production_csv",
        bash_command=(
            "echo 'Dumping production DB to CSV...'; "
            "# Replace the following line with the actual dump command\n"
            "pg_dump -U {{ conn.prod_database.login }} -h {{ conn.prod_database.host }} "
            "-d {{ conn.prod_database.schema }} > /tmp/production_dump.csv"
        ),
        on_failure_callback=_failure_callback,
    )

    # ------------------------------------------------------------------
    # Task: Load CSV into Development Database
    # ------------------------------------------------------------------
    load_dev_database = BashOperator(
        task_id="load_dev_database",
        bash_command=(
            "echo 'Loading CSV into Development DB...'; "
            "# Replace with actual load command\n"
            "psql -U {{ conn.dev_database.login }} -h {{ conn.dev_database.host }} "
            "-d {{ conn.dev_database.schema }} -c \"\\copy my_table FROM '/tmp/production_dump.csv' CSV HEADER;\""
        ),
        on_failure_callback=_failure_callback,
    )

    # ------------------------------------------------------------------
    # Task: Load CSV into QA Database
    # ------------------------------------------------------------------
    load_qa_database = BashOperator(
        task_id="load_qa_database",
        bash_command=(
            "echo 'Loading CSV into QA DB...'; "
            "# Replace with actual load command\n"
            "psql -U {{ conn.qa_database.login }} -h {{ conn.qa_database.host }} "
            "-d {{ conn.qa_database.schema }} -c \"\\copy my_table FROM '/tmp/production_dump.csv' CSV HEADER;\""
        ),
        on_failure_callback=_failure_callback,
    )

    # ------------------------------------------------------------------
    # Task: Load CSV into Staging Database
    # ------------------------------------------------------------------
    load_staging_database = BashOperator(
        task_id="load_staging_database",
        bash_command=(
            "echo 'Loading CSV into Staging DB...'; "
            "# Replace with actual load command\n"
            "psql -U {{ conn.staging_database.login }} -h {{ conn.staging_database.host }} "
            "-d {{ conn.staging_database.schema }} -c \"\\copy my_table FROM '/tmp/production_dump.csv' CSV HEADER;\""
        ),
        on_failure_callback=_failure_callback,
    )

    # ------------------------------------------------------------------
    # Set task dependencies (fanout pattern)
    # ------------------------------------------------------------------
    dump_production_csv >> [load_dev_database, load_qa_database, load_staging_database]