# Generated by Prefect Pipeline Generator
# Date: 2024-06-13
# Prefect version: 2.14.0
# Pipeline: dump_production_csv_pipeline
# Description: Dumps production database to CSV and loads it into dev, qa, and staging databases.

import os
import subprocess
import tempfile
from pathlib import Path

from prefect import flow, task, get_run_logger
from prefect.task_runners import ConcurrentTaskRunner
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem
from prefect.exceptions import PrefectException


def _run_subprocess(command: list[str], env: dict | None = None) -> None:
    """
    Execute a subprocess command and raise an exception on failure.

    Args:
        command: List of command arguments.
        env: Optional environment variables.

    Raises:
        PrefectException: If the subprocess exits with a non-zero status.
    """
    logger = get_run_logger()
    logger.info("Running command: %s", " ".join(command))
    try:
        result = subprocess.run(
            command,
            check=True,
            capture_output=True,
            text=True,
            env=env,
        )
        logger.debug("Command stdout: %s", result.stdout)
        logger.debug("Command stderr: %s", result.stderr)
    except subprocess.CalledProcessError as exc:
        logger.error(
            "Command failed with return code %s. Stderr: %s",
            exc.returncode,
            exc.stderr,
        )
        raise PrefectException(f"Subprocess failed: {exc}") from exc


@task(retries=2, retry_delay_seconds=30)
def dump_production_csv(
    prod_secret_name: str = "prod_database",
    filesystem_block_name: str = "local_filesystem",
) -> Path:
    """
    Dump the production database to a CSV file stored on the local filesystem.

    Returns:
        Path to the generated CSV file.
    """
    logger = get_run_logger()
    # Retrieve secrets and filesystem block
    prod_secret = Secret.load(prod_secret_name)
    prod_conn_str = prod_secret.get()  # Expected to be a connection string

    fs_block = LocalFileSystem.load(filesystem_block_name)

    # Create a temporary directory via the filesystem block
    temp_dir = Path(fs_block.basepath) / "tmp_dump"
    temp_dir.mkdir(parents=True, exist_ok=True)

    csv_path = temp_dir / "production_dump.csv"

    # Example command: using pg_dump to CSV (adjust for actual DB)
    command = [
        "psql",
        prod_conn_str,
        "-c",
        f"COPY (SELECT * FROM some_table) TO STDOUT WITH CSV HEADER",
    ]

    # Write output directly to file
    with open(csv_path, "w", encoding="utf-8") as f:
        logger.info("Dumping production database to %s", csv_path)
        try:
            subprocess.run(
                command,
                check=True,
                stdout=f,
                stderr=subprocess.PIPE,
                text=True,
            )
        except subprocess.CalledProcessError as exc:
            logger.error(
                "Failed to dump production DB. Stderr: %s", exc.stderr.decode()
            )
            raise PrefectException(f"Dump failed: {exc}") from exc

    logger.info("Production dump completed: %s", csv_path)
    return csv_path


def _load_csv_into_database(csv_path: Path, secret_name: str) -> None:
    """
    Helper to load a CSV file into a target database.

    Args:
        csv_path: Path to the CSV file.
        secret_name: Name of the Prefect Secret block containing the DB connection string.
    """
    logger = get_run_logger()
    db_secret = Secret.load(secret_name)
    db_conn_str = db_secret.get()

    # Example command: using psql to copy CSV into a table (adjust for actual DB)
    command = [
        "psql",
        db_conn_str,
        "-c",
        f"COPY some_table FROM STDIN WITH CSV HEADER",
    ]

    logger.info("Loading CSV %s into database %s", csv_path, secret_name)
    with open(csv_path, "r", encoding="utf-8") as f:
        try:
            subprocess.run(
                command,
                check=True,
                stdin=f,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
        except subprocess.CalledProcessError as exc:
            logger.error(
                "Failed to load CSV into %s. Stderr: %s",
                secret_name,
                exc.stderr,
            )
            raise PrefectException(f"Load failed for {secret_name}: {exc}") from exc
    logger.info("Successfully loaded CSV into %s", secret_name)


@task(retries=2, retry_delay_seconds=30)
def load_dev_database(csv_path: Path, dev_secret_name: str = "dev_database") -> None:
    """
    Load the CSV dump into the development database.
    """
    _load_csv_into_database(csv_path, dev_secret_name)


@task(retries=2, retry_delay_seconds=30)
def load_qa_database(csv_path: Path, qa_secret_name: str = "qa_database") -> None:
    """
    Load the CSV dump into the QA database.
    """
    _load_csv_into_database(csv_path, qa_secret_name)


@task(retries=2, retry_delay_seconds=30)
def load_staging_database(csv_path: Path, staging_secret_name: str = "staging_database") -> None:
    """
    Load the CSV dump into the staging database.
    """
    _load_csv_into_database(csv_path, staging_secret_name)


@flow(
    name="dump_production_csv_pipeline",
    task_runner=ConcurrentTaskRunner(),
)
def dump_production_csv_pipeline() -> None:
    """
    Orchestrates dumping the production database to CSV and loading it into
    development, QA, and staging environments.
    """
    csv_path = dump_production_csv()
    # Fanâ€‘out: load into each environment concurrently after dump completes
    load_dev_database.submit(csv_path)
    load_qa_database.submit(csv_path)
    load_staging_database.submit(csv_path)


if __name__ == "__main__":
    # Running the flow locally for testing/debugging
    dump_production_csv_pipeline()