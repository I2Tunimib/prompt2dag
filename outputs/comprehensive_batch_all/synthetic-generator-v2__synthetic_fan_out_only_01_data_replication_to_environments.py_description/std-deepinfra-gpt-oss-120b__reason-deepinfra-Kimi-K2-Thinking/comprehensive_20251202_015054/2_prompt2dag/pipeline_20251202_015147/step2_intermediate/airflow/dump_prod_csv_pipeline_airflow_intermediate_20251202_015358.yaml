metadata:
  target_orchestrator: airflow
  generated_at: 2025-12-02 01:53:58.098631
  source_analysis_file: 
    Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_fan_out_only_01_data_replication_to_environments.py_description.txt
  pipeline_name: dump_prod_csv_pipeline
  pipeline_description: No description provided.
  orchestrator_specific: {}
schedule:
  enabled: false
  schedule_expression: '@daily'
  start_date: '2024-01-01T00:00:00'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: prod_db
    conn_type: generic
    description: Production Database
    config:
      base_path:
      base_url:
      host:
      port:
      protocol: jdbc
      database: production
      schema:
      bucket:
      queue_name:
  - conn_id: dev_db
    conn_type: generic
    description: Development Environment Database
    config:
      base_path:
      base_url:
      host:
      port:
      protocol: jdbc
      database: dev_db
      schema:
      bucket:
      queue_name:
  - conn_id: staging_db
    conn_type: generic
    description: Staging Environment Database
    config:
      base_path:
      base_url:
      host:
      port:
      protocol: jdbc
      database: staging_db
      schema:
      bucket:
      queue_name:
  - conn_id: qa_db
    conn_type: generic
    description: QA Environment Database
    config:
      base_path:
      base_url:
      host:
      port:
      protocol: jdbc
      database: qa_db
      schema:
      bucket:
      queue_name:
  - conn_id: local_tmp_fs
    conn_type: fs
    description: Local Temporary Filesystem
    config:
      base_path: /tmp
      base_url:
      host:
      port:
      protocol: file
      database:
      schema:
      bucket:
      queue_name:
tasks:
  - task_id: dump_prod_csv
    task_name: Dump Production Database to CSV
    operator_class: BashOperator
    operator_module: airflow.operators.bash
    component_ref: dump_prod_csv
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids: []
    trigger_rule: none_failed
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: copy_dev
    task_name: Load CSV Snapshot into Development Database
    operator_class: BashOperator
    operator_module: airflow.operators.bash
    component_ref: copy_dev
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - dump_prod_csv
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: copy_staging
    task_name: Load CSV Snapshot into Staging Database
    operator_class: BashOperator
    operator_module: airflow.operators.bash
    component_ref: copy_staging
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - dump_prod_csv
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: copy_qa
    task_name: Load CSV Snapshot into QA Database
    operator_class: BashOperator
    operator_module: airflow.operators.bash
    component_ref: copy_qa
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - dump_prod_csv
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
