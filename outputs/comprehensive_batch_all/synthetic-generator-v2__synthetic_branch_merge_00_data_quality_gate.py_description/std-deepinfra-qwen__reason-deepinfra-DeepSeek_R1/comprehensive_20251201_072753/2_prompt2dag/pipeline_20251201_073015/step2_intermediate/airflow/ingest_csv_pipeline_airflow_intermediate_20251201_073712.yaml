metadata:
  target_orchestrator: airflow
  generated_at: 2025-12-01 07:37:12.130318
  source_analysis_file: 
    Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_branch_merge_00_data_quality_gate.py_description.txt
  pipeline_name: ingest_csv_pipeline
  pipeline_description: 'Comprehensive Pipeline Description: This DAG implements a data quality gate for customer CSV data
    that ingests raw data, performs quality assessment, and conditionally routes to production or quarantine based on quality
    scores.'
  orchestrator_specific: {}
schedule:
  enabled: true
  schedule_expression: '@daily'
  start_date: '2024-01-01'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: raw_csv_source
    conn_type: fs
    description: Raw CSV Source
    config:
      base_path: /data/raw/
      protocol: file
  - conn_id: production_database
    conn_type: generic
    description: Production Database
    config:
      host: production-db-host
      port: 5432
      protocol: jdbc
      database: production_db
      schema: public
      login: PROD_DB_USER
      password: PROD_DB_PASSWORD
  - conn_id: quarantine_storage
    conn_type: fs
    description: Quarantine Storage
    config:
      base_path: /data/quarantine/
      protocol: file
  - conn_id: email_system
    conn_type: http
    description: Email System
    config:
      base_url: https://smtp.company.com
      protocol: smtp
      login: SMTP_USER
      password: SMTP_PASSWORD
  - conn_id: cleanup_filesystem
    conn_type: fs
    description: Cleanup Filesystem
    config:
      base_path: /data/temp/
      protocol: file
tasks:
  - task_id: ingest_csv
    task_name: Ingest CSV
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: ingest_csv
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids: []
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: quality_check
    task_name: Quality Check
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: quality_check
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - ingest_csv
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: production_load
    task_name: Production Load
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: production_load
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - quality_check
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: quarantine_and_alert
    task_name: Quarantine and Alert
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: quarantine_and_alert
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - quality_check
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: send_alert_email
    task_name: Send Alert Email
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: send_alert_email
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - quarantine_and_alert
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: cleanup
    task_name: Cleanup
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: cleanup
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - production_load
      - send_alert_email
    trigger_rule: all_success
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
