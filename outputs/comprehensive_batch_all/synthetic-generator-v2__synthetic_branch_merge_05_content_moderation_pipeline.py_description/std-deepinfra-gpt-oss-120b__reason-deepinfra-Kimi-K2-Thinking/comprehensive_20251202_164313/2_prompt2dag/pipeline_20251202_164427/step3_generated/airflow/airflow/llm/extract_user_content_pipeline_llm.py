# -*- coding: utf-8 -*-
"""
Generated by Airflow DAG generator
Pipeline: extract_user_content_pipeline
Description: Content Moderation Pipeline
Pattern: fanout_fanin
"""

from __future__ import annotations

import logging
from datetime import datetime, timedelta

import pandas as pd
import requests
from airflow import DAG
from airflow.decorators import task
from airflow.exceptions import AirflowFailException
from airflow.utils.timezone import utc

# ----------------------------------------------------------------------
# Default arguments applied to all tasks
# ----------------------------------------------------------------------
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
    "email_on_failure": False,
    "email_on_retry": False,
}

# ----------------------------------------------------------------------
# DAG definition
# ----------------------------------------------------------------------
with DAG(
    dag_id="extract_user_content_pipeline",
    description="Content Moderation Pipeline",
    schedule_interval="@daily",
    start_date=datetime(2024, 1, 1, tzinfo=utc),
    catchup=False,
    default_args=default_args,
    tags=["content_moderation", "fanout_fanin"],
    max_active_runs=1,
) as dag:

    # ------------------------------------------------------------------
    # Task: Extract User Content
    # ------------------------------------------------------------------
    @task(task_id="extract_user_content")
    def extract_user_content() -> pd.DataFrame:
        """
        Reads raw user content from a local CSV file system.
        Expected connection ID: local_csv_filesystem
        Returns a pandas DataFrame with the raw content.
        """
        try:
            # In a real deployment, the path could be fetched from a Variable or Connection.
            csv_path = "/opt/airflow/data/user_content.csv"
            logging.info("Reading user content from %s", csv_path)
            df = pd.read_csv(csv_path)
            logging.info("Extracted %d rows of user content", len(df))
            return df
        except Exception as exc:
            logging.exception("Failed to extract user content")
            raise AirflowFailException(f"Extraction error: {exc}") from exc

    # ------------------------------------------------------------------
    # Task: Evaluate Toxicity
    # ------------------------------------------------------------------
    @task(task_id="evaluate_toxicity")
    def evaluate_toxicity(df: pd.DataFrame) -> pd.DataFrame:
        """
        Calls the Content Management API to evaluate toxicity scores.
        Expected connection ID: content_management_api
        Returns the original DataFrame enriched with a 'toxicity_score' column.
        """
        try:
            api_endpoint = "https://content-management.example.com/api/evaluate"
            headers = {"Content-Type": "application/json"}
            logging.info("Evaluating toxicity for %d records", len(df))

            # Batch request simulation (real implementation may differ)
            payload = {"records": df.to_dict(orient="records")}
            response = requests.post(api_endpoint, json=payload, headers=headers, timeout=30)

            response.raise_for_status()
            results = response.json().get("results", [])
            scores = [item.get("toxicity_score", 0.0) for item in results]

            df["toxicity_score"] = scores
            logging.info("Toxicity evaluation completed")
            return df
        except Exception as exc:
            logging.exception("Failed to evaluate toxicity")
            raise AirflowFailException(f"Toxicity evaluation error: {exc}") from exc

    # ------------------------------------------------------------------
    # Task: Publish Safe Content
    # ------------------------------------------------------------------
    @task(task_id="publish_content")
    def publish_content(df: pd.DataFrame) -> None:
        """
        Publishes content with toxicity_score below a safe threshold.
        Expected connection ID: publishing_api
        """
        try:
            safe_threshold = 0.3
            safe_content = df[df["toxicity_score"] < safe_threshold]
            logging.info("Publishing %d safe content items", len(safe_content))

            api_endpoint = "https://publishing.example.com/api/publish"
            headers = {"Content-Type": "application/json"}

            for _, row in safe_content.iterrows():
                payload = {"content_id": row["content_id"], "text": row["text"]}
                resp = requests.post(api_endpoint, json=payload, headers=headers, timeout=10)
                resp.raise_for_status()
                logging.debug("Published content_id=%s", row["content_id"])

            logging.info("All safe content published successfully")
        except Exception as exc:
            logging.exception("Failed to publish safe content")
            raise AirflowFailException(f"Publishing error: {exc}") from exc

    # ------------------------------------------------------------------
    # Task: Remove and Flag Toxic Content
    # ------------------------------------------------------------------
    @task(task_id="remove_and_flag_content")
    def remove_and_flag_content(df: pd.DataFrame) -> None:
        """
        Removes content with toxicity_score above the threshold and flags it.
        Expected connection IDs: content_management_api, email_smtp_service
        """
        try:
            toxic_threshold = 0.7
            toxic_content = df[df["toxicity_score"] >= toxic_threshold]
            logging.info("Removing and flagging %d toxic content items", len(toxic_content))

            # Remove content via Content Management API
            remove_endpoint = "https://content-management.example.com/api/remove"
            flag_endpoint = "https://content-management.example.com/api/flag"
            headers = {"Content-Type": "application/json"}

            for _, row in toxic_content.iterrows():
                payload = {"content_id": row["content_id"]}

                # Remove
                resp_remove = requests.post(remove_endpoint, json=payload, headers=headers, timeout=10)
                resp_remove.raise_for_status()
                logging.debug("Removed content_id=%s", row["content_id"])

                # Flag
                resp_flag = requests.post(flag_endpoint, json=payload, headers=headers, timeout=10)
                resp_flag.raise_for_status()
                logging.debug("Flagged content_id=%s", row["content_id"])

            # Optional: send notification email (placeholder)
            logging.info("Toxic content removal and flagging completed")
        except Exception as exc:
            logging.exception("Failed to remove/flag toxic content")
            raise AirflowFailException(f"Removal/Flagging error: {exc}") from exc

    # ------------------------------------------------------------------
    # Task: Create Audit Log
    # ------------------------------------------------------------------
    @task(task_id="audit_log")
    def audit_log() -> None:
        """
        Sends an audit entry to the Audit Logging System.
        Expected connection ID: audit_logging_api
        """
        try:
            api_endpoint = "https://audit-logging.example.com/api/log"
            headers = {"Content-Type": "application/json"}
            payload = {
                "pipeline": "extract_user_content_pipeline",
                "run_time": datetime.utcnow().isoformat() + "Z",
                "status": "completed",
            }
            resp = requests.post(api_endpoint, json=payload, headers=headers, timeout=10)
            resp.raise_for_status()
            logging.info("Audit log entry created successfully")
        except Exception as exc:
            logging.exception("Failed to create audit log")
            raise AirflowFailException(f"Audit logging error: {exc}") from exc

    # ------------------------------------------------------------------
    # Define task pipeline
    # ------------------------------------------------------------------
    raw_df = extract_user_content()
    evaluated_df = evaluate_toxicity(raw_df)

    # Fan‑out: two parallel branches
    publish_content(evaluated_df)
    remove_and_flag_content(evaluated_df)

    # Fan‑in: audit after both branches complete
    audit_log()

    # Set explicit dependencies for clarity (optional, as the above
    # function calls already create the DAG structure)
    evaluate_toxicity >> [publish_content, remove_and_flag_content]
    [publish_content, remove_and_flag_content] >> audit_log()