# Generated by Dagster Pipeline Generator
# Date: 2024-06-20
# Pipeline: Content Moderation Pipeline
# Description: Scans user‑generated content for toxicity, branches based on a 0.7 threshold,
# and merges results for audit logging.

from __future__ import annotations

import csv
import datetime
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple

import dagster
from dagster import (
    AssetKey,
    Config,
    In,
    IOManager,
    IOManagerDefinition,
    Out,
    Output,
    RetryPolicy,
    ScheduleDefinition,
    String,
    asset,
    job,
    op,
    resource,
    schedule,
)
from dagster import in_process_executor

# ----------------------------------------------------------------------
# Resource Definitions
# ----------------------------------------------------------------------


@resource(config_schema={"api_key": String})
def content_mgmt_api(init_context: dagster.InitResourceContext) -> Any:
    """Placeholder for a Content Management System API client."""
    class ContentMgmtClient:
        def __init__(self, api_key: str):
            self.api_key = api_key

        def fetch_user_content(self) -> List[Dict[str, Any]]:
            # In a real implementation, this would call the CMS.
            return []

    return ContentMgmtClient(init_context.resource_config["api_key"])


@resource(config_schema={"api_key": String})
def publishing_api(init_context: dagster.InitResourceContext) -> Any:
    """Placeholder for a Publishing System API client."""
    class PublishingClient:
        def __init__(self, api_key: str):
            self.api_key = api_key

        def publish(self, content: List[Dict[str, Any]]) -> None:
            # In a real implementation, this would publish the content.
            pass

    return PublishingClient(init_context.resource_config["api_key"])


@resource(config_schema={"api_key": String})
def audit_logging_api(init_context: dagster.InitResourceContext) -> Any:
    """Placeholder for an Audit Logging System API client."""
    class AuditLoggingClient:
        def __init__(self, api_key: str):
            self.api_key = api_key

        def log(self, records: List[Dict[str, Any]]) -> None:
            # In a real implementation, this would send logs to the audit system.
            pass

    return AuditLoggingClient(init_context.resource_config["api_key"])


@resource(config_schema={"smtp_server": String, "username": String, "password": String})
def email_smtp(init_context: dagster.InitResourceContext) -> Any:
    """Placeholder for an SMTP email server client."""
    class EmailClient:
        def __init__(self, server: str, user: str, pwd: str):
            self.server = server
            self.user = user
            self.pwd = pwd

        def send_email(self, to: str, subject: str, body: str) -> None:
            # In a real implementation, this would send an email.
            pass

    cfg = init_context.resource_config
    return EmailClient(cfg["smtp_server"], cfg["username"], cfg["password"])


# ----------------------------------------------------------------------
# IO Manager for Local CSV Filesystem
# ----------------------------------------------------------------------


class CSVIOManager(IOManager):
    """Simple CSV IO manager that reads/writes lists of dictionaries."""

    def __init__(self, base_path: str):
        self.base_path = base_path.rstrip("/")

    def _full_path(self, context: dagster.IOManagerContext) -> str:
        return f"{self.base_path}/{context.resource_key.path[-1]}.csv"

    def handle_output(self, context: dagster.IOManagerContext, obj: Any) -> None:
        path = self._full_path(context)
        with open(path, mode="w", newline="", encoding="utf-8") as f:
            if not obj:
                return
            writer = csv.DictWriter(f, fieldnames=obj[0].keys())
            writer.writeheader()
            writer.writerows(obj)

    def load_input(self, context: dagster.IOManagerContext) -> Any:
        path = self._full_path(context)
        with open(path, mode="r", newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            return [row for row in reader]


def csv_io_manager(init_context: dagster.InitResourceContext) -> CSVIOManager:
    base_path = init_context.resource_config.get("base_path", ".")
    return CSVIOManager(base_path=base_path)


csv_io_manager_def = IOManagerDefinition(
    name="fs_io_manager", resource_fn=csv_io_manager
)


# ----------------------------------------------------------------------
# Op Definitions
# ----------------------------------------------------------------------


@op(
    name="extract_user_content",
    description="Extracts user‑generated content from a CSV file stored locally.",
    out=Out(List[Dict[str, Any]]),
    retry_policy=RetryPolicy(max_retries=2, delay=5),
    required_resource_keys={"fs_io_manager"},
)
def extract_user_content(context: dagster.OpContext) -> List[Dict[str, Any]]:
    """Read the CSV containing user content using the CSV IO manager."""
    # The CSV file is expected to be named `user_content.csv` in the base path.
    # The IO manager will resolve the path automatically.
    content = context.resources.fs_io_manager.load_input(
        context=dagster.IOManagerContext(
            resource_key=dagster.ResourceKey(path=("user_content",))
        )
    )
    context.log.info(f"Extracted {len(content)} rows of user content.")
    return content


def _mock_toxicity_score(text: str) -> float:
    """Very naive mock toxicity scorer; replace with real model in production."""
    # For demonstration, any text containing the word "bad" is considered toxic.
    return 0.9 if "bad" in text.lower() else 0.1


@op(
    name="evaluate_toxicity",
    description="Evaluates toxicity of each content item and branches based on a 0.7 threshold.",
    ins={"content": In(List[Dict[str, Any]])},
    out={"safe": Out(List[Dict[str, Any]]), "toxic": Out(List[Dict[str, Any]])},
    retry_policy=RetryPolicy(max_retries=2, delay=5),
)
def evaluate_toxicity(context: dagster.OpContext, content: List[Dict[str, Any]]) -> Tuple[
    Output[List[Dict[str, Any]]], Output[List[Dict[str, Any]]]
]:
    """Score each piece of content and split into safe and toxic collections."""
    safe_items: List[Dict[str, Any]] = []
    toxic_items: List[Dict[str, Any]] = []

    for item in content:
        text = item.get("text", "")
        score = _mock_toxicity_score(text)
        item["toxicity_score"] = score
        if score >= 0.7:
            toxic_items.append(item)
        else:
            safe_items.append(item)

    context.log.info(f"Safe items: {len(safe_items)}; Toxic items: {len(toxic_items)}")
    # Emit two separate outputs for downstream branching.
    yield Output(value=safe_items, output_name="safe")
    yield Output(value=toxic_items, output_name="toxic")


@op(
    name="publish_content",
    description="Publishes safe content via the publishing API.",
    ins={"safe_content": In(List[Dict[str, Any]])},
    out=Out(None),
    retry_policy=RetryPolicy(max_retries=2, delay=5),
    required_resource_keys={"publishing_api"},
)
def publish_content(context: dagster.OpContext, safe_content: List[Dict[str, Any]]) -> None:
    """Send safe content to the publishing system."""
    if not safe_content:
        context.log.info("No safe content to publish.")
        return

    client = context.resources.publishing_api
    client.publish(safe_content)
    context.log.info(f"Published {len(safe_content)} safe content items.")


@op(
    name="remove_and_flag_content",
    description="Removes toxic content and flags the associated users.",
    ins={"toxic_content": In(List[Dict[str, Any]])},
    out=Out(List[Dict[str, Any]]),
    retry_policy=RetryPolicy(max_retries=2, delay=5),
    required_resource_keys={"content_mgmt_api", "email_smtp"},
)
def remove_and_flag_content(
    context: dagster.OpContext, toxic_content: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """Delete toxic content and notify users via email."""
    if not toxic_content:
        context.log.info("No toxic content to process.")
        return []

    cms_client = context.resources.content_mgmt_api
    email_client = context.resources.email_smtp

    # Placeholder logic: iterate and "remove" each item.
    for item in toxic_content:
        content_id = item.get("id")
        user_email = item.get("user_email")
        # Simulate removal
        context.log.debug(f"Removing content ID {content_id}")
        # Simulate user notification
        if user_email:
            email_client.send_email(
                to=user_email,
                subject="Content Removal Notice",
                body="Your content was removed due to policy violations.",
            )
            context.log.debug(f"Emailed user {user_email}")

    context.log.info(f"Processed {len(toxic_content)} toxic items.")
    return toxic_content


@op(
    name="audit_log",
    description="Creates a consolidated audit log entry for both safe and toxic processing.",
    ins={
        "safe_content": In(List[Dict[str, Any]]),
        "toxic_content": In(List[Dict[str, Any]]),
    },
    out=Out(None),
    retry_policy=RetryPolicy(max_retries=2, delay=5),
    required_resource_keys={"audit_logging_api"},
)
def audit_log(
    context: dagster.OpContext,
    safe_content: List[Dict[str, Any]],
    toxic_content: List[Dict[str, Any]],
) -> None:
    """Send a combined audit record to the audit logging system."""
    client = context.resources.audit_logging_api
    timestamp = datetime.datetime.utcnow().isoformat() + "Z"

    record = {
        "timestamp": timestamp,
        "safe_count": len(safe_content),
        "toxic_count": len(toxic_content),
        "details": {
            "safe_ids": [item.get("id") for item in safe_content],
            "toxic_ids": [item.get("id") for item in toxic_content],
        },
    }

    client.log([record])
    context.log.info("Audit log entry created.")


# ----------------------------------------------------------------------
# Job Definition
# ----------------------------------------------------------------------


@job(
    name="content_moderation_pipeline",
    description=(
        "Scans user‑generated content for toxicity, branches based on a 0.7 threshold, "
        "and merges results for audit logging."
    ),
    executor_def=in_process_executor,
    resource_defs={
        "fs_io_manager": csv_io_manager_def,
        "content_mgmt_api": content_mgmt_api,
        "publishing_api": publishing_api,
        "audit_logging_api": audit_logging_api,
        "email_smtp": email_smtp,
    },
)
def content_moderation_pipeline():
    """Orchestrates the content moderation workflow."""
    # Extract raw content
    raw_content = extract_user_content()

    # Evaluate toxicity and branch
    toxicity_results = evaluate_toxicity(raw_content)

    # Safe path
    publish_content(toxicity_results.safe)

    # Toxic path
    toxic_processed = remove_and_flag_content(toxicity_results.toxic)

    # Consolidate audit log (depends on both branches)
    audit_log(
        safe_content=toxicity_results.safe,
        toxic_content=toxic_processed,
    )


# ----------------------------------------------------------------------
# Schedule Definition
# ----------------------------------------------------------------------


daily_schedule = ScheduleDefinition(
    job=content_moderation_pipeline,
    name="content_moderation_daily_schedule",
    cron_schedule="@daily",
    execution_timezone="UTC",
    default_status=dagster.ScheduleStatus.RUNNING,
    description="Runs the content moderation pipeline once per day at midnight UTC.",
    # No catchup behavior; Dagster's default is to not backfill missed runs.
    # To explicitly disable catchup, we set `catchup=False` in the schedule decorator.
    # However, ScheduleDefinition does not expose a catchup flag directly; this is
    # handled by the scheduler configuration outside of code.
)


# ----------------------------------------------------------------------
# Entry point for local testing
# ----------------------------------------------------------------------


if __name__ == "__main__":
    # Execute the job locally for quick testing.
    result = content_moderation_pipeline.execute_in_process(
        run_config={
            "resources": {
                "fs_io_manager": {"config": {"base_path": "./data"}},
                "content_mgmt_api": {"config": {"api_key": "dummy_cms_key"}},
                "publishing_api": {"config": {"api_key": "dummy_pub_key"}},
                "audit_logging_api": {"config": {"api_key": "dummy_audit_key"}},
                "email_smtp": {
                    "config": {
                        "smtp_server": "smtp.example.com",
                        "username": "user@example.com",
                        "password": "password",
                    }
                },
            }
        }
    )
    assert result.success
    print("Pipeline executed successfully.")