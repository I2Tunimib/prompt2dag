# Generated by Airflow DAG Generator on 2024-06-13
# Content Moderation Pipeline
# Description: Scans user‑generated content for toxicity, branches based on a 0.7 threshold,
# and merges results for audit logging. Pattern: fanout_fanin.

import json
import logging
from datetime import datetime, timedelta

import pendulum
from airflow import DAG
from airflow.decorators import task
from airflow.exceptions import AirflowException
from airflow.models import Variable
from airflow.providers.http.hooks.http import HttpHook
from airflow.providers.smtp.hooks.smtp import SmtpHook
from airflow.providers.common.sql.hooks.sql import SqlHook

# Default arguments for all tasks
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": True,
    "email": ["alerts@example.com"],
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
}

# DAG definition
with DAG(
    dag_id="content_moderation_pipeline",
    description="Comprehensive pipeline that scans user‑generated content for toxicity, "
                "branches based on a 0.7 threshold, and merges results for audit logging.",
    schedule_interval="@daily",
    start_date=pendulum.datetime(2024, 1, 1, tz="UTC"),
    catchup=False,
    default_args=default_args,
    tags=["content", "moderation", "fanout_fanin"],
    max_active_runs=1,
) as dag:

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def extract_user_content() -> list:
        """
        Extract user‑generated content from a local CSV file.
        Returns a list of dictionaries, each representing a content record.
        """
        try:
            # Placeholder: replace with actual file path or connection usage
            csv_path = Variable.get("user_content_csv_path", default_var="/opt/airflow/data/user_content.csv")
            logging.info("Reading user content from %s", csv_path)

            import csv

            records = []
            with open(csv_path, mode="r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    records.append(row)

            logging.info("Extracted %d content records", len(records))
            return records
        except Exception as exc:
            logging.error("Failed to extract user content: %s", exc)
            raise AirflowException("extract_user_content failed") from exc

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def evaluate_toxicity(content_records: list) -> list:
        """
        Evaluate toxicity for each content record.
        Adds a 'toxicity_score' field (0.0‑1.0) to each record.
        """
        try:
            # Placeholder toxicity evaluation – replace with real model/API call
            import random

            for record in content_records:
                # Simulate a toxicity score
                record["toxicity_score"] = round(random.uniform(0, 1), 3)

            logging.info("Evaluated toxicity for %d records", len(content_records))
            return content_records
        except Exception as exc:
            logging.error("Toxicity evaluation failed: %s", exc)
            raise AirflowException("evaluate_toxicity failed") from exc

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def publish_content(evaluated_records: list) -> None:
        """
        Publish content deemed safe (toxicity_score < 0.7) via the publishing API.
        """
        try:
            publishing_hook = HttpHook(http_conn_id="publishing_api", method="POST")
            safe_records = [r for r in evaluated_records if r.get("toxicity_score", 1) < 0.7]

            logging.info("Publishing %d safe records", len(safe_records))

            for record in safe_records:
                payload = {
                    "content_id": record.get("id"),
                    "text": record.get("text"),
                    "score": record.get("toxicity_score"),
                }
                response = publishing_hook.run(
                    endpoint="/publish",
                    data=json.dumps(payload),
                    headers={"Content-Type": "application/json"},
                )
                if response.status_code != 200:
                    logging.warning(
                        "Failed to publish content_id %s: %s",
                        record.get("id"),
                        response.text,
                    )
                else:
                    logging.debug("Published content_id %s", record.get("id"))
        except Exception as exc:
            logging.error("Publishing safe content failed: %s", exc)
            raise AirflowException("publish_content failed") from exc

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def remove_and_flag_content(evaluated_records: list) -> None:
        """
        Remove and flag content deemed toxic (toxicity_score >= 0.7) via the content management API.
        """
        try:
            cms_hook = HttpHook(http_conn_id="content_management_api", method="POST")
            toxic_records = [r for r in evaluated_records if r.get("toxicity_score", 0) >= 0.7]

            logging.info("Removing and flagging %d toxic records", len(toxic_records))

            for record in toxic_records:
                payload = {
                    "content_id": record.get("id"),
                    "action": "remove_and_flag",
                    "reason": "Toxicity score {:.3f}".format(record.get("toxicity_score")),
                }
                response = cms_hook.run(
                    endpoint="/moderate",
                    data=json.dumps(payload),
                    headers={"Content-Type": "application/json"},
                )
                if response.status_code != 200:
                    logging.warning(
                        "Failed to remove/flag content_id %s: %s",
                        record.get("id"),
                        response.text,
                    )
                else:
                    logging.debug("Removed/flagged content_id %s", record.get("id"))
        except Exception as exc:
            logging.error("Removal/flagging of toxic content failed: %s", exc)
            raise AirflowException("remove_and_flag_content failed") from exc

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def audit_log(published: None, removed: None) -> None:
        """
        Consolidate audit information for both publishing and removal actions
        and send it to the audit logging API. Also email a summary report.
        """
        try:
            audit_hook = HttpHook(http_conn_id="audit_logging_api", method="POST")
            smtp_hook = SmtpHook(smtp_conn_id="email_smtp_service")

            # In a real implementation, we would retrieve detailed logs from a DB or storage.
            # Here we construct a simple placeholder payload.
            audit_payload = {
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "pipeline": "content_moderation_pipeline",
                "status": "completed",
                "details": "Publishing and removal actions have been logged.",
            }

            response = audit_hook.run(
                endpoint="/audit",
                data=json.dumps(audit_payload),
                headers={"Content-Type": "application/json"},
            )
            if response.status_code != 200:
                logging.warning("Audit logging failed: %s", response.text)
            else:
                logging.info("Audit log successfully sent")

            # Send email summary
            subject = "Content Moderation Pipeline Execution Summary"
            html_content = f"""
                <h3>Content Moderation Pipeline Completed</h3>
                <p>Timestamp: {audit_payload['timestamp']}</p>
                <p>Status: {audit_payload['status']}</p>
                <p>Details: {audit_payload['details']}</p>
            """
            smtp_hook.send_email(
                to=["audit@example.com"],
                subject=subject,
                html_content=html_content,
            )
            logging.info("Summary email sent")
        except Exception as exc:
            logging.error("Audit logging task failed: %s", exc)
            raise AirflowException("audit_log failed") from exc

    # Define task flow
    raw_content = extract_user_content()
    evaluated = evaluate_toxicity(raw_content)

    # Fan‑out: both publishing and removal run in parallel
    publish = publish_content(evaluated)
    remove = remove_and_flag_content(evaluated)

    # Fan‑in: audit runs after both branches complete
    audit = audit_log(publish, remove)

    # Explicit dependencies (optional, as they are inferred from arguments)
    raw_content >> evaluated
    evaluated >> [publish, remove]
    [publish, remove] >> audit