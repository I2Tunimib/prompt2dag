# Generated by Dagster Code Generator
# Generation Metadata:
# - Job Name: load_and_modify_data_pipeline
# - Description: No description provided.
# - Executor Type: docker_executor
# - IO Manager: fs_io_manager
# - Dagster Version: 1.5.0
# - Use Assets: False
# - Required Resources: openmeteo_api, geocoding_api, data_directory

from dagster import (
    job,
    op,
    Out,
    In,
    RetryPolicy,
    fs_io_manager,
    resource,
    Field,
    String,
    executor,
    execute_job,
    reconstructable,
)

# Define resources
@resource(config_schema={"data_directory": Field(String)})
def data_directory(context):
    """Data Directory Resource"""
    return context.resource_config["data_directory"]

@resource
def load_and_modify_service(context):
    """Load and Modify Service Resource"""
    pass

@resource
def reconciliation_service(context):
    """Reconciliation Service Resource"""
    pass

@resource
def openmeteo_api(context):
    """OpenMeteo API Resource"""
    pass

@resource
def geocoding_api(context):
    """Geocoding API Resource"""
    pass

@resource(config_schema={"docker_network": Field(String)})
def docker_network(context):
    """Docker Network Resource"""
    return context.resource_config["docker_network"]

@resource(config_schema={"shared_volume": Field(String)})
def shared_volume(context):
    """Shared Volume Resource"""
    return context.resource_config["shared_volume"]

# Define ops
@op(
    required_resource_keys={"data_directory", "load_and_modify_service"},
    out={"modified_data": Out()},
    retry_policy=RetryPolicy(max_retries=1),
)
def load_and_modify_data(context):
    """Load and modify data from the data directory."""
    data_directory = context.resources.data_directory
    # Simulate data loading and modification
    modified_data = {"data": "modified"}
    return modified_data

@op(
    required_resource_keys={"reconciliation_service"},
    out={"reconciled_data": Out()},
    retry_policy=RetryPolicy(max_retries=1),
)
def reconcile_data(context, modified_data):
    """Reconcile the modified data."""
    # Simulate data reconciliation
    reconciled_data = {"data": "reconciled"}
    return reconciled_data

@op(
    required_resource_keys={"openmeteo_api"},
    out={"extended_data": Out()},
    retry_policy=RetryPolicy(max_retries=1),
)
def extend_with_weather_data(context, reconciled_data):
    """Extend the reconciled data with weather data from OpenMeteo API."""
    # Simulate weather data extension
    extended_data = {"data": "extended with weather"}
    return extended_data

@op(
    out={"final_data": Out()},
    retry_policy=RetryPolicy(max_retries=1),
)
def extend_columns(context, extended_data):
    """Extend the columns of the extended data."""
    # Simulate column extension
    final_data = {"data": "final with extended columns"}
    return final_data

@op(
    required_resource_keys={"data_directory"},
    out={"saved_data": Out()},
    retry_policy=RetryPolicy(max_retries=1),
)
def save_final_data(context, final_data):
    """Save the final data to the data directory."""
    data_directory = context.resources.data_directory
    # Simulate data saving
    saved_data = {"data": "saved"}
    return saved_data

# Define the job
@job(
    name="load_and_modify_data_pipeline",
    description="No description provided.",
    executor_def=docker_executor,
    resource_defs={
        "data_directory": data_directory,
        "load_and_modify_service": load_and_modify_service,
        "reconciliation_service": reconciliation_service,
        "openmeteo_api": openmeteo_api,
        "geocoding_api": geocoding_api,
        "docker_network": docker_network,
        "shared_volume": shared_volume,
    },
    config={
        "resources": {
            "data_directory": {"config": {"data_directory": "/path/to/data"}},
            "docker_network": {"config": {"docker_network": "my_docker_network"}},
            "shared_volume": {"config": {"shared_volume": "/path/to/shared_volume"}},
        }
    },
)
def load_and_modify_data_pipeline():
    """Load and modify data pipeline."""
    modified_data = load_and_modify_data()
    reconciled_data = reconcile_data(modified_data)
    extended_data = extend_with_weather_data(reconciled_data)
    final_data = extend_columns(extended_data)
    save_final_data(final_data)

# Example execution
if __name__ == "__main__":
    result = execute_job(reconstructable(load_and_modify_data_pipeline))
    assert result.success, "Job execution failed"