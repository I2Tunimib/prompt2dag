# Generated by Prefect 2.x Code Generator
# Date: [Current Date]
# Prefect Version: 2.14.0

import os
from prefect import flow, task, get_run_logger
from prefect_docker import DockerContainer
from prefect_docker.containers import create_docker_container
from prefect_docker.credentials import DockerHost
from prefect.blocks.system import Secret
from prefect.filesystems import LocalFileSystem
from prefect.task_runners import SequentialTaskRunner

# Load secrets and resources
data_directory = LocalFileSystem.load("data_directory")
load_and_modify_service = Secret.load("load_and_modify_service")
reconciliation_service = Secret.load("reconciliation_service")
openmeteo_api = Secret.load("openmeteo_api")
docker_network = Secret.load("docker_network")
shared_volume = LocalFileSystem.load("shared_volume")

@task(retries=1, name="Load and Modify Data")
def load_and_modify_data():
    logger = get_run_logger()
    logger.info("Starting Load and Modify Data task")
    
    env_vars = {
        "DATASET_ID": "2",
        "DATE_COLUMN": "Fecha_id",
        "TABLE_NAMING_CONVENTION": "JOT_{}"
    }
    
    container = create_docker_container(
        image="i2t-backendwithintertwino6-load-and-modify:latest",
        env=env_vars,
        networks=[docker_network.get()],
        volumes=[f"{shared_volume.basepath}:/shared_volume"],
        docker_host=DockerHost.load("docker_host")
    )
    
    container.start()
    container.wait()
    logger.info("Load and Modify Data task completed")

@task(retries=1, name="Data Reconciliation")
def reconcile_data():
    logger = get_run_logger()
    logger.info("Starting Data Reconciliation task")
    
    env_vars = {
        "PRIMARY_COLUMN": "City",
        "OPTIONAL_COLUMNS": "County,Country",
        "RECONCILIATOR_ID": "geocodingHere",
        "API_TOKEN": reconciliation_service.get()
    }
    
    container = create_docker_container(
        image="i2t-backendwithintertwino6-reconciliation:latest",
        env=env_vars,
        networks=[docker_network.get()],
        volumes=[f"{shared_volume.basepath}:/shared_volume"],
        docker_host=DockerHost.load("docker_host")
    )
    
    container.start()
    container.wait()
    logger.info("Data Reconciliation task completed")

@task(retries=1, name="OpenMeteo Data Extension")
def extend_with_weather_data():
    logger = get_run_logger()
    logger.info("Starting OpenMeteo Data Extension task")
    
    env_vars = {
        "DATE_FORMAT": "your_date_format",
        "API_TOKEN": openmeteo_api.get()
    }
    
    container = create_docker_container(
        image="i2t-backendwithintertwino6-openmeteo-extension:latest",
        env=env_vars,
        networks=[docker_network.get()],
        volumes=[f"{shared_volume.basepath}:/shared_volume"],
        docker_host=DockerHost.load("docker_host")
    )
    
    container.start()
    container.wait()
    logger.info("OpenMeteo Data Extension task completed")

@task(retries=1, name="Column Extension")
def extend_columns():
    logger = get_run_logger()
    logger.info("Starting Column Extension task")
    
    env_vars = {
        "EXTENDER_ID": "reconciledColumnExt"
    }
    
    container = create_docker_container(
        image="i2t-backendwithintertwino6-column-extension:latest",
        env=env_vars,
        networks=[docker_network.get()],
        volumes=[f"{shared_volume.basepath}:/shared_volume"],
        docker_host=DockerHost.load("docker_host")
    )
    
    container.start()
    container.wait()
    logger.info("Column Extension task completed")

@task(retries=1, name="Save Final Data")
def save_final_data():
    logger = get_run_logger()
    logger.info("Starting Save Final Data task")
    
    container = create_docker_container(
        image="i2t-backendwithintertwino6-save:latest",
        networks=[docker_network.get()],
        volumes=[f"{shared_volume.basepath}:/shared_volume"],
        docker_host=DockerHost.load("docker_host")
    )
    
    container.start()
    container.wait()
    logger.info("Save Final Data task completed")

@flow(name="load_and_modify_data_pipeline", task_runner=SequentialTaskRunner())
def load_and_modify_data_pipeline():
    logger = get_run_logger()
    logger.info("Starting load_and_modify_data_pipeline")
    
    load_and_modify_data_result = load_and_modify_data()
    reconcile_data_result = reconcile_data()
    extend_with_weather_data_result = extend_with_weather_data()
    extend_columns_result = extend_columns()
    save_final_data_result = save_final_data()
    
    logger.info("load_and_modify_data_pipeline completed")

if __name__ == "__main__":
    load_and_modify_data_pipeline()