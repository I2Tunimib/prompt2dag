# Generated by Airflow DAG Generator
# Date: 2024-06-28
# Description: DAG for loading, reconciling, enriching, extending, and saving data using Docker containers.

import logging
from datetime import datetime, timedelta

from airflow import DAG
from airflow.providers.docker.operators.docker import DockerOperator
from airflow.utils.dates import days_ago

# ----------------------------------------------------------------------
# Default arguments applied to all tasks
# ----------------------------------------------------------------------
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=5),
}


def task_failure_callback(context):
    """Callback executed when a task fails."""
    task_instance = context.get("task_instance")
    dag_id = context.get("dag").dag_id
    logging.error(
        "Task %s in DAG %s failed. Log URL: %s",
        task_instance.task_id,
        dag_id,
        task_instance.log_url,
    )


# ----------------------------------------------------------------------
# DAG definition
# ----------------------------------------------------------------------
with DAG(
    dag_id="load_and_modify_data_pipeline",
    description="No description provided.",
    schedule_interval=None,  # Disabled schedule
    start_date=days_ago(1),
    catchup=False,
    default_args=default_args,
    tags=["sequential"],
    on_failure_callback=task_failure_callback,
) as dag:

    # ------------------------------------------------------------------
    # Task: Load and Modify Data
    # ------------------------------------------------------------------
    load_and_modify_data = DockerOperator(
        task_id="load_and_modify_data",
        image="i2t-backendwithintertwino6-load-and-modify:latest",
        api_version="auto",
        auto_remove=True,
        docker_url="unix://var/run/docker.sock",
        network_mode="app_network",  # Custom Docker network
        environment={
            "DATA_DIR": "/app/data",
            "DATASET_ID": "2",
            "DATE_COLUMN": "Fecha_id",
            "TABLE_NAMING": "JOT_{}",
        },
        retries=1,
        retry_delay=timedelta(minutes=5),
        on_failure_callback=task_failure_callback,
    )

    # ------------------------------------------------------------------
    # Task: Data Reconciliation
    # ------------------------------------------------------------------
    reconcile_city_names = DockerOperator(
        task_id="reconcile_city_names",
        image="i2t-backendwithintertwino6-reconciliation:latest",
        api_version="auto",
        auto_remove=True,
        docker_url="unix://var/run/docker.sock",
        network_mode="app_network",
        environment={
            "RECONCILIATOR_ID": "geocodingHere",
            "PRIMARY_COLUMN": "City",
            "OPTIONAL_COLUMNS": "County,Country",
            "API_TOKEN": "<HERE_API_TOKEN>",
        },
        retries=1,
        retry_delay=timedelta(minutes=5),
        on_failure_callback=task_failure_callback,
    )

    # ------------------------------------------------------------------
    # Task: OpenMeteo Data Extension
    # ------------------------------------------------------------------
    enrich_with_openmeteo = DockerOperator(
        task_id="enrich_with_openmeteo",
        image="i2t-backendwithintertwino6-openmeteo-extension:latest",
        api_version="auto",
        auto_remove=True,
        docker_url="unix://var/run/docker.sock",
        network_mode="app_network",
        environment={
            "WEATHER_ATTRIBUTES": "apparent_temperature_max,apparent_temperature_min,precipitation_sum,precipitation_hours",
            "DATE_SEPARATOR": "-",
        },
        retries=1,
        retry_delay=timedelta(minutes=5),
        on_failure_callback=task_failure_callback,
    )

    # ------------------------------------------------------------------
    # Task: Column Extension
    # ------------------------------------------------------------------
    extend_columns = DockerOperator(
        task_id="extend_columns",
        image="i2t-backendwithintertwino6-column-extension:latest",
        api_version="auto",
        auto_remove=True,
        docker_url="unix://var/run/docker.sock",
        network_mode="app_network",
        environment={
            "EXTENDER_ID": "reconciledColumnExt",
        },
        retries=1,
        retry_delay=timedelta(minutes=5),
        on_failure_callback=task_failure_callback,
    )

    # ------------------------------------------------------------------
    # Task: Save Final Data
    # ------------------------------------------------------------------
    save_final_data = DockerOperator(
        task_id="save_final_data",
        image="i2t-backendwithintertwino6-save:latest",
        api_version="auto",
        auto_remove=True,
        docker_url="unix://var/run/docker.sock",
        network_mode="app_network",
        environment={
            "OUTPUT_DIR": "/app/data",
        },
        retries=1,
        retry_delay=timedelta(minutes=5),
        on_failure_callback=task_failure_callback,
    )

    # ------------------------------------------------------------------
    # Define task dependencies (sequential flow)
    # ------------------------------------------------------------------
    load_and_modify_data >> reconcile_city_names >> enrich_with_openmeteo >> extend_columns >> save_final_data

# End of DAG definition.