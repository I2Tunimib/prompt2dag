# Generated by Airflow DAG generator on 2024-06-13
"""
DAG: load_and_modify_data_pipeline
Description: No description provided.
Pattern: sequential
"""

from datetime import datetime, timedelta

from airflow import DAG
from airflow.utils.task_group import TaskGroup
from airflow.providers.docker.operators.docker import DockerOperator
from airflow.models import Variable
from airflow.utils.email import send_email
from airflow.utils.trigger_rule import TriggerRule
from airflow.exceptions import AirflowFailException

# ----------------------------------------------------------------------
# Default arguments for all tasks
# ----------------------------------------------------------------------
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=5),
    "email_on_failure": False,
    "email_on_retry": False,
}


def failure_callback(context):
    """Send an email on task failure (optional)."""
    dag_id = context.get("dag").dag_id
    task_id = context.get("task_instance").task_id
    execution_date = context.get("execution_date")
    log_url = context.get("task_instance").log_url

    subject = f"[Airflow] DAG {dag_id} - Task {task_id} Failed"
    html_content = f"""
    <p>Task <strong>{task_id}</strong> in DAG <strong>{dag_id}</strong> failed.</p>
    <p>Execution date: {execution_date}</p>
    <p>Log URL: <a href="{log_url}">{log_url}</a></p>
    """
    # Replace with your email address or use Airflow's email config
    send_email(to=["airflow@example.com"], subject=subject, html_content=html_content)


# ----------------------------------------------------------------------
# DAG definition
# ----------------------------------------------------------------------
with DAG(
    dag_id="load_and_modify_data_pipeline",
    description="No description provided.",
    schedule_interval=None,  # Disabled schedule
    start_date=datetime(2024, 1, 1),
    catchup=False,
    default_args=default_args,
    tags=["sequential", "docker"],
    render_template_as_native_obj=True,
) as dag:

    # ------------------------------------------------------------------
    # Common DockerOperator configuration
    # ------------------------------------------------------------------
    docker_common_kwargs = {
        "api_version": "auto",
        "auto_remove": True,
        "docker_url": "unix://var/run/docker.sock",
        # Use the custom Docker network defined in the resources
        "network_mode": "app_network",
        # Mount the shared data directory volume into the container
        "volumes": ["data_dir_volume:/data"],  # Docker volume name -> container path
        # Pass API endpoints as environment variables using Airflow connections
        "environment": {
            "LOAD_MODIFY_API": "{{ conn.load_modify_api.host }}",
            "RECONCILIATION_API": "{{ conn.reconciliation_api.host }}",
            "OPENMETEO_API": "{{ conn.openmeteo_api.host }}",
            "INTERTWINO_API": "{{ conn.intertwino_api.host }}",
            "MONGODB_URI": "{{ conn.mongodb.get_uri() }}",
        },
        "on_failure_callback": failure_callback,
        "trigger_rule": TriggerRule.ALL_SUCCESS,
    }

    # ------------------------------------------------------------------
    # Task: Load and Modify Data
    # ------------------------------------------------------------------
    load_and_modify_data = DockerOperator(
        task_id="load_and_modify_data",
        image="i2t-backendwithintertwino6-load-and-modify:latest",
        **docker_common_kwargs,
    )

    # ------------------------------------------------------------------
    # Task: Data Reconciliation
    # ------------------------------------------------------------------
    reconcile_city_names = DockerOperator(
        task_id="reconcile_city_names",
        image="i2t-backendwithintertwino6-reconciliation:latest",
        **docker_common_kwargs,
    )

    # ------------------------------------------------------------------
    # Task: OpenMeteo Data Extension
    # ------------------------------------------------------------------
    enrich_with_openmeteo = DockerOperator(
        task_id="enrich_with_openmeteo",
        image="i2t-backendwithintertwino6-openmeteo-extension:latest",
        **docker_common_kwargs,
    )

    # ------------------------------------------------------------------
    # Task: Column Extension
    # ------------------------------------------------------------------
    extend_columns = DockerOperator(
        task_id="extend_columns",
        image="i2t-backendwithintertwino6-column-extension:latest",
        **docker_common_kwargs,
    )

    # ------------------------------------------------------------------
    # Task: Save Final Data
    # ------------------------------------------------------------------
    save_final_data = DockerOperator(
        task_id="save_final_data",
        image="i2t-backendwithintertwino6-save:latest",
        **docker_common_kwargs,
    )

    # ------------------------------------------------------------------
    # Set task dependencies (sequential flow)
    # ------------------------------------------------------------------
    (
        load_and_modify_data
        >> reconcile_city_names
        >> enrich_with_openmeteo
        >> extend_columns
        >> save_final_data
    )