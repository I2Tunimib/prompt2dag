# Generated by Dagster code generator
# Date: 2024-06-28
# Pipeline: load_and_modify_data_pipeline
# Description: No description provided.

from typing import Any, Dict, List, Optional

import pandas as pd
from dagster import (
    OpExecutionContext,
    RetryPolicy,
    asset,
    job,
    op,
    resource,
    fs_io_manager,
    ConfigurableResource,
    InitResourceContext,
    InputDefinition,
    OutputDefinition,
    Out,
    In,
    Nothing,
    RetryRequested,
    executor,
    docker_executor,
)

# ----------------------------------------------------------------------
# Resource definitions
# ----------------------------------------------------------------------


@resource(config_schema={"base_url": str})
def load_modify_api_resource(init_context: InitResourceContext) -> Any:
    """Placeholder resource for the Load‑and‑Modify Service API."""
    class LoadModifyAPI:
        def __init__(self, base_url: str):
            self.base_url = base_url

        def fetch_and_modify(self) -> pd.DataFrame:
            # Replace with real API call logic
            init_context.log.info(f"Fetching data from Load‑and‑Modify API at {self.base_url}")
            return pd.DataFrame({"city": ["Berlin", "Paris"], "value": [1, 2]})

    return LoadModifyAPI(init_context.resource_config["base_url"])


@resource(config_schema={"base_url": str})
def reconciliation_api_resource(init_context: InitResourceContext) -> Any:
    """Placeholder resource for the HERE Geocoding Reconciliation Service API."""
    class ReconciliationAPI:
        def __init__(self, base_url: str):
            self.base_url = base_url

        def reconcile(self, df: pd.DataFrame) -> pd.DataFrame:
            # Replace with real reconciliation logic
            init_context.log.info(f"Reconciling city names via {self.base_url}")
            df["city_normalized"] = df["city"].str.upper()
            return df

    return ReconciliationAPI(init_context.resource_config["base_url"])


@resource(config_schema={"base_url": str})
def openmeteo_api_resource(init_context: InitResourceContext) -> Any:
    """Placeholder resource for the OpenMeteo Weather Service API."""
    class OpenMeteoAPI:
        def __init__(self, base_url: str):
            self.base_url = base_url

        def enrich(self, df: pd.DataFrame) -> pd.DataFrame:
            # Replace with real weather enrichment logic
            init_context.log.info(f"Enriching data with OpenMeteo from {self.base_url}")
            df["temperature"] = [20.0, 22.5]
            return df

    return OpenMeteoAPI(init_context.resource_config["base_url"])


@resource(config_schema={"connection_string": str})
def mongodb_resource(init_context: InitResourceContext) -> Any:
    """Placeholder resource for a MongoDB instance."""
    class MongoDB:
        def __init__(self, conn_str: str):
            self.conn_str = conn_str

        def save(self, collection: str, data: List[Dict]) -> None:
            # Replace with real MongoDB insertion logic
            init_context.log.info(f"Saving {len(data)} records to MongoDB collection '{collection}'")
            # No actual DB operation performed

    return MongoDB(init_context.resource_config["connection_string"])


@resource(config_schema={"base_url": str})
def intertwino_api_resource(init_context: InitResourceContext) -> Any:
    """Placeholder resource for the Intertwino API."""
    class IntertwinoAPI:
        def __init__(self, base_url: str):
            self.base_url = base_url

        def extend_columns(self, df: pd.DataFrame) -> pd.DataFrame:
            # Replace with real column extension logic
            init_context.log.info(f"Extending columns via Intertwino at {self.base_url}")
            df["extra_info"] = ["info1", "info2"]
            return df

    return IntertwinoAPI(init_context.resource_config["base_url"])


@resource(config_schema={"network_name": str})
def docker_network_app_resource(init_context: InitResourceContext) -> Any:
    """Placeholder resource representing a custom Docker network."""
    class DockerNetwork:
        def __init__(self, name: str):
            self.name = name

        def get_name(self) -> str:
            return self.name

    return DockerNetwork(init_context.resource_config["network_name"])


# ----------------------------------------------------------------------
# Op definitions
# ----------------------------------------------------------------------


@op(
    name="load_and_modify_data",
    description="Loads raw data and applies initial modifications using the Load‑and‑Modify service.",
    out=Out(pd.DataFrame),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"load_modify_api"},
)
def load_and_modify_data(context: OpExecutionContext) -> pd.DataFrame:
    """Fetches data from the Load‑and‑Modify API and returns a DataFrame."""
    api = context.resources.load_modify_api
    df = api.fetch_and_modify()
    context.log.info(f"Loaded {len(df)} rows.")
    return df


@op(
    name="reconcile_city_names",
    description="Reconciles city names using the HERE Geocoding service.",
    ins={"df": In(pd.DataFrame)},
    out=Out(pd.DataFrame),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"reconciliation_api"},
)
def reconcile_city_names(context: OpExecutionContext, df: pd.DataFrame) -> pd.DataFrame:
    """Normalizes city names via the reconciliation API."""
    api = context.resources.reconciliation_api
    reconciled_df = api.reconcile(df)
    context.log.info("City names reconciled.")
    return reconciled_df


@op(
    name="enrich_with_openmeteo",
    description="Enriches the dataset with weather information from OpenMeteo.",
    ins={"df": In(pd.DataFrame)},
    out=Out(pd.DataFrame),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"openmeteo_api"},
)
def enrich_with_openmeteo(context: OpExecutionContext, df: pd.DataFrame) -> pd.DataFrame:
    """Adds temperature data from OpenMeteo."""
    api = context.resources.openmeteo_api
    enriched_df = api.enrich(df)
    context.log.info("Weather data added.")
    return enriched_df


@op(
    name="extend_columns",
    description="Extends the DataFrame with additional columns via the Intertwino service.",
    ins={"df": In(pd.DataFrame)},
    out=Out(pd.DataFrame),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"intertwino_api"},
)
def extend_columns(context: OpExecutionContext, df: pd.DataFrame) -> pd.DataFrame:
    """Adds extra columns using the Intertwino API."""
    api = context.resources.intertwino_api
    extended_df = api.extend_columns(df)
    context.log.info("Additional columns added.")
    return extended_df


@op(
    name="save_final_data",
    description="Persists the final DataFrame into MongoDB.",
    ins={"df": In(pd.DataFrame)},
    out=Out(Nothing),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"mongodb"},
)
def save_final_data(context: OpExecutionContext, df: pd.DataFrame) -> None:
    """Writes the final dataset to MongoDB."""
    mongo = context.resources.mongodb
    records = df.to_dict(orient="records")
    mongo.save(collection="final_dataset", data=records)
    context.log.info(f"Saved {len(records)} records to MongoDB.")


# ----------------------------------------------------------------------
# Job definition
# ----------------------------------------------------------------------


@job(
    name="load_and_modify_data_pipeline",
    description="No description provided.",
    resource_defs={
        "io_manager": fs_io_manager,
        "load_modify_api": load_modify_api_resource,
        "reconciliation_api": reconciliation_api_resource,
        "openmeteo_api": openmeteo_api_resource,
        "mongodb": mongodb_resource,
        "intertwino_api": intertwino_api_resource,
        "docker_network_app": docker_network_app_resource,
    },
    executor_def=docker_executor,
)
def load_and_modify_data_pipeline():
    """Sequential pipeline that loads, reconciles, enriches, extends, and saves data."""
    raw_df = load_and_modify_data()
    reconciled_df = reconcile_city_names(raw_df)
    enriched_df = enrich_with_openmeteo(reconciled_df)
    extended_df = extend_columns(enriched_df)
    save_final_data(extended_df)


# ----------------------------------------------------------------------
# Example resource configuration (to be supplied at runtime)
# ----------------------------------------------------------------------
# resources:
#   load_modify_api:
#     config:
#       base_url: "https://api.load-modify.example.com"
#   reconciliation_api:
#     config:
#       base_url: "https://api.reconciliation.example.com"
#   openmeteo_api:
#     config:
#       base_url: "https://api.open-meteo.com"
#   mongodb:
#     config:
#       connection_string: "mongodb://user:pass@host:27017/db"
#   intertwino_api:
#     config:
#       base_url: "https://api.intertwino.example.com"
#   docker_network_app:
#     config:
#       network_name: "app_network"
#   io_manager:
#     config:
#       base_dir: "/tmp/dagster_io"
#
# The above configuration can be placed in a YAML file and passed to Dagster
# via the `dagster job execute` CLI or through Dagster UI.