# Generated by Dagster Code Generator
# Generation Metadata:
# - Job Name: load_and_modify_data_pipeline
# - Description: No description provided.
# - Executor Type: docker_executor
# - IO Manager: fs_io_manager
# - Dagster Version: 1.5.0
# - Use Assets: False
# - Required Resources: data_dir

from dagster import job, op, Out, In, RetryPolicy, fs_io_manager, docker_executor, resource

@resource
def data_dir():
    return "/path/to/data"

@op(
    out={"modified_data": Out()},
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"data_dir"}
)
def load_and_modify_data(context):
    """
    Load and modify data from the specified data directory.
    """
    data_path = context.resources.data_dir
    # Simulate data loading and modification
    modified_data = {"data": "modified"}
    return modified_data

@op(
    ins={"modified_data": In()},
    out={"language_data": Out()},
    retry_policy=RetryPolicy(max_retries=1)
)
def language_detection(context, modified_data):
    """
    Detect the language of the modified data.
    """
    # Simulate language detection
    language_data = {"language": "en"}
    return language_data

@op(
    ins={"language_data": In()},
    out={"sentiment_data": Out()},
    retry_policy=RetryPolicy(max_retries=1)
)
def sentiment_analysis(context, language_data):
    """
    Perform sentiment analysis on the language data.
    """
    # Simulate sentiment analysis
    sentiment_data = {"sentiment": "positive"}
    return sentiment_data

@op(
    ins={"sentiment_data": In()},
    out={"category_data": Out()},
    retry_policy=RetryPolicy(max_retries=1)
)
def category_extraction(context, sentiment_data):
    """
    Extract categories from the sentiment data.
    """
    # Simulate category extraction
    category_data = {"category": "news"}
    return category_data

@op(
    ins={"category_data": In()},
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"data_dir"}
)
def save_final_data(context, category_data):
    """
    Save the final data to the specified data directory.
    """
    data_path = context.resources.data_dir
    # Simulate saving final data
    with open(f"{data_path}/final_data.json", "w") as f:
        f.write(str(category_data))

@job(
    name="load_and_modify_data_pipeline",
    description="No description provided.",
    executor_def=docker_executor,
    resource_defs={"data_dir": data_dir, "io_manager": fs_io_manager}
)
def load_and_modify_data_pipeline():
    """
    Define the load_and_modify_data_pipeline job.
    """
    modified_data = load_and_modify_data()
    language_data = language_detection(modified_data)
    sentiment_data = sentiment_analysis(language_data)
    category_data = category_extraction(sentiment_data)
    save_final_data(category_data)