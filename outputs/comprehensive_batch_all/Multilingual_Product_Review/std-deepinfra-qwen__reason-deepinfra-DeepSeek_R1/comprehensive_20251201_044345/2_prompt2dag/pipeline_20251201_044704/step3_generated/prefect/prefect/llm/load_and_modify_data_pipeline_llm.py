# Generated by Prefect 2.x Code Generator
# Date: 2023-10-05
# Prefect Version: 2.14.0

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.docker import DockerContainer
from prefect.filesystems import LocalFileSystem

# Define the LocalFileSystem blocks
data_dir = LocalFileSystem(basepath="/path/to/data_dir")
json_data = LocalFileSystem(basepath="/path/to/json_data")

@task(retries=1, name="Load and Modify Data")
def load_and_modify_data():
    logger = get_run_logger()
    logger.info("Starting Load and Modify Data task")
    container = DockerContainer(
        image="i2t-backendwithintertwino6-load-and-modify:latest",
        env={
            "DATASET_ID": "2",
            "DATE_COLUMN": "submission_date",
            "TABLE_NAME_PREFIX": "JOT_"
        },
        filesystems=[data_dir, json_data]
    )
    container.run()
    logger.info("Completed Load and Modify Data task")

@task(retries=1, name="Language Detection")
def language_detection():
    logger = get_run_logger()
    logger.info("Starting Language Detection task")
    container = DockerContainer(
        image="jmockit/language-detection",
        env={
            "TEXT_COLUMN": "review_text",
            "LANG_CODE_COLUMN": "language_code",
            "OUTPUT_FILE": "lang_detected_2.json"
        },
        filesystems=[json_data]
    )
    container.run()
    logger.info("Completed Language Detection task")

@task(retries=1, name="Sentiment Analysis")
def sentiment_analysis():
    logger = get_run_logger()
    logger.info("Starting Sentiment Analysis task")
    container = DockerContainer(
        image="huggingface/transformers-inference",
        env={
            "MODEL_NAME": "distilbert-base-uncased-finetuned-sst-2-english",
            "TEXT_COLUMN": "review_text",
            "OUTPUT_COLUMN": "sentiment_score"
        },
        filesystems=[json_data]
    )
    container.run()
    logger.info("Completed Sentiment Analysis task")

@task(retries=1, name="Category Extraction")
def category_extraction():
    logger = get_run_logger()
    logger.info("Starting Category Extraction task")
    container = DockerContainer(
        image="i2t-backendwithintertwino6-column-extension:latest",
        env={
            "EXTENDER_ID": "featureExtractor",
            "TEXT_COLUMN": "review_text",
            "OUTPUT_COLUMN": "mentioned_features"
        },
        filesystems=[json_data]
    )
    container.run()
    logger.info("Completed Category Extraction task")

@task(retries=1, name="Save Final Data")
def save_final_data():
    logger = get_run_logger()
    logger.info("Starting Save Final Data task")
    container = DockerContainer(
        image="i2t-backendwithintertwino6-save:latest",
        env={
            "DATASET_ID": "2"
        },
        filesystems=[data_dir, json_data]
    )
    container.run()
    logger.info("Completed Save Final Data task")

@flow(name="load_and_modify_data_pipeline", task_runner=SequentialTaskRunner())
def load_and_modify_data_pipeline():
    logger = get_run_logger()
    logger.info("Starting load_and_modify_data_pipeline")
    
    load_and_modify_data_result = load_and_modify_data()
    language_detection_result = language_detection(wait_for=[load_and_modify_data_result])
    sentiment_analysis_result = sentiment_analysis(wait_for=[language_detection_result])
    category_extraction_result = category_extraction(wait_for=[sentiment_analysis_result])
    save_final_data_result = save_final_data(wait_for=[category_extraction_result])
    
    logger.info("Completed load_and_modify_data_pipeline")

if __name__ == "__main__":
    load_and_modify_data_pipeline()