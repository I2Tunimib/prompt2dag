# Generated by Dagster Pipeline Generator
# Date: 2024-06-20
# Pipeline: Multilingual Product Review Analysis Pipeline
# Description: Enriches product reviews with language verification, sentiment, and key feature extraction using LLM capabilities for deeper customer insight.

from __future__ import annotations

from typing import Any, Dict, List

from dagster import (
    IOManager,
    In,
    Nothing,
    Out,
    ResourceDefinition,
    RetryPolicy,
    executor,
    job,
    op,
    io_manager,
    ConfigurableResource,
    docker_executor,
)


# ----------------------------------------------------------------------
# Resources
# ----------------------------------------------------------------------


@io_manager
def fs_io_manager(init_context) -> IOManager:
    """Simple filesystem IO manager that writes to a shared data directory.

    The directory path is provided via the ``data_dir`` config field.
    """
    import os
    import json

    class SimpleFSIOManager(IOManager):
        def __init__(self, base_dir: str):
            self.base_dir = base_dir
            os.makedirs(self.base_dir, exist_ok=True)

        def handle_output(self, context, obj):
            file_path = os.path.join(self.base_dir, f"{context.step_key}.json")
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(obj, f, ensure_ascii=False, indent=2)

        def load_input(self, context):
            file_path = os.path.join(self.base_dir, f"{context.upstream_output.step_key}.json")
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)

    return SimpleFSIOManager(init_context.resource_config["data_dir"])


class AppNetworkResource(ConfigurableResource):
    """Placeholder for a custom Docker network resource."""

    network_name: str

    def get_network(self) -> str:
        """Return the Docker network name."""
        return self.network_name


# ----------------------------------------------------------------------
# Ops
# ----------------------------------------------------------------------


@op(
    name="load_and_modify_reviews",
    description="Loads raw product reviews from the shared data directory and applies any required preprocessing.",
    out=Out(List[Dict[str, Any]], description="List of pre‑processed review dictionaries."),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"data_dir_fs"},
)
def load_and_modify_reviews(context) -> List[Dict[str, Any]]:
    """Load raw reviews and perform basic cleaning/modification.

    Returns:
        A list of dictionaries, each representing a single review.
    """
    # Placeholder implementation – replace with real loading logic.
    raw_reviews = [
        {"id": 1, "text": "Great product!"},
        {"id": 2, "text": "No me gustó el producto."},
        {"id": 3, "text": "Produit très bon."},
    ]
    context.log.info(f"Loaded {len(raw_reviews)} reviews.")
    return raw_reviews


@op(
    name="detect_review_language",
    description="Detects the language of each review using an LLM or language detection model.",
    ins={"reviews": In(List[Dict[str, Any]])},
    out=Out(List[Dict[str, Any]], description="Reviews annotated with a 'language' field."),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"app_network"},
)
def detect_review_language(context, reviews: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Add a ``language`` key to each review dictionary."""
    # Placeholder language detection – replace with actual model call.
    for review in reviews:
        text = review["text"]
        if any(word in text.lower() for word in ["great", "product"]):
            review["language"] = "en"
        elif any(word in text.lower() for word in ["no", "gustó"]):
            review["language"] = "es"
        else:
            review["language"] = "fr"
    context.log.info("Language detection completed.")
    return reviews


@op(
    name="analyze_sentiment",
    description="Performs sentiment analysis on each review.",
    ins={"reviews": In(List[Dict[str, Any]])},
    out=Out(List[Dict[str, Any]], description="Reviews annotated with a 'sentiment' field."),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"app_network"},
)
def analyze_sentiment(context, reviews: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Add a ``sentiment`` key (positive/negative/neutral) to each review."""
    # Placeholder sentiment analysis – replace with real LLM call.
    for review in reviews:
        text = review["text"].lower()
        if "great" in text or "bon" in text:
            review["sentiment"] = "positive"
        elif "no" in text or "gustó" in text:
            review["sentiment"] = "negative"
        else:
            review["sentiment"] = "neutral"
    context.log.info("Sentiment analysis completed.")
    return reviews


@op(
    name="extract_review_features",
    description="Extracts key product features mentioned in each review using LLM capabilities.",
    ins={"reviews": In(List[Dict[str, Any]])},
    out=Out(List[Dict[str, Any]], description="Reviews annotated with a 'features' list."),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"app_network"},
)
def extract_review_features(context, reviews: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Add a ``features`` list to each review dictionary."""
    # Placeholder feature extraction – replace with real LLM call.
    for review in reviews:
        text = review["text"].lower()
        features = []
        if "product" in text:
            features.append("product_quality")
        if "price" in text:
            features.append("price")
        if "delivery" in text:
            features.append("delivery")
        review["features"] = features or ["general"]
    context.log.info("Feature extraction completed.")
    return reviews


@op(
    name="save_enriched_reviews",
    description="Persists the enriched reviews back to the shared data directory.",
    ins={"reviews": In(List[Dict[str, Any]])},
    out=Out(Nothing),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"data_dir_fs"},
)
def save_enriched_reviews(context, reviews: List[Dict[str, Any]]) -> None:
    """Write the enriched reviews to a JSON file using the configured IO manager."""
    # The output is handled by the IO manager; we simply log success.
    context.log.info(f"Saving {len(reviews)} enriched reviews.")
    # The actual write is performed by the downstream IO manager when this op returns.
    return None


# ----------------------------------------------------------------------
# Job Definition
# ----------------------------------------------------------------------


@job(
    name="multilingual_product_review_analysis_pipeline",
    description=(
        "Enriches product reviews with language verification, sentiment, and key feature extraction "
        "using LLM capabilities for deeper customer insight."
    ),
    executor_def=docker_executor,
    resource_defs={
        "data_dir_fs": ResourceDefinition(
            resource_fn=fs_io_manager,
            config_schema={"data_dir": str},
        ),
        "app_network": ResourceDefinition(
            resource_fn=lambda _: AppNetworkResource(network_name="my_app_network"),
        ),
        "io_manager": fs_io_manager,
    },
    config={
        "resources": {
            "data_dir_fs": {"config": {"data_dir": "/tmp/shared_data"}},
            "app_network": {"config": {"network_name": "my_app_network"}},
        }
    },
)
def multilingual_product_review_analysis_pipeline():
    """Sequential pipeline that loads reviews, detects language, analyses sentiment,
    extracts key features, and finally saves the enriched data.
    """
    reviews = load_and_modify_reviews()
    lang_reviews = detect_review_language(reviews)
    sentiment_reviews = analyze_sentiment(lang_reviews)
    feature_reviews = extract_review_features(sentiment_reviews)
    save_enriched_reviews(feature_reviews)