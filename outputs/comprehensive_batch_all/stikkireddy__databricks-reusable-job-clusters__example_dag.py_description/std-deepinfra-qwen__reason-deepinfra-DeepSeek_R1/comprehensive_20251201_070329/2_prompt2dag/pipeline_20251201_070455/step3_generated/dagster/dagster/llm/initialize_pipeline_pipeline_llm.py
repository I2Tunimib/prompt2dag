# Generated by Dagster Code Generator
# Generation Metadata:
# - Job Name: initialize_pipeline_pipeline
# - Description: No description provided.
# - Executor Type: docker_executor
# - IO Manager: fs_io_manager
# - Dagster Version: 1.5.0
# - Use Assets: False
# - Required Resources: databricks_default

from dagster import job, op, Out, In, RetryPolicy, in_process_executor, docker_executor, fs_io_manager, resource

# Define the required resources
@resource
def databricks_default():
    """
    Databricks Default Connection resource.
    """
    return None

# Define the ops
@op(
    name="initialize_pipeline",
    description="Initialize Pipeline",
    out=Out(str, description="Initialization message"),
    retry_policy=RetryPolicy(max_retries=0),
    required_resource_keys={"databricks_default"}
)
def initialize_pipeline(context):
    """
    Initialize the pipeline.
    """
    context.log.info("Pipeline initialized")
    return "Pipeline initialized"

@op(
    name="execute_primary_notebook",
    description="Execute Primary Notebook",
    ins={"init_message": In(str, description="Initialization message")},
    out=Out(str, description="Primary notebook execution result"),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"databricks_default"}
)
def execute_primary_notebook(context, init_message):
    """
    Execute the primary notebook.
    """
    context.log.info(f"Executing primary notebook with message: {init_message}")
    return "Primary notebook executed"

@op(
    name="intermediate_step_1",
    description="Intermediate Step 1",
    ins={"primary_result": In(str, description="Primary notebook execution result")},
    out=Out(str, description="Intermediate step 1 result"),
    retry_policy=RetryPolicy(max_retries=0),
    required_resource_keys={"databricks_default"}
)
def intermediate_step_1(context, primary_result):
    """
    Perform intermediate step 1.
    """
    context.log.info(f"Intermediate step 1 with result: {primary_result}")
    return "Intermediate step 1 completed"

@op(
    name="branch_decision",
    description="Branch Decision",
    ins={"intermediate_result": In(str, description="Intermediate step 1 result")},
    out=Out(bool, description="Branch decision result"),
    retry_policy=RetryPolicy(max_retries=0),
    required_resource_keys={"databricks_default"}
)
def branch_decision(context, intermediate_result):
    """
    Make a branch decision.
    """
    context.log.info(f"Branch decision with result: {intermediate_result}")
    return True  # Example decision, can be dynamic

@op(
    name="execute_secondary_notebook",
    description="Execute Secondary Notebook",
    ins={"branch_result": In(bool, description="Branch decision result")},
    out=Out(str, description="Secondary notebook execution result"),
    retry_policy=RetryPolicy(max_retries=1),
    required_resource_keys={"databricks_default"}
)
def execute_secondary_notebook(context, branch_result):
    """
    Execute the secondary notebook.
    """
    context.log.info(f"Executing secondary notebook with decision: {branch_result}")
    return "Secondary notebook executed"

@op(
    name="terminal_branch_task",
    description="Terminal Branch Task",
    ins={"branch_result": In(bool, description="Branch decision result")},
    out=Out(str, description="Terminal branch task result"),
    retry_policy=RetryPolicy(max_retries=0),
    required_resource_keys={"databricks_default"}
)
def terminal_branch_task(context, branch_result):
    """
    Perform the terminal branch task.
    """
    context.log.info(f"Terminal branch task with decision: {branch_result}")
    return "Terminal branch task completed"

@op(
    name="intermediate_step_2",
    description="Intermediate Step 2",
    ins={"secondary_result": In(str, description="Secondary notebook execution result")},
    out=Out(str, description="Intermediate step 2 result"),
    retry_policy=RetryPolicy(max_retries=0),
    required_resource_keys={"databricks_default"}
)
def intermediate_step_2(context, secondary_result):
    """
    Perform intermediate step 2.
    """
    context.log.info(f"Intermediate step 2 with result: {secondary_result}")
    return "Intermediate step 2 completed"

@op(
    name="pipeline_completion",
    description="Pipeline Completion",
    ins={"final_result": In(str, description="Intermediate step 2 result")},
    out=Out(str, description="Pipeline completion message"),
    retry_policy=RetryPolicy(max_retries=0),
    required_resource_keys={"databricks_default"}
)
def pipeline_completion(context, final_result):
    """
    Complete the pipeline.
    """
    context.log.info(f"Pipeline completed with result: {final_result}")
    return "Pipeline completed"

# Define the job
@job(
    name="initialize_pipeline_pipeline",
    description="No description provided.",
    executor_def=docker_executor,
    resource_defs={"databricks_default": databricks_default, "io_manager": fs_io_manager},
)
def initialize_pipeline_pipeline():
    """
    Define the pipeline with the specified tasks and dependencies.
    """
    init_message = initialize_pipeline()
    primary_result = execute_primary_notebook(init_message)
    intermediate_result = intermediate_step_1(primary_result)
    branch_result = branch_decision(intermediate_result)
    terminal_branch_task_result = terminal_branch_task(branch_result)
    secondary_result = execute_secondary_notebook(branch_result)
    intermediate_step_2_result = intermediate_step_2(secondary_result)
    pipeline_completion(intermediate_step_2_result)