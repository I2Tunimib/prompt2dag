metadata:
  target_orchestrator: dagster
  generated_at: 2025-12-02 13:41:15.459406
  source_analysis_file: 
    Pipeline_Description_Dataset/stikkireddy__databricks-reusable-job-clusters__example_dag.py_description.txt
  pipeline_name: initialize_pipeline_pipeline
  pipeline_description: No description provided.
  orchestrator_specific:
    job_name: initialize_pipeline_pipeline
    description: No description provided.
    executor_type: docker_executor
    io_manager: fs_io_manager
    dagster_version: 1.5.0
    use_assets: false
    required_resources:
      - databricks_default
schedule:
  enabled: false
  schedule_expression:
  start_date: '2023-06-06T00:00:00Z'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: databricks_default
    conn_type: resource
    description: Databricks Default Connection
    config:
      resource_type: resource
      resource_module: dagster
      resource_key: databricks_default
      config:
        base_url: https://<databricks-instance>.cloud.databricks.com
        protocol: https
        host: <databricks-instance>.cloud.databricks.com
        port: 443
        token: EnvVar('DATABRICKS_TOKEN')
tasks:
  - task_id: initialize_pipeline
    task_name: Initialize Pipeline
    operator_class: Op
    operator_module: dagster
    component_ref: initialize_pipeline
    config:
      op_decorator: '@op'
      executor:
        type: in_process_executor
        module: dagster
        config: {}
      config_schema: {}
      required_resource_keys: []
      ins: []
      outs: []
    upstream_task_ids: []
    trigger_rule: default
    retries: 0
    retry_delay_seconds: 0
    validation_warnings: []
  - task_id: execute_primary_notebook
    task_name: Execute Primary Notebook
    operator_class: Op
    operator_module: dagster
    component_ref: execute_primary_notebook
    config:
      op_decorator: '@op'
      executor:
        type: in_process_executor
        module: dagster
        config:
          compute_fn: databricks_submit_run_operator.submit_run
      config_schema: {}
      required_resource_keys:
        - databricks_default
      retry_policy:
        max_retries: 1
        delay: 300
        backoff: CONSTANT
      ins:
        - name: databricks_notebook
          dagster_type: String
          description: /Users/sri.tikkireddy@databricks.com/workflow-mirroring/helloworld
      outs: []
    upstream_task_ids:
      - initialize_pipeline
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: intermediate_step_1
    task_name: Intermediate Step 1
    operator_class: Op
    operator_module: dagster
    component_ref: intermediate_step_1
    config:
      op_decorator: '@op'
      executor:
        type: in_process_executor
        module: dagster
        config: {}
      config_schema: {}
      required_resource_keys: []
      ins: []
      outs: []
    upstream_task_ids:
      - execute_primary_notebook
    trigger_rule: default
    retries: 0
    retry_delay_seconds: 0
    validation_warnings: []
  - task_id: branch_decision
    task_name: Branch Decision
    operator_class: Op
    operator_module: dagster
    component_ref: branch_decision
    config:
      op_decorator: '@op'
      executor:
        type: in_process_executor
        module: dagster
        config:
          compute_fn: branch_python_operator.branch_func
      config_schema: {}
      required_resource_keys: []
      ins: []
      outs: []
    upstream_task_ids:
      - intermediate_step_1
    trigger_rule: default
    retries: 0
    retry_delay_seconds: 0
    validation_warnings: []
  - task_id: terminal_branch_path_1
    task_name: Terminal Branch Path 1
    operator_class: Op
    operator_module: dagster
    component_ref: terminal_branch_path_1
    config:
      op_decorator: '@op'
      executor:
        type: in_process_executor
        module: dagster
        config: {}
      config_schema: {}
      required_resource_keys: []
      ins: []
      outs: []
    upstream_task_ids:
      - branch_decision
    trigger_rule: default
    retries: 0
    retry_delay_seconds: 0
    validation_warnings: []
  - task_id: execute_secondary_notebook
    task_name: Execute Secondary Notebook
    operator_class: Op
    operator_module: dagster
    component_ref: execute_secondary_notebook
    config:
      op_decorator: '@op'
      executor:
        type: in_process_executor
        module: dagster
        config:
          compute_fn: databricks_submit_run_operator.submit_run
      config_schema: {}
      required_resource_keys:
        - databricks_default
      retry_policy:
        max_retries: 1
        delay: 300
        backoff: CONSTANT
      ins:
        - name: databricks_notebook
          dagster_type: String
          description: /Users/sri.tikkireddy@databricks.com/workflow-mirroring/helloworld
      outs: []
    upstream_task_ids:
      - branch_decision
    trigger_rule: default
    retries: 1
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: intermediate_step_2
    task_name: Intermediate Step 2
    operator_class: Op
    operator_module: dagster
    component_ref: intermediate_step_2
    config:
      op_decorator: '@op'
      executor:
        type: in_process_executor
        module: dagster
        config: {}
      config_schema: {}
      required_resource_keys: []
      ins: []
      outs: []
    upstream_task_ids:
      - execute_secondary_notebook
    trigger_rule: default
    retries: 0
    retry_delay_seconds: 0
    validation_warnings: []
  - task_id: pipeline_completion
    task_name: Pipeline Completion
    operator_class: Op
    operator_module: dagster
    component_ref: pipeline_completion
    config:
      op_decorator: '@op'
      executor:
        type: in_process_executor
        module: dagster
        config: {}
      config_schema: {}
      required_resource_keys: []
      ins: []
      outs: []
    upstream_task_ids:
      - intermediate_step_2
    trigger_rule: default
    retries: 0
    retry_delay_seconds: 0
    validation_warnings: []
