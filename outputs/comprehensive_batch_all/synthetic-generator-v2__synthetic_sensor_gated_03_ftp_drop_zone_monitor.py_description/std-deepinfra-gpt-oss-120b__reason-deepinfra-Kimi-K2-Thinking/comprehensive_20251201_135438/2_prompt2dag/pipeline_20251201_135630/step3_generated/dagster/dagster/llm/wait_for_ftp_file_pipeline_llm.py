# Generated by Dagster Code Generator
# Date: 2024-06-28
# Pipeline: wait_for_ftp_file_pipeline
# Description: No description provided.
# Executor: in_process_executor
# Resources: ftp_server, internal_inventory_db, local_tmp_filesystem (fs_io_manager)

from dagster import (
    op,
    job,
    In,
    Out,
    RetryPolicy,
    ResourceDefinition,
    fs_io_manager,
    in_process_executor,
    ScheduleDefinition,
    ScheduleStatus,
    ConfigurableResource,
    InitResourceContext,
    get_dagster_logger,
)

# ----------------------------------------------------------------------
# Resource Definitions
# ----------------------------------------------------------------------


class FTPServerResource(ConfigurableResource):
    """Resource for connecting to the vendor FTP server."""

    host: str
    username: str
    password: str
    port: int = 21

    def get_connection(self):
        """Create and return an FTP connection object."""
        # Placeholder implementation – replace with actual FTP client logic.
        logger = get_dagster_logger()
        logger.info(f"Connecting to FTP server {self.host}:{self.port} as {self.username}")
        return {"host": self.host, "port": self.port, "user": self.username}


class InternalInventoryDBResource(ConfigurableResource):
    """Resource for interacting with the internal inventory database."""

    connection_string: str

    def get_connection(self):
        """Create and return a DB connection object."""
        # Placeholder implementation – replace with actual DB client logic.
        logger = get_dagster_logger()
        logger.info(f"Connecting to internal inventory DB at {self.connection_string}")
        return {"connection_string": self.connection_string}


# ----------------------------------------------------------------------
# Op Definitions
# ----------------------------------------------------------------------


@op(
    name="wait_for_ftp_file",
    description="Polls the FTP server until the expected file appears.",
    out=Out(str, description="Remote path of the file on the FTP server."),
    retry_policy=RetryPolicy(max_retries=2),
)
def wait_for_ftp_file(context: InitResourceContext, ftp_server: FTPServerResource) -> str:
    """Wait for a specific file to be present on the vendor FTP server.

    Returns:
        str: The remote file path on the FTP server.
    """
    logger = context.log
    conn = ftp_server.get_connection()
    # Placeholder polling logic – replace with real implementation.
    remote_path = "/incoming/vendor_data.csv"
    logger.info(f"Detected file at {remote_path} on FTP server {conn['host']}")
    return remote_path


@op(
    name="download_vendor_file",
    description="Downloads the vendor file from the FTP server to local storage.",
    ins={"remote_path": In(str)},
    out=Out(str, description="Local filesystem path of the downloaded file."),
    retry_policy=RetryPolicy(max_retries=2),
)
def download_vendor_file(
    context: InitResourceContext,
    remote_path: str,
    ftp_server: FTPServerResource,
) -> str:
    """Download the vendor file from the FTP server.

    Args:
        remote_path: Path of the file on the FTP server.

    Returns:
        str: Local path where the file was saved.
    """
    logger = context.log
    conn = ftp_server.get_connection()
    # Placeholder download logic – replace with real FTP download.
    local_path = f"/tmp/vendor_data_{context.run_id}.csv"
    logger.info(f"Downloading {remote_path} from FTP {conn['host']} to {local_path}")
    # Simulate file creation
    with open(local_path, "w") as f:
        f.write("id,name,quantity\n1,Widget,100\n")
    return local_path


@op(
    name="cleanse_vendor_data",
    description="Cleanses and validates the downloaded vendor data.",
    ins={"local_path": In(str)},
    out=Out(str, description="Path to the cleansed data file."),
    retry_policy=RetryPolicy(max_retries=2),
)
def cleanse_vendor_data(context: InitResourceContext, local_path: str) -> str:
    """Perform data cleansing on the downloaded vendor file.

    Args:
        local_path: Path to the raw vendor file.

    Returns:
        str: Path to the cleansed data file.
    """
    logger = context.log
    cleansed_path = f"{local_path}.cleansed"
    logger.info(f"Cleansing data from {local_path} into {cleansed_path}")
    # Placeholder cleansing – copy file for demo purposes.
    with open(local_path, "r") as src, open(cleansed_path, "w") as dst:
        for line in src:
            dst.write(line.strip() + "\n")
    return cleansed_path


@op(
    name="merge_with_internal_inventory",
    description="Merges the cleansed vendor data with the internal inventory database.",
    ins={"cleansed_path": In(str)},
    out=Out(str, description="Result summary of the merge operation."),
    retry_policy=RetryPolicy(max_retries=2),
)
def merge_with_internal_inventory(
    context: InitResourceContext,
    cleansed_path: str,
    internal_inventory_db: InternalInventoryDBResource,
) -> str:
    """Merge cleansed vendor data into the internal inventory system.

    Args:
        cleansed_path: Path to the cleansed vendor data file.

    Returns:
        str: Summary message of the merge operation.
    """
    logger = context.log
    db_conn = internal_inventory_db.get_connection()
    logger.info(f"Merging data from {cleansed_path} into internal DB {db_conn['connection_string']}")
    # Placeholder merge logic – replace with actual DB operations.
    summary = f"Successfully merged data from {cleansed_path} into internal inventory."
    logger.info(summary)
    return summary


# ----------------------------------------------------------------------
# Job Definition
# ----------------------------------------------------------------------


@job(
    name="wait_for_ftp_file_pipeline",
    description="No description provided.",
    resource_defs={
        "ftp_server": FTPServerResource,
        "internal_inventory_db": InternalInventoryDBResource,
        "io_manager": fs_io_manager,
    },
    executor_def=in_process_executor,
)
def wait_for_ftp_file_job():
    """Dagster job orchestrating the FTP file ingestion pipeline."""
    # Step 1: Wait for the file to appear on the FTP server.
    remote_path = wait_for_ftp_file(ftp_server=ftp_server)

    # Step 2: Download the file once it is available.
    local_path = download_vendor_file(remote_path, ftp_server=ftp_server)

    # Step 3: Cleanse the downloaded data.
    cleansed_path = cleanse_vendor_data(local_path)

    # Step 4: Merge the cleansed data with the internal inventory.
    merge_with_internal_inventory(cleansed_path, internal_inventory_db=internal_inventory_db)


# ----------------------------------------------------------------------
# Schedule Definition
# ----------------------------------------------------------------------


daily_ftp_ingest_schedule = ScheduleDefinition(
    job=wait_for_ftp_file_job,
    cron_schedule="0 0 * * *",  # @daily in UTC
    execution_timezone="UTC",
    default_status=ScheduleStatus.RUNNING,
    description="Daily execution of the FTP ingestion pipeline.",
    catchup=False,
)

# ----------------------------------------------------------------------
# End of generated pipeline
# ----------------------------------------------------------------------