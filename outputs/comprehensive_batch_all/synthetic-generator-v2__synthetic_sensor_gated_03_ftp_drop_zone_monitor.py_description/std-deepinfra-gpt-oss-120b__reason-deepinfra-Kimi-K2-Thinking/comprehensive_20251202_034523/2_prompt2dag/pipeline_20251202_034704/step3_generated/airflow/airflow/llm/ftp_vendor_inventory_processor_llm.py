# Generated by Airflow DAG generator on 2024-06-13
"""
DAG: ftp_vendor_inventory_processor
Description: No description provided.
Pattern: sequential
"""

from datetime import datetime, timedelta
from pathlib import Path
import logging
import json

from airflow import DAG
from airflow.decorators import task
from airflow.exceptions import AirflowException
from airflow.providers.ftp.hooks.ftp import FTPHook
from airflow.providers.common.sql.hooks.sql import DbApiHook

# Default arguments applied to all tasks
DEFAULT_ARGS = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 0,  # individual tasks set their own retry count
    "retry_delay": timedelta(minutes=5),
}

# DAG definition
with DAG(
    dag_id="ftp_vendor_inventory_processor",
    description="No description provided.",
    schedule_interval="@daily",
    start_date=datetime(2024, 1, 1),
    catchup=False,
    default_args=DEFAULT_ARGS,
    tags=["vendor", "inventory", "ftp"],
    is_paused_upon_creation=True,  # Disabled by default
    max_active_runs=1,
    timezone="UTC",
) as dag:

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def wait_for_ftp_file(file_path: str = "/incoming/vendor_inventory.csv", timeout: int = 300) -> str:
        """
        Poll the FTP server until the expected file appears or timeout is reached.
        Returns the remote file path when found.
        """
        ftp_hook = FTPHook(ftp_conn_id="ftp_server_connection")
        start = datetime.utcnow()
        while (datetime.utcnow() - start).seconds < timeout:
            try:
                files = ftp_hook.list_directory(Path(file_path).parent.as_posix())
                if Path(file_path).name in files:
                    logging.info("File %s found on FTP server.", file_path)
                    return file_path
                logging.info("File %s not yet available. Retrying...", file_path)
            except Exception as exc:
                logging.error("Error while listing FTP directory: %s", exc)
                raise AirflowException(f"FTP listing failed: {exc}")

            # Simple backâ€‘off
            time.sleep(10)

        raise AirflowException(f"Timeout reached while waiting for {file_path} on FTP server.")

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def download_vendor_file(remote_path: str) -> str:
        """
        Downloads the vendor file from the FTP server to a local temporary directory.
        Returns the local file path.
        """
        ftp_hook = FTPHook(ftp_conn_id="ftp_server_connection")
        local_tmp_dir = Path("/tmp/ftp_vendor_inventory")
        local_tmp_dir.mkdir(parents=True, exist_ok=True)
        local_path = local_tmp_dir / Path(remote_path).name

        try:
            logging.info("Downloading %s to %s", remote_path, local_path)
            ftp_hook.retrieve_file(remote_path, str(local_path))
            logging.info("Download completed.")
            return str(local_path)
        except Exception as exc:
            logging.error("Failed to download %s: %s", remote_path, exc)
            raise AirflowException(f"Download failed: {exc}")

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def cleanse_vendor_data(local_file_path: str) -> str:
        """
        Performs basic cleansing on the downloaded CSV file.
        Returns the path to the cleansed file.
        """
        import pandas as pd

        cleansed_path = Path(local_file_path).with_name("cleansed_" + Path(local_file_path).name)

        try:
            df = pd.read_csv(local_file_path)
            logging.info("Original rows: %d", len(df))

            # Example cleansing steps
            df.dropna(subset=["product_id", "quantity"], inplace=True)
            df["quantity"] = pd.to_numeric(df["quantity"], errors="coerce").fillna(0).astype(int)
            df["price"] = pd.to_numeric(df["price"], errors="coerce").fillna(0.0)

            df.to_csv(cleansed_path, index=False)
            logging.info("Cleansed rows: %d", len(df))
            return str(cleansed_path)
        except Exception as exc:
            logging.error("Data cleansing failed: %s", exc)
            raise AirflowException(f"Cleansing failed: {exc}")

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def merge_with_internal_inventory(cleansed_file_path: str) -> None:
        """
        Merges the cleansed vendor data with the internal inventory database.
        """
        import pandas as pd

        try:
            # Load cleansed data
            vendor_df = pd.read_csv(cleansed_file_path)

            # Connect to internal inventory DB
            db_hook = DbApiHook(conn_id="internal_inventory_db")
            engine = db_hook.get_sqlalchemy_engine()

            with engine.begin() as conn:
                # Load current inventory into a DataFrame
                internal_df = pd.read_sql_table("inventory", conn)

                # Example merge logic: upsert based on product_id
                merged_df = pd.concat([internal_df, vendor_df]).drop_duplicates(
                    subset=["product_id"], keep="last"
                )

                # Replace the table with merged data
                merged_df.to_sql("inventory", conn, if_exists="replace", index=False)
                logging.info("Inventory merge completed. Total rows: %d", len(merged_df))

        except Exception as exc:
            logging.error("Merging with internal inventory failed: %s", exc)
            raise AirflowException(f"Merge failed: {exc}")

    # -------------------------------------------------------------------------
    # Task orchestration
    # -------------------------------------------------------------------------
    remote_file = wait_for_ftp_file()
    local_file = download_vendor_file(remote_file)
    cleansed_file = cleanse_vendor_data(local_file)
    merge_with_internal_inventory(cleansed_file)

    # Define explicit dependencies (optional, as TaskFlow API already chains)
    wait_for_ftp_file >> download_vendor_file >> cleanse_vendor_data >> merge_with_internal_inventory