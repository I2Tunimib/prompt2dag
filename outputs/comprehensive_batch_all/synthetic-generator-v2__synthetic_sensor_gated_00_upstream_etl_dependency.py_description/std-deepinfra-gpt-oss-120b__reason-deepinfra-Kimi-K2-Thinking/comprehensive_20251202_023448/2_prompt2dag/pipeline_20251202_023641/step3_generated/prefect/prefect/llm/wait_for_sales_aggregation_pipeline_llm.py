# Generated by Prefect Pipeline Generator
# Pipeline: wait_for_sales_aggregation_pipeline
# Generation Date: 2024-06-13
# Prefect version: 2.14.0

import os
import time
import subprocess
import pandas as pd
import smtplib
from email.message import EmailMessage

from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from prefect.deployments import DeploymentSpec
from prefect.server.schemas.schedules import CronSchedule
from prefect.filesystems import LocalFileSystem
from prefect.blocks.system import Secret


# -------------------------------------------------------------------------
# Block references (configured in Prefect UI / CLI)
# -------------------------------------------------------------------------
# Local filesystem block that points to the directory containing aggregated CSVs
AGGREGATED_SALES_BLOCK = LocalFileSystem.load("aggregated_sales_csv")
# Secret block that stores SMTP credentials as a JSON string:
# {"host": "...", "port": 587, "username": "...", "password": "...", "from_email": "...", "to_email": "..."}
SMTP_SECRET = Secret.load("email_smtp")


@task(retries=0, name="Wait for Sales Aggregation DAG")
def wait_for_sales_aggregation() -> str:
    """
    Placeholder task that waits for an external sales aggregation DAG to finish.
    In a real environment this could poll Airflow, check a flag file, or invoke a CLI.
    Returns the path to the generated CSV file.
    """
    logger = get_run_logger()
    logger.info("Waiting for sales aggregation to complete...")

    # Example implementation: wait for a sentinel file to appear.
    sentinel_path = os.path.join(AGGREGATED_SALES_BLOCK.basepath, "aggregation_complete.txt")
    timeout_seconds = 60 * 30  # 30 minutes
    poll_interval = 30

    elapsed = 0
    while elapsed < timeout_seconds:
        if os.path.isfile(sentinel_path):
            logger.info("Aggregation sentinel file detected.")
            break
        logger.debug(f"Sentinel not found, sleeping {poll_interval}s...")
        time.sleep(poll_interval)
        elapsed += poll_interval
    else:
        raise TimeoutError("Timed out waiting for sales aggregation to complete.")

    # Assume the aggregated CSV is named `aggregated_sales.csv` in the same directory
    csv_path = os.path.join(AGGREGATED_SALES_BLOCK.basepath, "aggregated_sales.csv")
    if not os.path.isfile(csv_path):
        raise FileNotFoundError(f"Aggregated sales CSV not found at {csv_path}")

    logger.info(f"Aggregated sales CSV located at {csv_path}")
    return csv_path


@task(retries=2, name="Load Aggregated Sales CSV")
def load_sales_csv(csv_path: str) -> pd.DataFrame:
    """
    Loads the aggregated sales CSV into a pandas DataFrame.
    """
    logger = get_run_logger()
    logger.info(f"Loading CSV from {csv_path}")

    try:
        df = pd.read_csv(csv_path)
        logger.info(f"Loaded {len(df)} rows.")
        return df
    except Exception as exc:
        logger.error(f"Failed to load CSV: {exc}")
        raise


@task(retries=2, name="Generate Executive Dashboard")
def generate_dashboard(df: pd.DataFrame) -> str:
    """
    Generates a simple executive dashboard (summary CSV) and emails it.
    Returns the path to the generated dashboard file.
    """
    logger = get_run_logger()
    logger.info("Generating executive dashboard summary...")

    # Simple aggregation: total sales per region
    summary = (
        df.groupby("region")["sales_amount"]
        .sum()
        .reset_index()
        .rename(columns={"sales_amount": "total_sales"})
    )

    dashboard_path = os.path.join(AGGREGATED_SALES_BLOCK.basepath, "executive_dashboard.csv")
    summary.to_csv(dashboard_path, index=False)
    logger.info(f"Dashboard written to {dashboard_path}")

    # Email the dashboard
    try:
        smtp_config = SMTP_SECRET.get()
        # Expecting JSON string; parse it
        import json

        cfg = json.loads(smtp_config)
        host = cfg["host"]
        port = cfg["port"]
        username = cfg["username"]
        password = cfg["password"]
        from_email = cfg["from_email"]
        to_email = cfg["to_email"]

        msg = EmailMessage()
        msg["Subject"] = "Executive Sales Dashboard"
        msg["From"] = from_email
        msg["To"] = to_email
        msg.set_content("Please find attached the latest executive sales dashboard.")

        with open(dashboard_path, "rb") as f:
            file_data = f.read()
            file_name = os.path.basename(dashboard_path)
        msg.add_attachment(
            file_data,
            maintype="text",
            subtype="csv",
            filename=file_name,
        )

        with smtplib.SMTP(host, port) as server:
            server.starttls()
            server.login(username, password)
            server.send_message(msg)

        logger.info("Dashboard email sent successfully.")
    except Exception as exc:
        logger.error(f"Failed to send dashboard email: {exc}")
        raise

    return dashboard_path


@flow(
    name="wait_for_sales_aggregation_pipeline",
    task_runner=SequentialTaskRunner(),
)
def wait_for_sales_aggregation_pipeline() -> None:
    """
    Orchestrates the sales aggregation pipeline:
    1. Waits for the external aggregation DAG.
    2. Loads the resulting CSV.
    3. Generates and emails an executive dashboard.
    """
    csv_path = wait_for_sales_aggregation()
    df = load_sales_csv(csv_path)
    generate_dashboard(df)


# -------------------------------------------------------------------------
# Deployment specification
# -------------------------------------------------------------------------
DeploymentSpec(
    name="wait_for_sales_aggregation_pipeline_deployment",
    flow=wait_for_sales_aggregation_pipeline,
    schedule=CronSchedule(cron="0 0 * * *", timezone="UTC"),  # @daily UTC
    tags=["sales", "aggregation"],
    parameters={},
    work_pool_name="default-agent-pool",
    enforce_parameter_schema=False,
    description="Deployment for the wait_for_sales_aggregation_pipeline.",
    catchup=False,
)