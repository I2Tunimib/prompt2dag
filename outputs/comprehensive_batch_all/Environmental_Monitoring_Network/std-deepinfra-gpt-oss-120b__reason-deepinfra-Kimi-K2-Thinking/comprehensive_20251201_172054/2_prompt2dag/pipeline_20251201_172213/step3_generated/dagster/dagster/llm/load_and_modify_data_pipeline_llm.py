# Generated by Dagster Pipeline Generator
# Date: 2024-06-13
# Pipeline: load_and_modify_data_pipeline
# Description: No description provided.
# Executor: docker_executor
# Dagster version: 1.5.0

from typing import Any, Dict

from dagster import (
    IOManager,
    In,
    Out,
    RetryPolicy,
    ResourceDefinition,
    io_manager,
    job,
    op,
    resource,
    executor,
)
from dagster_docker import docker_executor  # type: ignore


# ----------------------------------------------------------------------
# IO Manager
# ----------------------------------------------------------------------
@io_manager(config_schema={"base_dir": str})
def fs_io_manager(init_context) -> IOManager:
    """Simple filesystem IO manager that writes/reads JSON files to a base directory."""
    import json
    import os

    base_dir = init_context.resource_config["base_dir"]

    class SimpleFSIOManager(IOManager):
        def _path(self, key: str) -> str:
            return os.path.join(base_dir, f"{key}.json")

        def handle_output(self, context, obj: Any) -> None:
            path = self._path(context.step_key)
            os.makedirs(os.path.dirname(path), exist_ok=True)
            with open(path, "w", encoding="utf-8") as f:
                json.dump(obj, f)

        def load_input(self, context) -> Any:
            path = self._path(context.upstream_output.step_key)
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)

    return SimpleFSIOManager()


# ----------------------------------------------------------------------
# Resource Stubs
# ----------------------------------------------------------------------
@resource(config_schema={})
def load_modify_api_resource(_):
    """Stub for Load & Modify Service API."""
    class LoadModifyAPI:
        def process(self, data: Dict) -> Dict:
            # Placeholder implementation
            data["load_modify"] = "processed"
            return data

    return LoadModifyAPI()


@resource(config_schema={})
def reconciliation_api_resource(_):
    """Stub for Reconciliation Service API."""
    class ReconciliationAPI:
        def reconcile(self, data: Dict) -> Dict:
            data["reconciliation"] = "done"
            return data

    return ReconciliationAPI()


@resource(config_schema={})
def openmeteo_api_resource(_):
    """Stub for OpenMeteo Service API."""
    class OpenMeteoAPI:
        def extend(self, data: Dict) -> Dict:
            data["openmeteo"] = "extended"
            return data

    return OpenMeteoAPI()


@resource(config_schema={})
def geoapify_api_resource(_):
    """Stub for Geoapify Land Use API."""
    class GeoapifyAPI:
        def extend(self, data: Dict) -> Dict:
            data["geoapify"] = "land_use_added"
            return data

    return GeoapifyAPI()


@resource(config_schema={})
def worldpop_api_resource(_):
    """Stub for WorldPop Demographic Service API."""
    class WorldPopAPI:
        def extend(self, data: Dict) -> Dict:
            data["worldpop"] = "population_density_added"
            return data

    return WorldPopAPI()


@resource(config_schema={})
def column_extension_api_resource(_):
    """Stub for Column Extension Service API."""
    class ColumnExtensionAPI:
        def calculate(self, data: Dict) -> Dict:
            data["environmental_risk"] = "calculated"
            return data

    return ColumnExtensionAPI()


@resource(config_schema={})
def save_service_api_resource(_):
    """Stub for Save Service API."""
    class SaveServiceAPI:
        def save(self, data: Dict) -> None:
            # In a real implementation this would persist data somewhere.
            pass

    return SaveServiceAPI()


@resource(config_schema={})
def mongodb_resource(_):
    """Stub for MongoDB resource."""
    class MongoDB:
        def insert(self, collection: str, document: Dict) -> None:
            # Placeholder for MongoDB insert.
            pass

    return MongoDB()


@resource(config_schema={})
def intertwino_api_resource(_):
    """Stub for Intertwino API."""
    class IntertwinoAPI:
        def enrich(self, data: Dict) -> Dict:
            data["intertwino"] = "enriched"
            return data

    return IntertwinoAPI()


@resource(config_schema={})
def app_network_resource(_):
    """Stub for custom Docker network resource."""
    class AppNetwork:
        name = "custom_network"

    return AppNetwork()


# ----------------------------------------------------------------------
# Operations
# ----------------------------------------------------------------------
@op(
    name="load_and_modify_data",
    required_resource_keys={"load_modify_api", "shared_filesystem"},
    out=Out(Dict),
    retry_policy=RetryPolicy(max_retries=1),
)
def load_and_modify_data(context) -> Dict:
    """
    Load raw data and apply initial modifications using the Load & Modify Service.
    """
    api = context.resources.load_modify_api
    # In a real scenario, raw data would be fetched here.
    raw_data = {"raw": "data"}
    processed = api.process(raw_data)
    context.log.info("Load & Modify completed.")
    return processed


@op(
    name="geocode_reconciliation",
    required_resource_keys={"reconciliation_api", "shared_filesystem"},
    ins={"data": In(Dict)},
    out=Out(Dict),
    retry_policy=RetryPolicy(max_retries=1),
)
def geocode_reconciliation(context, data: Dict) -> Dict:
    """
    Perform geocoding reconciliation on the dataset.
    """
    api = context.resources.reconciliation_api
    reconciled = api.reconcile(data)
    context.log.info("Geocoding reconciliation completed.")
    return reconciled


@op(
    name="openmeteo_extension",
    required_resource_keys={"openmeteo_api", "shared_filesystem"},
    ins={"data": In(Dict)},
    out=Out(Dict),
    retry_policy=RetryPolicy(max_retries=1),
)
def openmeteo_extension(context, data: Dict) -> Dict:
    """
    Extend dataset with OpenMeteo weather data.
    """
    api = context.resources.openmeteo_api
    extended = api.extend(data)
    context.log.info("OpenMeteo extension completed.")
    return extended


@op(
    name="land_use_extension",
    required_resource_keys={"geoapify_api", "shared_filesystem"},
    ins={"data": In(Dict)},
    out=Out(Dict),
    retry_policy=RetryPolicy(max_retries=1),
)
def land_use_extension(context, data: Dict) -> Dict:
    """
    Add land use information using the Geoapify API.
    """
    api = context.resources.geoapify_api
    extended = api.extend(data)
    context.log.info("Land use extension completed.")
    return extended


@op(
    name="population_density_extension",
    required_resource_keys={"worldpop_api", "shared_filesystem"},
    ins={"data": In(Dict)},
    out=Out(Dict),
    retry_policy=RetryPolicy(max_retries=1),
)
def population_density_extension(context, data: Dict) -> Dict:
    """
    Enrich dataset with population density data from WorldPop.
    """
    api = context.resources.worldpop_api
    extended = api.extend(data)
    context.log.info("Population density extension completed.")
    return extended


@op(
    name="calculate_environmental_risk",
    required_resource_keys={"column_extension_api", "shared_filesystem"},
    ins={"data": In(Dict)},
    out=Out(Dict),
    retry_policy=RetryPolicy(max_retries=1),
)
def calculate_environmental_risk(context, data: Dict) -> Dict:
    """
    Compute environmental risk scores using the Column Extension Service.
    """
    api = context.resources.column_extension_api
    calculated = api.calculate(data)
    context.log.info("Environmental risk calculation completed.")
    return calculated


@op(
    name="save_final_data",
    required_resource_keys={"save_service_api", "mongodb", "shared_filesystem"},
    ins={"data": In(Dict)},
    out=Out(None),
    retry_policy=RetryPolicy(max_retries=1),
)
def save_final_data(context, data: Dict) -> None:
    """
    Persist the final dataset using the Save Service and store metadata in MongoDB.
    """
    saver = context.resources.save_service_api
    db = context.resources.mongodb

    saver.save(data)
    db.insert(collection="final_dataset", document=data)
    context.log.info("Final data saved successfully.")


# ----------------------------------------------------------------------
# Job Definition
# ----------------------------------------------------------------------
resource_defs = {
    "shared_filesystem": fs_io_manager,
    "load_modify_api": load_modify_api_resource,
    "reconciliation_api": reconciliation_api_resource,
    "openmeteo_api": openmeteo_api_resource,
    "geoapify_api": geoapify_api_resource,
    "worldpop_api": worldpop_api_resource,
    "column_extension_api": column_extension_api_resource,
    "save_service_api": save_service_api_resource,
    "mongodb": mongodb_resource,
    "intertwino_api": intertwino_api_resource,
    "app_network": app_network_resource,
}


@job(
    name="load_and_modify_data_pipeline",
    description="No description provided.",
    resource_defs=resource_defs,
    executor_def=docker_executor,
)
def load_and_modify_data_pipeline():
    """
    Sequential pipeline that loads data, enriches it through several external services,
    calculates environmental risk, and finally persists the result.
    """
    loaded = load_and_modify_data()
    reconciled = geocode_reconciliation(loaded)
    meteo = openmeteo_extension(reconciled)
    land_use = land_use_extension(meteo)
    pop_density = population_density_extension(land_use)
    risk = calculate_environmental_risk(pop_density)
    save_final_data(risk)


# ----------------------------------------------------------------------
# Schedule (disabled)
# ----------------------------------------------------------------------
# The schedule is intentionally disabled as per the specification.
# To enable, uncomment and configure the following:

# from dagster import ScheduleDefinition, DefaultScheduleStatus

# schedule = ScheduleDefinition(
#     job=load_and_modify_data_pipeline,
#     cron_schedule="0 0 * * *",  # Example cron; replace as needed
#     default_status=DefaultScheduleStatus.INACTIVE,
#     execution_timezone="UTC",
# )