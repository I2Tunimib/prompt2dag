# Generated by Dagster Code Generator
# Generation Metadata:
# - Job Name: load_and_modify_data_pipeline
# - Description: No description provided.
# - Executor Type: docker_executor
# - IO Manager: fs_io_manager
# - Dagster Version: 1.5.0
# - Use Assets: False
# - Required Resources: app_network

from dagster import (
    job,
    op,
    Out,
    In,
    RetryPolicy,
    resource,
    fs_io_manager,
    Field,
    String,
    execute_job,
    job_executor,
    docker_executor,
)

# Resources
@resource(config_schema={"data_dir": Field(String, is_required=True)})
def data_dir(context):
    return context.resource_config["data_dir"]

@resource
def load_and_modify_service():
    pass

@resource
def reconciliation_service():
    pass

@resource
def openmeteo_service():
    pass

@resource
def geoapify_land_use_api():
    pass

@resource
def worldpop_density_api():
    pass

@resource
def column_extension_service():
    pass

@resource
def save_service():
    pass

@resource
def docker_network():
    pass

@resource
def mongodb():
    pass

@resource
def intertwino_api():
    pass

# Ops
@op(
    out={"modified_data": Out()},
    required_resource_keys={"load_and_modify_service", "data_dir"},
    retry_policy=RetryPolicy(max_retries=1),
)
def load_and_modify_data(context):
    """Load and modify data using the load_and_modify_service."""
    data_dir = context.resources.data_dir
    # Simulate data loading and modification
    modified_data = "Modified Data"
    return modified_data

@op(
    out={"reconciled_data": Out()},
    required_resource_keys={"reconciliation_service"},
    retry_policy=RetryPolicy(max_retries=1),
)
def reconcile_geocoding(context, modified_data):
    """Reconcile geocoding using the reconciliation_service."""
    # Simulate geocoding reconciliation
    reconciled_data = f"Reconciled {modified_data}"
    return reconciled_data

@op(
    out={"extended_openmeteo_data": Out()},
    required_resource_keys={"openmeteo_service"},
    retry_policy=RetryPolicy(max_retries=1),
)
def extend_openmeteo_data(context, reconciled_data):
    """Extend data with OpenMeteo data using the openmeteo_service."""
    # Simulate OpenMeteo data extension
    extended_openmeteo_data = f"Extended OpenMeteo {reconciled_data}"
    return extended_openmeteo_data

@op(
    out={"extended_land_use_data": Out()},
    required_resource_keys={"geoapify_land_use_api"},
    retry_policy=RetryPolicy(max_retries=1),
)
def extend_land_use(context, extended_openmeteo_data):
    """Extend data with land use data using the geoapify_land_use_api."""
    # Simulate land use data extension
    extended_land_use_data = f"Extended Land Use {extended_openmeteo_data}"
    return extended_land_use_data

@op(
    out={"extended_population_density_data": Out()},
    required_resource_keys={"worldpop_density_api"},
    retry_policy=RetryPolicy(max_retries=1),
)
def extend_population_density(context, extended_land_use_data):
    """Extend data with population density data using the worldpop_density_api."""
    # Simulate population density data extension
    extended_population_density_data = f"Extended Population Density {extended_land_use_data}"
    return extended_population_density_data

@op(
    out={"extended_environmental_risk_data": Out()},
    required_resource_keys={"column_extension_service"},
    retry_policy=RetryPolicy(max_retries=1),
)
def extend_environmental_risk(context, extended_population_density_data):
    """Extend data with environmental risk data using the column_extension_service."""
    # Simulate environmental risk data extension
    extended_environmental_risk_data = f"Extended Environmental Risk {extended_population_density_data}"
    return extended_environmental_risk_data

@op(
    required_resource_keys={"save_service", "data_dir"},
    retry_policy=RetryPolicy(max_retries=1),
)
def save_final_data(context, extended_environmental_risk_data):
    """Save the final data using the save_service."""
    data_dir = context.resources.data_dir
    # Simulate saving the final data
    context.log.info(f"Saving final data to {data_dir}")

# Job
@job(
    resource_defs={
        "data_dir": data_dir,
        "load_and_modify_service": load_and_modify_service,
        "reconciliation_service": reconciliation_service,
        "openmeteo_service": openmeteo_service,
        "geoapify_land_use_api": geoapify_land_use_api,
        "worldpop_density_api": worldpop_density_api,
        "column_extension_service": column_extension_service,
        "save_service": save_service,
        "docker_network": docker_network,
        "mongodb": mongodb,
        "intertwino_api": intertwino_api,
        "io_manager": fs_io_manager,
    },
    executor_def=docker_executor,
)
def load_and_modify_data_pipeline():
    """No description provided."""
    modified_data = load_and_modify_data()
    reconciled_data = reconcile_geocoding(modified_data)
    extended_openmeteo_data = extend_openmeteo_data(reconciled_data)
    extended_land_use_data = extend_land_use(extended_openmeteo_data)
    extended_population_density_data = extend_population_density(extended_land_use_data)
    extended_environmental_risk_data = extend_environmental_risk(extended_population_density_data)
    save_final_data(extended_environmental_risk_data)

# Example execution
if __name__ == "__main__":
    execute_job(
        load_and_modify_data_pipeline,
        run_config={
            "resources": {
                "data_dir": {"config": {"data_dir": "/path/to/data"}},
                "docker_network": {"config": {"network": "app_network"}},
            }
        },
    )