metadata:
  target_orchestrator: airflow
  generated_at: 2025-12-02 04:44:08.547751
  source_analysis_file: 
    Pipeline_Description_Dataset/synthetic-generator-v2__synthetic_staged_etl_01_supply_chain_etl.py_description.txt
  pipeline_name: extract_vendor_a_pipeline
  pipeline_description: No description provided.
  orchestrator_specific: {}
schedule:
  enabled: true
  schedule_expression: '@daily'
  start_date: '2024-01-01T00:00:00Z'
  end_date:
  timezone: UTC
  catchup: false
connections:
  - conn_id: vendor_csv_fs
    conn_type: fs
    description: Vendor Shipment CSV Files
    config:
      base_path: /data/vendors
      base_url:
      host:
      port:
      protocol: file
      database:
      schema:
      bucket:
      queue_name:
  - conn_id: inventory_postgres
    conn_type: generic
    description: Inventory PostgreSQL Database
    config:
      base_path:
      base_url:
      host: postgresql.company.com
      port: 5432
      protocol: jdbc
      database: inventory_db
      schema: public
      bucket:
      queue_name:
      login: DB_USER_ENV
      password: DB_PASSWORD_ENV
  - conn_id: smtp_email
    conn_type: generic
    description: Supply Chain Email Notification Service
    config:
      base_path:
      base_url:
      host: smtp.company.com
      port: 587
      protocol: smtp
      database:
      schema:
      bucket:
      queue_name:
      login: SMTP_USER_ENV
      password: SMTP_PASSWORD_ENV
tasks:
  - task_id: extract_vendor_a
    task_name: Extract Vendor A Shipments
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: extract_vendor_a
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - extract_parallel
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: extract_vendor_b
    task_name: Extract Vendor B Shipments
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: extract_vendor_b
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - extract_parallel
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: extract_vendor_c
    task_name: Extract Vendor C Shipments
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: extract_vendor_c
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - extract_parallel
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: cleanse_shipment_data
    task_name: Cleanse and Enrich Shipment Data
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: cleanse_shipment_data
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - extract_vendor_a
      - extract_vendor_b
      - extract_vendor_c
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: load_shipment_to_inventory
    task_name: Load Shipment Data to Inventory Database
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: load_shipment_to_inventory
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - cleanse_shipment_data
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
  - task_id: send_etl_summary_email
    task_name: Send ETL Summary Email
    operator_class: PythonOperator
    operator_module: airflow.operators.python
    component_ref: send_etl_summary_email
    config:
      retry_delay: timedelta(seconds=300)
    upstream_task_ids:
      - load_shipment_to_inventory
    trigger_rule: all_success
    retries: 2
    retry_delay_seconds: 300
    validation_warnings: []
