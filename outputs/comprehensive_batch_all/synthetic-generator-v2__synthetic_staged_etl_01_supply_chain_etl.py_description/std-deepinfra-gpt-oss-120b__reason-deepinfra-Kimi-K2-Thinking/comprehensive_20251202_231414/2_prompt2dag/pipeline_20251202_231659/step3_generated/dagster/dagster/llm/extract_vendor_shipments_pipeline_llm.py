# Generated by Dagster Pipeline Generator
# Date: 2024-06-28
# Pipeline: extract_vendor_shipments_pipeline
# Description: No description provided.

from typing import Any, List, Dict
import pandas as pd
import smtplib
from dagster import (
    op,
    job,
    In,
    Out,
    RetryPolicy,
    ResourceDefinition,
    IOManager,
    io_manager,
    ConfigurableResource,
    ScheduleDefinition,
    multiprocess_executor,
    in_process_executor,
    Definitions,
)


# ----------------------------------------------------------------------
# Resource Definitions
# ----------------------------------------------------------------------


class FSIOManager(IOManager):
    """Simple filesystem IO manager placeholder."""

    def __init__(self, base_path: str = "/tmp"):
        self.base_path = base_path

    def handle_output(self, context, obj):
        # Placeholder: write DataFrame to CSV
        path = f"{self.base_path}/{context.step_key}.csv"
        if isinstance(obj, pd.DataFrame):
            obj.to_csv(path, index=False)
        else:
            with open(path, "w") as f:
                f.write(str(obj))

    def load_input(self, context):
        # Placeholder: read CSV into DataFrame
        path = f"{self.base_path}/{context.upstream_output.step_key}.csv"
        return pd.read_csv(path)


fs_io_manager = FSIOManager()


class InventoryPostgresResource(ConfigurableResource):
    """Placeholder for a PostgreSQL inventory database."""

    def write_shipments(self, df: pd.DataFrame) -> None:
        # In a real implementation this would write to PostgreSQL.
        print("Writing shipments to inventory database (placeholder).")
        print(df.head())


class EmailSMTPResource(ConfigurableResource):
    """Placeholder for an SMTP email server."""

    smtp_host: str = "localhost"
    smtp_port: int = 25
    sender: str = "no-reply@example.com"
    recipients: List[str] = ["data-team@example.com"]

    def send_email(self, subject: str, body: str) -> None:
        # In a real implementation this would send an email via SMTP.
        print(f"Sending email to {self.recipients} (placeholder).")
        print(f"Subject: {subject}")
        print(body)


# ----------------------------------------------------------------------
# Ops
# ----------------------------------------------------------------------


@op(
    name="extract_join",
    description="Placeholder upstream op required by extract_vendor_shipments.",
    out=Out(pd.DataFrame),
    retry_policy=RetryPolicy(max_retries=2, delay=1),
    required_resource_keys=set(),
    executor_def=in_process_executor,
)
def extract_join() -> pd.DataFrame:
    """Generate a dummy DataFrame representing joined data."""
    data = {"order_id": [1, 2, 3], "vendor": ["A", "B", "C"]}
    return pd.DataFrame(data)


@op(
    name="extract_vendor_shipments",
    description="Extract Vendor Shipment CSVs.",
    ins={"joined": In(pd.DataFrame)},
    out=Out(pd.DataFrame),
    retry_policy=RetryPolicy(max_retries=2, delay=1),
    required_resource_keys={"fs_vendor_a", "fs_vendor_b", "fs_vendor_c"},
    executor_def=in_process_executor,
)
def extract_vendor_shipments(context, joined: pd.DataFrame) -> pd.DataFrame:
    """
    Simulate extraction of vendor shipment CSV files from multiple filesystem resources.
    Returns a concatenated DataFrame of all shipments.
    """
    # Placeholder: create dummy shipment data
    shipments_a = pd.DataFrame({"shipment_id": [101, 102], "vendor": ["A", "A"], "qty": [10, 20]})
    shipments_b = pd.DataFrame({"shipment_id": [201], "vendor": ["B"], "qty": [15]})
    shipments_c = pd.DataFrame({"shipment_id": [301, 302, 303], "vendor": ["C", "C", "C"], "qty": [5, 7, 9]})

    all_shipments = pd.concat([shipments_a, shipments_b, shipments_c], ignore_index=True)
    context.log.info(f"Extracted {len(all_shipments)} shipment records.")
    return all_shipments


@op(
    name="cleanse_and_normalize_shipments",
    description="Cleanse and normalize shipment data.",
    ins={"raw_shipments": In(pd.DataFrame)},
    out=Out(pd.DataFrame),
    retry_policy=RetryPolicy(max_retries=2, delay=1),
    required_resource_keys=set(),
    executor_def=in_process_executor,
)
def cleanse_and_normalize_shipments(context, raw_shipments: pd.DataFrame) -> pd.DataFrame:
    """
    Perform basic data cleansing:
    - Drop rows with missing shipment_id or qty.
    - Ensure qty is positive integer.
    - Standardize column names.
    """
    df = raw_shipments.dropna(subset=["shipment_id", "qty"])
    df = df[df["qty"] > 0]
    df["qty"] = df["qty"].astype(int)
    df = df.rename(columns=lambda x: x.strip().lower())
    context.log.info(f"Cleansed data contains {len(df)} records.")
    return df


@op(
    name="load_shipment_data",
    description="Load cleansed shipments to the inventory database.",
    ins={"clean_shipments": In(pd.DataFrame)},
    out=Out(None),
    retry_policy=RetryPolicy(max_retries=2, delay=1),
    required_resource_keys={"postgres_inventory"},
    executor_def=in_process_executor,
)
def load_shipment_data(context, clean_shipments: pd.DataFrame) -> None:
    """Write the cleaned shipment DataFrame to the inventory PostgreSQL resource."""
    inventory: InventoryPostgresResource = context.resources.postgres_inventory
    inventory.write_shipments(clean_shipments)
    context.log.info("Shipment data loaded into inventory database.")


@op(
    name="send_summary_email",
    description="Send ETL summary email.",
    ins={"loaded": In(None)},
    out=Out(None),
    retry_policy=RetryPolicy(max_retries=2, delay=1),
    required_resource_keys={"email_smtp"},
    executor_def=in_process_executor,
)
def send_summary_email(context, loaded: Any) -> None:
    """Send a summary email after successful load."""
    email: EmailSMTPResource = context.resources.email_smtp
    subject = "ETL Summary: Vendor Shipments"
    body = "The vendor shipment extraction and load process completed successfully."
    email.send_email(subject, body)
    context.log.info("Summary email sent.")


# ----------------------------------------------------------------------
# Job Definition
# ----------------------------------------------------------------------


@job(
    name="extract_vendor_shipments_pipeline",
    description="No description provided.",
    executor_def=multiprocess_executor,
    resource_defs={
        "fs_vendor_a": ResourceDefinition.hardcoded_resource(fs_io_manager),
        "fs_vendor_b": ResourceDefinition.hardcoded_resource(fs_io_manager),
        "fs_vendor_c": ResourceDefinition.hardcoded_resource(fs_io_manager),
        "postgres_inventory": ResourceDefinition.hardcoded_resource(InventoryPostgresResource()),
        "email_smtp": ResourceDefinition.hardcoded_resource(EmailSMTPResource()),
        # Additional placeholder resources referenced in the spec
        "ref_location": ResourceDefinition.none_resource(),
        "fs_io_manager": ResourceDefinition.hardcoded_resource(fs_io_manager),
    },
)
def extract_vendor_shipments_pipeline():
    """
    Orchestrates the extraction, cleansing, loading, and notification steps for vendor shipments.
    """
    joined = extract_join()
    raw_shipments = extract_vendor_shipments(joined)
    clean_shipments = cleanse_and_normalize_shipments(raw_shipments)
    load_result = load_shipment_data(clean_shipments)
    send_summary_email(load_result)


# ----------------------------------------------------------------------
# Schedule (disabled)
# ----------------------------------------------------------------------


daily_schedule = ScheduleDefinition(
    job=extract_vendor_shipments_pipeline,
    cron_schedule="@daily",
    execution_timezone="UTC",
    description="Daily schedule for the extract_vendor_shipments_pipeline (currently disabled).",
    default_status="inactive",  # Disabled schedule
    tags={"catchup": "false"},
)


# ----------------------------------------------------------------------
# Definitions
# ----------------------------------------------------------------------


defs = Definitions(
    jobs=[extract_vendor_shipments_pipeline],
    schedules=[daily_schedule],
    resources={
        "fs_vendor_a": fs_io_manager,
        "fs_vendor_b": fs_io_manager,
        "fs_vendor_c": fs_io_manager,
        "postgres_inventory": InventoryPostgresResource(),
        "email_smtp": EmailSMTPResource(),
        "ref_location": None,
        "fs_io_manager": fs_io_manager,
    },
)