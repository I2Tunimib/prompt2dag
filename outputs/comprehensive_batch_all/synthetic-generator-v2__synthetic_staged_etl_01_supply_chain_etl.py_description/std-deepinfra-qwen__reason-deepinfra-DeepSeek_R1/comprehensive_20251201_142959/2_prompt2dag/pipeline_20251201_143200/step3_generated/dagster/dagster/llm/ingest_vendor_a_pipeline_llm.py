# Generated by Dagster Code Generator
# Date: 2023-10-05
# Dagster Version: 1.5.0

from dagster import (
    job,
    op,
    Out,
    In,
    RetryPolicy,
    multiprocess_executor,
    fs_io_manager,
    resource,
    schedule,
)

# Resources
@resource
def vendor_a_data_source():
    """Vendor A Data Source"""
    pass

@resource
def vendor_b_data_source():
    """Vendor B Data Source"""
    pass

@resource
def vendor_c_data_source():
    """Vendor C Data Source"""
    pass

@resource
def location_reference_tables():
    """Location Reference Tables"""
    pass

@resource
def inventory_database():
    """Inventory Database"""
    pass

@resource
def email_system():
    """Email System"""
    pass

# Ops
@op(
    name="ingest_vendor_a",
    out={"vendor_a_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"vendor_a_data_source"},
)
def ingest_vendor_a(context):
    """Ingest Vendor A Data"""
    # Simulate data ingestion
    vendor_a_data = "Vendor A Data"
    context.log.info(f"Ingested {vendor_a_data}")
    return vendor_a_data

@op(
    name="ingest_vendor_b",
    out={"vendor_b_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"vendor_b_data_source"},
)
def ingest_vendor_b(context):
    """Ingest Vendor B Data"""
    # Simulate data ingestion
    vendor_b_data = "Vendor B Data"
    context.log.info(f"Ingested {vendor_b_data}")
    return vendor_b_data

@op(
    name="ingest_vendor_c",
    out={"vendor_c_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"vendor_c_data_source"},
)
def ingest_vendor_c(context):
    """Ingest Vendor C Data"""
    # Simulate data ingestion
    vendor_c_data = "Vendor C Data"
    context.log.info(f"Ingested {vendor_c_data}")
    return vendor_c_data

@op(
    name="cleanse_data",
    ins={
        "vendor_a_data": In(),
        "vendor_b_data": In(),
        "vendor_c_data": In(),
    },
    out={"cleaned_data": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"location_reference_tables"},
)
def cleanse_data(context, vendor_a_data, vendor_b_data, vendor_c_data):
    """Cleanse and Normalize Data"""
    # Simulate data cleansing
    cleaned_data = f"Cleaned Data from {vendor_a_data}, {vendor_b_data}, {vendor_c_data}"
    context.log.info(f"Cleaned data: {cleaned_data}")
    return cleaned_data

@op(
    name="load_to_db",
    ins={"cleaned_data": In()},
    out={"db_load_status": Out()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"inventory_database"},
)
def load_to_db(context, cleaned_data):
    """Load to Database"""
    # Simulate data loading
    db_load_status = "Data loaded successfully"
    context.log.info(f"Loaded data to database: {db_load_status}")
    return db_load_status

@op(
    name="send_summary_email",
    ins={"db_load_status": In()},
    retry_policy=RetryPolicy(max_retries=2),
    required_resource_keys={"email_system"},
)
def send_summary_email(context, db_load_status):
    """Send Summary Email"""
    # Simulate sending summary email
    context.log.info(f"Sent summary email with status: {db_load_status}")

# Job
@job(
    name="ingest_vendor_a_pipeline",
    description="No description provided.",
    executor_def=multiprocess_executor,
    resource_defs={
        "vendor_a_data_source": vendor_a_data_source,
        "vendor_b_data_source": vendor_b_data_source,
        "vendor_c_data_source": vendor_c_data_source,
        "location_reference_tables": location_reference_tables,
        "inventory_database": inventory_database,
        "email_system": email_system,
    },
    io_manager_def=fs_io_manager,
)
def ingest_vendor_a_pipeline():
    vendor_a_data = ingest_vendor_a()
    vendor_b_data = ingest_vendor_b()
    vendor_c_data = ingest_vendor_c()
    cleaned_data = cleanse_data(vendor_a_data, vendor_b_data, vendor_c_data)
    db_load_status = load_to_db(cleaned_data)
    send_summary_email(db_load_status)

# Schedule
@schedule(
    job=ingest_vendor_a_pipeline,
    cron_schedule="@daily",
    execution_timezone="UTC",
    name="ingest_vendor_a_pipeline_schedule",
    should_execute=lambda: True,
    execution_time_window=None,
    tags=None,
    description="No description provided.",
    default_status="RUNNING",
    job_name="ingest_vendor_a_pipeline",
)
def ingest_vendor_a_pipeline_schedule(_context):
    return {}