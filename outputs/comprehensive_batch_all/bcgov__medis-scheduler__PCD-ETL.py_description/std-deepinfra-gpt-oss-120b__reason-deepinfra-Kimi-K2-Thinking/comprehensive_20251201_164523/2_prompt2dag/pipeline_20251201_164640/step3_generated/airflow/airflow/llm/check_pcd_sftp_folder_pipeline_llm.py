# Generated by Airflow DAG generator on 2024-06-13
"""
DAG: check_pcd_sftp_folder_pipeline
Description: Sequential pipeline to check SFTP and shared folders, extract PCD API data,
process and load it, and send an ETL notification.
"""

from datetime import datetime, timedelta
import logging
import json

from airflow import DAG
from airflow.exceptions import AirflowException
from airflow.providers.http.operators.http import SimpleHttpOperator
from airflow.decorators import task
from airflow.utils.task_group import TaskGroup

# Default arguments for the DAG
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=5),
}

with DAG(
    dag_id="check_pcd_sftp_folder_pipeline",
    description="Sequential pipeline to check SFTP and shared folders, extract PCD API data, process and load it, and send an ETL notification.",
    schedule_interval=None,  # Disabled schedule
    start_date=datetime(2024, 1, 1),
    catchup=False,
    default_args=default_args,
    tags=["pcd", "sftp", "etl"],
    max_active_runs=1,
) as dag:

    @task(retries=3, retry_delay=timedelta(minutes=2))
    def check_pcd_sftp_folder():
        """
        Verify that the PCD SFTP folder is reachable and contains expected files.
        Uses the ``sftp_folder_conn`` connection.
        """
        from airflow.hooks.base import BaseHook
        try:
            conn = BaseHook.get_connection("sftp_folder_conn")
            # Placeholder logic: log connection details
            logging.info("Checking SFTP folder using connection: %s", conn.host)
            # Insert real SFTP checking logic here (e.g., list files)
        except Exception as exc:
            logging.error("Failed to check SFTP folder: %s", exc)
            raise AirflowException("SFTP folder check failed") from exc

    @task(retries=3, retry_delay=timedelta(minutes=2))
    def check_pcd_shared_folder():
        """
        Verify that the PCD shared folder is reachable.
        Uses the ``shared_folder_conn`` connection.
        """
        from airflow.hooks.base import BaseHook
        try:
            conn = BaseHook.get_connection("shared_folder_conn")
            logging.info("Checking shared folder using connection: %s", conn.host)
            # Insert real shared folder checking logic here
        except Exception as exc:
            logging.error("Failed to check shared folder: %s", exc)
            raise AirflowException("Shared folder check failed") from exc

    extract_pcd_api = SimpleHttpOperator(
        task_id="extract_pcd_api",
        http_conn_id="api_financial_expense_conn",
        endpoint="/",  # Adjust endpoint as needed
        method="GET",
        headers={"Content-Type": "application/json"},
        response_check=lambda response: response.status_code == 200,
        log_response=True,
        retries=2,
        retry_delay=timedelta(minutes=3),
    )

    @task(retries=2, retry_delay=timedelta(minutes=3))
    def process_and_load_pcd(**context):
        """
        Process the data extracted from the PCD API and load it into the target system.
        """
        try:
            # Pull the HTTP response from XCom
            ti = context["ti"]
            api_response = ti.xcom_pull(task_ids="extract_pcd_api")
            if not api_response:
                raise ValueError("No data received from extract_pcd_api")
            data = json.loads(api_response)
            logging.info("Processing %d records from PCD API", len(data))
            # Placeholder for processing logic
            # e.g., transform, validate, and load into a database
        except Exception as exc:
            logging.error("Processing and loading failed: %s", exc)
            raise AirflowException("Process and load step failed") from exc

    @task(retries=1, retry_delay=timedelta(minutes=5))
    def send_etl_notification():
        """
        Send an ETL completion notification via the email_notification_conn.
        """
        from airflow.hooks.base import BaseHook
        try:
            conn = BaseHook.get_connection("email_notification_conn")
            # Placeholder: log notification details
            logging.info("Sending ETL notification using connection: %s", conn.host)
            # Real implementation could use SMTPHook or a custom API call
        except Exception as exc:
            logging.error("Failed to send ETL notification: %s", exc)
            raise AirflowException("ETL notification failed") from exc

    # Define task dependencies (sequential flow)
    (
        check_pcd_sftp_folder()
        >> check_pcd_shared_folder()
        >> extract_pcd_api
        >> process_and_load_pcd()
        >> send_etl_notification()
    )