# Generated by Prefect 2.x Code Generator
# Date: 2023-10-05
# Prefect Version: 2.14.0

from prefect import flow, task, get_run_logger
from prefect.task_runners import ConcurrentTaskRunner
from prefect.deployments import Deployment
from prefect.infrastructure.kubernetes import KubernetesJob
from prefect.infrastructure.process import Process
from prefect.blocks.system import Secret

# Schedule Configuration
pcd_etl_schedule = Secret.load("pcd-etl-schedule").get()

# Task Definitions

@task(retries=0, name="Check PCD SFTP Folder")
def check_pcd_sftp_folder():
    logger = get_run_logger()
    logger.info("Checking PCD SFTP Folder")
    # Add your task logic here
    return "SFTP Folder Checked"

@task(retries=0, name="Check PCD Shared Folder")
def check_pcd_shared_folder():
    logger = get_run_logger()
    logger.info("Checking PCD Shared Folder")
    # Add your task logic here
    return "Shared Folder Checked"

@task(retries=0, name="Start PCD Extract 1")
def start_pcd_extract_1():
    logger = get_run_logger()
    logger.info("Starting PCD Extract 1")
    # Add your task logic here
    return "PCD Extract 1 Started"

@task(retries=0, name="Parallel HTTP API Extraction")
def parallel_http_api_extraction():
    logger = get_run_logger()
    logger.info("Performing Parallel HTTP API Extraction")
    # Add your task logic here
    return "HTTP API Extraction Completed"

@task(retries=0, name="Start PCD Extract 2")
def start_pcd_extract_2():
    logger = get_run_logger()
    logger.info("Starting PCD Extract 2")
    # Add your task logic here
    return "PCD Extract 2 Started"

@task(retries=0, name="PCD File Upload")
def pcd_file_upload():
    logger = get_run_logger()
    logger.info("Uploading PCD File")
    # Add your task logic here
    return "PCD File Uploaded"

@task(retries=0, name="ETL Notification")
def etl_notification():
    logger = get_run_logger()
    logger.info("Sending ETL Notification")
    # Add your task logic here
    return "ETL Notification Sent"

# Flow Definition
@flow(name="check_pcd_sftp_folder_pipeline", task_runner=ConcurrentTaskRunner(), schedule=pcd_etl_schedule)
def check_pcd_sftp_folder_pipeline():
    logger = get_run_logger()
    logger.info("Starting PCD SFTP Folder Pipeline")

    sftp_result = check_pcd_sftp_folder.submit()
    shared_result = check_pcd_shared_folder.submit(wait_for=[sftp_result])
    extract_1_result = start_pcd_extract_1.submit(wait_for=[shared_result])
    api_extraction_result = parallel_http_api_extraction.submit(wait_for=[extract_1_result])
    extract_2_result = start_pcd_extract_2.submit(wait_for=[api_extraction_result])
    upload_result = pcd_file_upload.submit(wait_for=[extract_2_result])
    notification_result = etl_notification.submit(wait_for=[upload_result])

    logger.info("PCD SFTP Folder Pipeline Completed")

# Deployment Configuration
deployment = Deployment.build_from_flow(
    flow=check_pcd_sftp_folder_pipeline,
    name="check_pcd_sftp_folder_pipeline_deployment",
    work_pool_name="default-agent-pool",
    work_queue_name="default",
    parameters={},
    tags=["pcd", "etl"],
    description="Comprehensive Pipeline Description for PCD (Primary Care Data) processing",
    version="1.0.0",
    schedule=pcd_etl_schedule,
    path=".",
    entrypoint="path/to/your/flow_file.py:check_pcd_sftp_folder_pipeline",
    infra_overrides={"env": {"VAR_NAME": "var_value"}},
)

if __name__ == "__main__":
    deployment.apply()