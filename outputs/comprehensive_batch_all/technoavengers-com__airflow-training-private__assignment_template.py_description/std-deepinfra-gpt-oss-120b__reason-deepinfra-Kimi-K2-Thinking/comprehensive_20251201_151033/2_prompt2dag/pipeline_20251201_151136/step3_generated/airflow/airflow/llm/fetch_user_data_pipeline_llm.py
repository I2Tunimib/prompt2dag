# Generated by Airflow DAG generator on 2024-06-13
"""
Airflow DAG: fetch_user_data_pipeline
Description: No description provided.
Pattern: sequential
"""

from datetime import datetime, timedelta

from airflow import DAG
from airflow.providers.http.operators.http import SimpleHttpOperator
from airflow.operators.python import PythonOperator
from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator
from airflow.utils.task_group import TaskGroup
from airflow.utils.dates import days_ago
from airflow.models import Variable
from airflow.utils.email import send_email

# Default arguments for all tasks
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "retries": 0,                     # All tasks have 0 retries as per specification
    "retry_delay": timedelta(minutes=5),
    "email_on_failure": False,
    "email_on_retry": False,
}

def failure_callback(context):
    """Send an email on task failure (optional)."""
    dag_id = context.get("dag").dag_id
    task_id = context.get("task_instance").task_id
    execution_date = context.get("execution_date")
    subject = f"[Airflow] DAG {dag_id} - Task {task_id} Failed"
    html_content = f"""
    <p>Task <strong>{task_id}</strong> in DAG <strong>{dag_id}</strong> failed.</p>
    <p>Execution date: {execution_date}</p>
    <pre>{context.get('exception')}</pre>
    """
    # Replace with your email address or use Airflow variables
    send_email(to=["airflow@example.com"], subject=subject, html_content=html_content)

with DAG(
    dag_id="fetch_user_data_pipeline",
    description="No description provided.",
    schedule_interval="@daily",
    start_date=days_ago(1),
    catchup=False,
    default_args=default_args,
    tags=["example"],
    max_active_runs=1,
    default_view="graph",
    timezone="UTC",
    on_failure_callback=failure_callback,
) as dag:

    # -------------------------------------------------------------------------
    # Task: fetch_user_data
    # -------------------------------------------------------------------------
    fetch_user_data = SimpleHttpOperator(
        task_id="fetch_user_data",
        http_conn_id="reqres_http_api",
        method="GET",
        endpoint="api/users",
        headers={"Content-Type": "application/json"},
        response_check=lambda response: response.status_code == 200,
        log_response=True,
        # The response body will be pushed to XCom automatically
    )

    # -------------------------------------------------------------------------
    # Task: transform_user_data
    # -------------------------------------------------------------------------
    def _transform_user_data(**context):
        """
        Pull raw JSON from fetch_user_data, extract relevant fields,
        and return a list of dictionaries ready for insertion.
        """
        raw_response = context["ti"].xcom_pull(task_ids="fetch_user_data")
        if not raw_response:
            raise ValueError("No data received from fetch_user_data task.")

        # SimpleHttpOperator returns a string; parse JSON if needed
        import json
        data = json.loads(raw_response) if isinstance(raw_response, str) else raw_response

        # Expected structure: {"data": [{...}, ...]}
        users = data.get("data", [])
        transformed = []
        for user in users:
            transformed.append({
                "id": user.get("id"),
                "email": user.get("email"),
                "first_name": user.get("first_name"),
                "last_name": user.get("last_name"),
                "avatar": user.get("avatar"),
            })
        # Push transformed data to XCom
        return transformed

    transform_user_data = PythonOperator(
        task_id="transform_user_data",
        python_callable=_transform_user_data,
        provide_context=True,
    )

    # -------------------------------------------------------------------------
    # Task: create_user_table
    # -------------------------------------------------------------------------
    create_user_table = SQLExecuteQueryOperator(
        task_id="create_user_table",
        conn_id="postgres_db",
        sql="""
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY,
            email VARCHAR(255),
            first_name VARCHAR(255),
            last_name VARCHAR(255),
            avatar VARCHAR(255)
        );
        """,
    )

    # -------------------------------------------------------------------------
    # Task: insert_user_data
    # -------------------------------------------------------------------------
    insert_user_data = SQLExecuteQueryOperator(
        task_id="insert_user_data",
        conn_id="postgres_db",
        sql="""
        {% for user in ti.xcom_pull(task_ids='transform_user_data') %}
        INSERT INTO users (id, email, first_name, last_name, avatar)
        VALUES ({{ user.id }}, '{{ user.email }}', '{{ user.first_name }}', '{{ user.last_name }}', '{{ user.avatar }}')
        ON CONFLICT (id) DO NOTHING;
        {% endfor %}
        """,
        # Enable Jinja templating for the SQL field
        templated_fields=["sql"],
    )

    # -------------------------------------------------------------------------
    # Set task dependencies (sequential execution)
    # -------------------------------------------------------------------------
    fetch_user_data >> transform_user_data >> create_user_table >> insert_user_data