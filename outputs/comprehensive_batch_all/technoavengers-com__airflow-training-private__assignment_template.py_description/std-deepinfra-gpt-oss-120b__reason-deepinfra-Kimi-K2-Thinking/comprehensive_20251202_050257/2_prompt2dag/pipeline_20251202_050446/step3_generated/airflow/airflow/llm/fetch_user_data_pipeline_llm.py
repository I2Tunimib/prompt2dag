# Generated by Airflow DAG generator on 2024-06-12
"""
Airflow DAG: fetch_user_data_pipeline
Description: No description provided.
Pattern: sequential
"""

from __future__ import annotations

import json
from datetime import datetime, timedelta

import requests
from airflow import DAG
from airflow.exceptions import AirflowException
from airflow.providers.http.hooks.http import HttpHook
from airflow.providers.common.sql.operators.sql import SqlExecuteQueryOperator
from airflow.decorators import task

# Default arguments for the DAG
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "retries": 0,
    "retry_delay": timedelta(minutes=5),
    "email_on_failure": False,
    "email_on_retry": False,
}

# DAG definition
with DAG(
    dag_id="fetch_user_data_pipeline",
    description="No description provided.",
    schedule_interval="@daily",
    start_date=datetime(2024, 1, 1),
    catchup=True,
    default_args=default_args,
    tags=["example"],
    max_active_runs=1,
    timezone="UTC",
) as dag:

    @task(task_id="fetch_user_data", retries=0)
    def fetch_user_data() -> list[dict]:
        """
        Fetch user data from the ReqRes API using an HttpHook.
        Returns a list of user dictionaries.
        """
        hook = HttpHook(http_conn_id="reqres_api", method="GET")
        try:
            # The ReqRes API endpoint for users (page 1)
            response = hook.run(endpoint="api/users?page=1")
            if response.status_code != 200:
                raise AirflowException(
                    f"Failed to fetch data, status code: {response.status_code}"
                )
            data = response.json()
            users = data.get("data", [])
            return users
        except requests.RequestException as exc:
            raise AirflowException(f"Error while calling ReqRes API: {exc}") from exc

    @task(task_id="transform_user_data", retries=0)
    def transform_user_data(users: list[dict]) -> list[dict]:
        """
        Transform raw user data into a format suitable for PostgreSQL insertion.
        For this example we keep the fields asâ€‘is.
        """
        transformed = []
        for user in users:
            transformed.append(
                {
                    "id": user.get("id"),
                    "email": user.get("email"),
                    "first_name": user.get("first_name"),
                    "last_name": user.get("last_name"),
                    "avatar": user.get("avatar"),
                }
            )
        return transformed

    # -------------------------------------------------------------------------
    # SQL tasks using SqlExecuteQueryOperator (works with any DB connection)
    # -------------------------------------------------------------------------

    create_user_table = SqlExecuteQueryOperator(
        task_id="create_user_table",
        conn_id="postgres_db",
        sql="""
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY,
            email VARCHAR(255) NOT NULL,
            first_name VARCHAR(100),
            last_name VARCHAR(100),
            avatar TEXT
        );
        """,
        retries=0,
    )

    insert_user_data = SqlExecuteQueryOperator(
        task_id="insert_user_data",
        conn_id="postgres_db",
        sql="""
        INSERT INTO users (id, email, first_name, last_name, avatar)
        VALUES (%(id)s, %(email)s, %(first_name)s, %(last_name)s, %(avatar)s)
        ON CONFLICT (id) DO UPDATE SET
            email = EXCLUDED.email,
            first_name = EXCLUDED.first_name,
            last_name = EXCLUDED.last_name,
            avatar = EXCLUDED.avatar;
        """,
        # Pull the transformed data from XCom and pass it as parameters.
        parameters="{{ ti.xcom_pull(task_ids='transform_user_data') }}",
        retries=0,
    )

    # -------------------------------------------------------------------------
    # Define task dependencies (sequential flow)
    # -------------------------------------------------------------------------

    # fetch_user_data >> transform_user_data >> create_user_table >> insert_user_data
    fetched = fetch_user_data()
    transformed = transform_user_data(fetched)
    transformed >> create_user_table >> insert_user_data

# End of DAG definition.