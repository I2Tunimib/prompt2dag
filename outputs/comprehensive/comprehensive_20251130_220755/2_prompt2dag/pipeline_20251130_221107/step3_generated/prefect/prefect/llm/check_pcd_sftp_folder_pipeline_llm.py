# Generated by Prefect 2.x Code Generator
# Date: 2023-10-05
# Prefect Version: 2.14.0

from prefect import flow, task, get_run_logger
from prefect.deployments import Deployment
from prefect.orion.schemas.schedules import CronSchedule
from prefect_kubernetes.job import KubernetesJob
from prefect.tasks import task_input_hash
from prefect.infrastructure.process import Process
from prefect.infrastructure.kubernetes import KubernetesJob as KubernetesJobInfra
from prefect.task_runners import ConcurrentTaskRunner

# Task definitions
@task(retries=0, name="Check PCD SFTP Folder")
def check_pcd_sftp_folder():
    logger = get_run_logger()
    logger.info("Checking PCD SFTP Folder")
    # Placeholder for actual task logic
    return "SFTP folder checked"

@task(retries=0, name="Check PCD Shared Folder")
def check_pcd_shared_folder():
    logger = get_run_logger()
    logger.info("Checking PCD Shared Folder")
    # Placeholder for actual task logic
    return "Shared folder checked"

@task(retries=0, name="Start PCD Extract 1")
def start_pcd_extract_1():
    logger = get_run_logger()
    logger.info("Starting PCD Extract 1")
    # Placeholder for actual task logic
    return "PCD Extract 1 started"

@task(retries=0, name="Parallel HTTP API Extraction")
def parallel_http_api_extraction():
    logger = get_run_logger()
    logger.info("Performing Parallel HTTP API Extraction")
    # Placeholder for actual task logic
    return "HTTP API extraction completed"

@task(retries=0, name="Start PCD Extract 2")
def start_pcd_extract_2():
    logger = get_run_logger()
    logger.info("Starting PCD Extract 2")
    # Placeholder for actual task logic
    return "PCD Extract 2 started"

@task(retries=0, name="PCD File Upload")
def pcd_file_upload():
    logger = get_run_logger()
    logger.info("Uploading PCD File")
    # Placeholder for actual task logic
    return "PCD file uploaded"

@task(retries=0, name="ETL Notification")
def etl_notification():
    logger = get_run_logger()
    logger.info("Sending ETL Notification")
    # Placeholder for actual task logic
    return "ETL notification sent"

# Flow definition
@flow(name="check_pcd_sftp_folder_pipeline", task_runner=ConcurrentTaskRunner())
def check_pcd_sftp_folder_pipeline():
    logger = get_run_logger()
    logger.info("Starting check_pcd_sftp_folder_pipeline")

    sftp_result = check_pcd_sftp_folder.submit()
    shared_folder_result = check_pcd_shared_folder.submit(wait_for=[sftp_result])
    extract_1_result = start_pcd_extract_1.submit(wait_for=[shared_folder_result])
    http_api_result = parallel_http_api_extraction.submit(wait_for=[extract_1_result])
    extract_2_result = start_pcd_extract_2.submit(wait_for=[http_api_result])
    file_upload_result = pcd_file_upload.submit(wait_for=[extract_2_result])
    etl_notification.submit(wait_for=[file_upload_result, http_api_result])

# Deployment configuration
deployment = Deployment.build_from_flow(
    flow=check_pcd_sftp_folder_pipeline,
    name="check_pcd_sftp_folder_pipeline_deployment",
    work_pool_name="default-agent-pool",
    schedule=CronSchedule(
        cron="{{var.value.pcd_etl_schedule}}",
        timezone="UTC",
        start_date=None,
        end_date=None,
        inclusive=False,
        day_or=True,
        tags=[],
        parameters={},
        description="",
        catchup=False,
    ),
    parameters={},
    tags=[],
    description="",
    version=None,
    enforce_parameter_schema=False,
    skip_upload=True,
)

if __name__ == "__main__":
    deployment.apply()
```
This code defines a Prefect 2.x flow named `check_pcd_sftp_folder_pipeline` with the specified tasks and dependencies. The flow is configured to use a `ConcurrentTaskRunner` and is scheduled using a cron expression. The deployment is configured to run in the `default-agent-pool` work pool. The tasks are placeholders and should be replaced with the actual logic for your use case.